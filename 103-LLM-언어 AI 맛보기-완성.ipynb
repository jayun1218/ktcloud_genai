{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAPO58qbDYi8"
   },
   "source": [
    "# **언어 AI 이해**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAmo5uhXQ46c"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHIcfXn8RArA"
   },
   "source": [
    "- 💡 **NOTE**\n",
    "    - 이 노트북의 코드를 실행하려면 GPU를 사용하는 것이 좋습니다. 구글 코랩에서는 **런타임 > 런타임 유형 변경 > 하드웨어 가속기 > T4 GPU**를 선택하세요.\n",
    "    - **T4 GPU : 16GB VRAM**\n",
    "\n",
    "- 💡**코드 내용**\n",
    "    - 언어 AI의 이해를 돕는 코드\n",
    "    - 2000년대 이전의 자연어 처리(NLP) 과정 이해를 돕는 예제로 구성함\n",
    "    - 어떤 모델은 실행시간이 오래 걸릴 수 있음.(코랩에서는 RAM을 모두 사용 후 세션이 다운 될 수 있음)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-OX9xcYMp_f"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TCZmmIJs4D-"
   },
   "source": [
    "# **[Quicktour] transformers로 확인하는 언어 AI의 기능 예**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSl3zLaYboW6"
   },
   "source": [
    "- **Hugging Face**\n",
    "    - Hugging Face는 AI 모델과 데이터셋을 공유·활용할 수 있는 대표적인 오픈소스 플랫폼, 커뮤니티\n",
    "        - **모델 허브(Model Hub)** : 수만 개의 공개된 머신러닝/딥러닝 모델을 누구나 다운로드·활용 가능\n",
    "        - **데이터셋 허브(Datasets)** : 다양한 표준/비표준 데이터셋을 간편하게 불러와 실험 가능\n",
    "        - **Transformers 라이브러리** : BERT, GPT, T5, LLaMA 등 최신 NLP·멀티모달 모델을 손쉽게 사용 가능\n",
    "        - **PEFT/Accelerate 등 도구** : 파인튜닝·분산 학습·최적화 지원\n",
    "        - **커뮤니티**: 연구자·개발자가 모델과 코드를 공유하고 협업할 수 있는 생태계\n",
    "\n",
    "- **transformers**\n",
    "    - transformers library https://huggingface.co/docs/transformers/index\n",
    "    - Hugging Face에서 제공하는 사전 훈련된 AI 모델들을 쉽게 사용할 수 있게 해주는 파이썬 라이브러리\n",
    "    - 복잡한 AI 모델을 간단한 코드로 사용할 수 있게 해주는 도구\n",
    "\n",
    "- **pipeline**\n",
    "    - https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
    "    - pipeline은 자연어 처리(NLP)·비전·오디오 등 다양한 AI 태스크를 쉽게 실행할 수 있도록 미리 구성된 추론(실행) 도구\n",
    "    - 태스크 이름(예: \"sentiment-analysis\", \"translation\")을 입력하면,자동으로 적합한 모델 + 토크나이저 + 전/후처리 로직을 불러와,사용자가 텍스트/이미지/오디오를 바로 넣어 결과를 얻을 수 있게 함\n",
    "\n",
    "    - **pipeline(sentiment-analysis)**\n",
    "        - Hugging Face Pipelines Documentation :  \n",
    "        - 텍스트의 감정(긍정/부정) 분석에 특화된 즉시 사용 가능한 AI 모델을 사용하는 파이프라인의 작업(task) 이름\n",
    "        - 감정 분석에 특화된 즉시 사용 가능한 AI 모델을 사용하는 작업(task) 이름\n",
    "        - (AI모델 X) 내부적으로 BERT, RoBERTa, DistilBERT 등의 실제 신경망 모델이 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLclNnCla-rt"
   },
   "source": [
    "## **예제: 나만의 영화 평론 분석기 (자연어 이해 - NLU)**\n",
    "- **목표**: 영화 리뷰를 입력하면, 해당 리뷰가 긍정적인지 부정적인지를 맞추고, 리뷰에 언급된 핵심 키워드를 뽑아내는 프로그램\n",
    "- **핵심 기술**: 감성 분석(Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.56.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nXxu78mQa-0C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 감성 분석(Sentiment Analysis) 결과\n",
      "리뷰: 이 영화는 정말 시간 가는 줄 모르고 봤어요. 배우들 연기가 최고!\n",
      "분석 결과: [{'label': 'POSITIVE', 'score': 0.9532296657562256}]\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face의 transformers 라이브러리 활용\n",
    "from transformers import pipeline\n",
    "\n",
    "# 감성 분석 파이프라인 로드 (sentiment-analysis는 \"작업 유형\"을 지정하는 것)\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")  # Task : sentiment-analysis\n",
    "\n",
    "review = \"이 영화는 정말 시간 가는 줄 모르고 봤어요. 배우들 연기가 최고!\"\n",
    "\n",
    "result = sentiment_analyzer(review)\n",
    "\n",
    "print('\\n✅ 감성 분석(Sentiment Analysis) 결과')\n",
    "print(f\"리뷰: {review}\")\n",
    "print(f\"분석 결과: {result}\") # [{'label': 'POSITIVE', 'score': 0.99...}]\n",
    "\n",
    "# 핵심 구문 추출은 별도의 모델이나 기법이 필요\n",
    "# 예시: \"배우들 연기\", \"시간 가는 줄\" 등을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JCRrWclPL0j"
   },
   "source": [
    "### **(AI모델 구성파일) 다운로드 진행바 On/Off**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Qqyjc1kL_iHN"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "# 1. 원래 init을 백업\n",
    "tqdm_init_backup = tqdm.tqdm.__init__\n",
    "\n",
    "# # 2. 진행바 끄기\n",
    "# tqdm.tqdm.__init__ = lambda *args, **kwargs: None\n",
    "\n",
    "# 3. 다시 켜기 (복원)\n",
    "tqdm.tqdm.__init__ = tqdm_init_backup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xf0z5da-_a"
   },
   "source": [
    "- **(AI모델 구성파일) 파일 구성 예:(Task마다 다를 수 있다)**\n",
    "|파일 이름\t|비유|\t핵심 역할|\n",
    "|---|---|---|\n",
    "|model.safetensors\t|🧠 AI의 뇌 (엔진)|\t모델의 학습된 가중치(weights), 즉 실질적인 지능이 담긴 가장 핵심적인 파일입니다.|\n",
    "|config.json|\t📜 AI의 설계도|\t모델의 구조(몇 개의 층, 어떤 종류의 모델 등)가 정의된 설정 파일입니다.|\n",
    "|vocab.txt\t|📖 AI의 단어 사전|\t모델이 이해할 수 있는 단어(토큰)와 그에 해당하는 고유 번호 목록입니다.|\n",
    "|tokenizer_config.json\t|📝 사전 사용 설명서\t|단어 사전을 어떤 규칙(소문자화 여부, 특수 토큰 등)으로 사용할지 정의한 파일입니다.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuGMeNFNgqZZ"
   },
   "source": [
    "- **(AI모델 구성파일) 다운로드된 파일 위치(캐시파일) : 코랩**\n",
    "    - /root/.cache/huggingface/hub ~ /snapshots/...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QVputcVhgrFd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /root/.cache/huggingface/hub/: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# 캐시 폴더에 어떤 모델들이 저장되어 있는지 목록을 봅니다.\n",
    "!ls /root/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNcbyi4arCWH"
   },
   "source": [
    "### **모델 직접 지정하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3RBxHyjAq9Hb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 감성 분석(Sentiment Analysis) 결과\n",
      "                   text sentiment  confidence\n",
      "0   이 제품 정말 좋아요! 추천합니다.   5 stars    0.718316\n",
      "1  배송이 너무 늦었어요. 실망스럽네요.    1 star    0.425818\n",
      "2     가격 대비 괜찮은 것 같습니다.   3 stars    0.556177\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# 감정 분석 파이프라인 초기화\n",
    "#   model=<업로더이름>/<모델이름>\n",
    "#       nlptown → 모델을 공개한 Hugging Face 사용자(혹은 조직) 계정명\n",
    "#       bert-base-multilingual-uncased-sentiment → 모델의 이름\n",
    "#           BERT 기반\n",
    "#           다국어 지원\n",
    "#           대소문자 구분하지 않음 (uncased)\n",
    "#           감성 분석용으로 학습된 모델\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\",\n",
    "                             model=\"nlptown/bert-base-multilingual-uncased-sentiment\" )\n",
    "\n",
    "\n",
    "# 샘플 리뷰 데이터\n",
    "reviews = [\n",
    "    \"이 제품 정말 좋아요! 추천합니다.\",\n",
    "    \"배송이 너무 늦었어요. 실망스럽네요.\",\n",
    "    \"가격 대비 괜찮은 것 같습니다.\"\n",
    "]\n",
    "\n",
    "# 감정 분석 수행\n",
    "results = []\n",
    "for review in reviews:\n",
    "    result = sentiment_analyzer(review)\n",
    "    results.append({\n",
    "        'text': review,\n",
    "        'sentiment': result[0]['label'],\n",
    "        'confidence': result[0]['score']\n",
    "    })\n",
    "\n",
    "# 결과 출력\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print('\\n✅ 감성 분석(Sentiment Analysis) 결과')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDcR5MBOaN_l"
   },
   "source": [
    "- **Task별 기본모델 참고** : 버전별로 다를 수 있음\n",
    "\n",
    "|태스크 이름|기본 모델 예시 (지정하지 않을 때)|\n",
    "|---|---|\n",
    "|text-generation | gpt2 |\n",
    "|text-classification / sentiment-analysis| distilbert-base-uncased-finetuned-sst-2-english |\n",
    "|fill-mask|bert-base-uncased|\n",
    "|ner / token-classification|dslim/bert-base-NER 또는 BERT 기반 NER 모델|\n",
    "|question-answering | distilbert-base-uncased-distilled-squad 또는 BERT 기반 QA 모델|\n",
    "|summarization | facebook/bart-large-cnn |\n",
    "|translation (예: translation_en_to_fr) | Helsinki-NLP/opus-mt-en-fr |\n",
    "|zero-shot-classification  |facebook/bart-large-mnli |\n",
    "|conversational | microsoft/DialoGPT-small 또는 Chat 모델 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXPJs5hxa_M3"
   },
   "source": [
    "## **예제: 문장 소설 이어 쓰기 (자연어 생성 - NLG)**\n",
    "- **목표**: 재미있는 소설의 첫 문장을 제시하면, AI가 그럴듯한 다음 문장들을 자동으로 생성해 하나의 짧은 이야기를 완성하는 프로그램\n",
    "- **핵심 기술**: 텍스트 생성(Text Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BITqxWoda_Tj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 텍스트 생성(Text Generation) 결과\n",
      "--- AI가 완성한 이야기 ---\n",
      "어느 날 아침, 잠에서 깨어보니 내 방에 코끼리가 있었다. 때명 이스 있는 방에 어느 날 아침로 어느 있었다.\n",
      "\n",
      "루아음 방에 어느 날 아침로 어느 있었다. 명지을 구춌리가 있었다. 아침로 어느 있었다.\n",
      "\n",
      "오드 아침로 어느 있었다. 명지을 구춌리가 있었다. 명지을 구춌리가 있었다.\n",
      "\n",
      "�\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '어느 날 아침, 잠에서 깨어보니 내 방에 코끼리가 있었다. 때명 이스 있는 방에 어느 날 아침로 어느 있었다.\\n\\n루아음 방에 어느 날 아침로 어느 있었다. 명지을 구춌리가 있었다. 아침로 어느 있었다.\\n\\n오드 아침로 어느 있었다. 명지을 구춌리가 있었다. 명지을 구춌리가 있었다.\\n\\n�'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hugging Face의 transformers 라이브러리 활용\n",
    "from transformers import pipeline\n",
    "\n",
    "# 텍스트 생성 파이프라인 로드 (예: GPT-2)\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "\n",
    "prompt = \"어느 날 아침, 잠에서 깨어보니 내 방에 코끼리가 있었다.\"\n",
    "\n",
    "story = text_generator(prompt,\n",
    "                       max_length=100,\n",
    "                       num_return_sequences=1)\n",
    "\n",
    "print('\\n✅ 텍스트 생성(Text Generation) 결과')\n",
    "print(\"--- AI가 완성한 이야기 ---\")\n",
    "print(story[0]['generated_text'])\n",
    "story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4z-C4ZcrXY1"
   },
   "source": [
    "## **예제 3: 텍스트 요약 (Text Summarization)**\n",
    "- **목표**: 긴 글(뉴스 기사, 논문, 보고서 등)을 AI를 이용해 핵심 내용만 담은 짧은 글로 자동 요약하는 프로그램\n",
    "- **핵심 기술**: 텍스트 요약 (Text Summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dQRCtJEzrXf_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 텍스트 요약 (Text Summarization) 결과\n",
      "원문 길이: 62\n",
      "요약문: Review of BERT, GPT, BERT and GPT-BERT systems. BERT:  PERT: 21    ‘‘  하’   ‘�\n",
      "요약문 길이: 14\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 요약 파이프라인 초기화\n",
    "summarizer = pipeline(\"summarization\",\n",
    "                     model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# 긴 텍스트 예시\n",
    "long_text = \"\"\"\n",
    "인공지능(AI)은 21세기 가장 중요한 기술 중 하나로 여겨지고 있습니다.\n",
    "특히 자연어 처리 분야에서는 BERT, GPT와 같은 대규모 언어 모델의 등장으로\n",
    "인해 기계가 인간 수준의 언어 이해와 생성 능력을 보여주고 있습니다.\n",
    "이러한 발전은 교육, 의료, 금융, 엔터테인먼트 등 다양한 분야에서\n",
    "혁신적인 변화를 가져오고 있으며, 앞으로도 계속해서 발전할 것으로\n",
    "예상됩니다. 하지만 동시에 윤리적 문제, 일자리 대체, 편향성 등의\n",
    "문제도 제기되고 있어 신중한 접근이 필요합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 요약 수행\n",
    "summary = summarizer(long_text,\n",
    "                    max_length=50,\n",
    "                    min_length=10,\n",
    "                    do_sample=False)\n",
    "\n",
    "print('\\n✅ 텍스트 요약 (Text Summarization) 결과')\n",
    "print(\"원문 길이:\", len(long_text.split()))\n",
    "print(\"요약문:\", summary[0]['summary_text'])\n",
    "print(\"요약문 길이:\", len(summary[0]['summary_text'].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFrxAVx8ywRu"
   },
   "source": [
    "## **예제 4: 제로샷 텍스트 분류 (ZeroShotClassification)**\n",
    "- **제로샷 텍스트 분류 (ZeroShotClassification)**\n",
    "    - 정의: 학습 데이터에 없는 새로운 라벨(카테고리)에 대해서도, 사전학습된 언어모델을 활용해 문장을 해당 라벨로 분류하는 방법\n",
    "    - 원리: 라벨을 “설명 문장(hypothesis)”으로 바꿔서, 자연어 추론(NLI, Natural Language Inference) 문제로 변환 후 모델이 참/거짓을 판단하도록 함.\n",
    "    - 예:\n",
    "        - 문장: \"이 영화는 정말 재밌었다\"\n",
    "        - 라벨 후보: [\"긍정\", \"부정\"]\n",
    "        - 변환 → \"이 문장은 긍정을 표현한다.\" (참/거짓 예측)\n",
    "    -\n",
    "- **목표**: 각 단어와 문장의 의미를 바탕으로 스스로 추론하여 가장 적절한 분류하는 프로그램\n",
    "- **핵심 기술**: 제로샷 분류(ZeroShotClassification)--> 자연어 추론 (NLI, Natural Language Inference)\n",
    "    - NLI 모델은 두 문장(전제, 가설)을 보고 그 관계가 '참(Entailment)', '모순(Contradiction)', '중립(Neutral)' 중 무엇인지 판단하도록 훈련됨\n",
    "    - 각 단어와 문장의 의미를 바탕으로 스스로 추론하여 가장 적절한 분류 진행\n",
    "- **입력** :\n",
    "    - 분류할 문장\n",
    "    - 후보 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HBMhCBJUy5n9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 제로샷 분류 (Zero-Shot Classification) 결과\n",
      "{'sequence': '내일 주주총회에서는 차기 CED 선임 안건이 논의될 예정이다.', 'labels': ['정치', '연예', '경제', '스포츠', 'IT'], 'scores': [0.3559017479419708, 0.25379055738449097, 0.21660219132900238, 0.13524654507637024, 0.0384589321911335]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 제로샷 분류 파이프라인 생성\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# 분류할 문장\n",
    "sequence_to_classify = \"내일 주주총회에서는 차기 CED 선임 안건이 논의될 예정이다.\"\n",
    "\n",
    "# 후보 라벨 (미리 학습시킬 필요 없이, 그냥 원하는 라벨을 나열)\n",
    "candidate_labels = ['경제', '정치', 'IT', '스포츠', '연예']\n",
    "\n",
    "# 분류 실행\n",
    "result = classifier(sequence_to_classify, candidate_labels)\n",
    "\n",
    "# print 문의 설명을 '제로샷 분류'로 수정했습니다.\n",
    "print('\\n✅ 제로샷 분류 (Zero-Shot Classification) 결과')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.32.1\n"
     ]
    }
   ],
   "source": [
    "import google.protobuf\n",
    "print(google.protobuf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 파이썬: /usr/local/bin/python3\n",
      "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (6.32.1)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "print(\"현재 파이썬:\", sys.executable)\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"sentencepiece\", \"protobuf\", \"transformers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dW8TpnnFfT1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ mDeBERTa 결과\n",
      "{'sequence': '내일 주주총회에서는 차기 CEO 선임 안건이 논의될 예정이다.', 'labels': ['정치', '경제', 'IT', '스포츠', '연예'], 'scores': [0.5355885028839111, 0.17627373337745667, 0.14330951869487762, 0.0727677196264267, 0.07206055521965027]}\n",
      "\n",
      "✅ DeBERTa (영어 위주) 결과\n",
      "{'sequence': '내일 주주총회에서는 차기 CEO 선임 안건이 논의될 예정이다.', 'labels': ['IT', '경제', '정치', '연예', '스포츠'], 'scores': [0.28434714674949646, 0.24767960608005524, 0.20274610817432404, 0.1659708321094513, 0.09925622493028641]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. XLM-RoBERTa 기반 다국어 제로샷 분류\n",
    "# classifier_xlm = pipeline(\"zero-shot-classification\",\n",
    "                          # model=\"joeddav/xlm-roberta-large-xnli\")\n",
    "\n",
    "# 2. mDeBERTa-v3 기반 다국어 제로샷 분류\n",
    "classifier_mdeberta = pipeline(\"zero-shot-classification\",\n",
    "                               model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
    "\n",
    "# 3. DeBERTa-v3 기반 영어 전용 제로샷 분류\n",
    "classifier_deberta = pipeline(\"zero-shot-classification\",\n",
    "                              model=\"cross-encoder/nli-deberta-v3-base\")\n",
    "\n",
    "# 테스트 문장\n",
    "sequence = \"내일 주주총회에서는 차기 CEO 선임 안건이 논의될 예정이다.\"\n",
    "candidate_labels = [\"경제\", \"정치\", \"IT\", \"스포츠\", \"연예\"]\n",
    "\n",
    "# 실행 예시\n",
    "# print(\"✅ XLM-RoBERTa 결과\")\n",
    "# print(classifier_xlm(sequence, candidate_labels))\n",
    "\n",
    "print(\"\\n✅ mDeBERTa 결과\")\n",
    "print(classifier_mdeberta(sequence, candidate_labels))\n",
    "\n",
    "print(\"\\n✅ DeBERTa (영어 위주) 결과\")\n",
    "print(classifier_deberta(sequence, candidate_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUNj37MpB12F"
   },
   "source": [
    "- **[주의!]** 모델을 지정하지 않으면, 기본적으로 영어 데이터 위주로 훈련된 모델이 사용됨\n",
    "    - 해결 방법: 한국어 모델 + 한국어 가설 템플릿 사용\n",
    "        - (1) 한국어 성능이 검증된 모델 사용하고,\n",
    "        - (2) 가설 템플릿 또한 한국어로 명확하게 지정하여 모델이 온전히 한국어 환경에서만 추론하도록 함\n",
    "    - klue/roberta-large\n",
    "        - KLUE(Korean Language Understanding Evaluation) 벤치마크는 한국어 모델 성능의 표준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "YBE30a04B0nW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ KLUE 모델과 한국어 템플릿 적용 후 결과\n",
      "{'sequence': '내일 주주총회에서는 차기 임원 선임 안건이 논의될 예정이다.', 'labels': ['정치', 'IT', '스포츠', '경제', '연예'], 'scores': [0.20047549903392792, 0.20003601908683777, 0.19996817409992218, 0.19976912438869476, 0.19975115358829498]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. 한국어 성능이 검증된 KLUE 모델을 지정합니다.\n",
    "# classifier = pipeline(\"zero-shot-classification\",\n",
    "#                       model=\"klue/roberta-large\")\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"klue/roberta-large\")\n",
    "\n",
    "sequence = \"내일 주주총회에서는 차기 임원 선임 안건이 논의될 예정이다.\"\n",
    "labels = ['경제', '정치', 'IT', '스포츠', '연예']\n",
    "\n",
    "# 2. 모델이 추론할 가설의 형태를 한국어로 명확히 지정합니다.\n",
    "hypothesis_template = \"이것은 {} 카테고리의 뉴스이다.\"   # 이 내용은 {}과/와 관련이 있다.\n",
    "\n",
    "# 분류 실행 시 템플릿을 함께 전달합니다.\n",
    "result = classifier(sequence, labels, hypothesis_template=hypothesis_template)\n",
    "\n",
    "print('\\n✅ KLUE 모델과 한국어 템플릿 적용 후 결과')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkobzHPyewgk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05pJ1ow0GgWW"
   },
   "source": [
    "- [추가 정보] 모델과 템플릿 추천 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oUp5cPIgFDFU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 방법 1: 다양한 한국어 모델 테스트 ===\n",
      "\n",
      "📊 모델: klue/roberta-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "템플릿 1: 이 글의 주제는 {}에 관한 내용이다.\n",
      "1위: 정치 (0.2003)\n",
      "2위: 스포츠 (0.2002)\n",
      "--------------------------------------------------\n",
      "템플릿 2: 이 문장은 {} 분야에 관련된다.\n",
      "1위: 연예 (0.2004)\n",
      "2위: 스포츠 (0.2001)\n",
      "--------------------------------------------------\n",
      "템플릿 3: 이것은 {} 카테고리의 뉴스이다.\n",
      "1위: 정치 (0.2007)\n",
      "2위: 스포츠 (0.2007)\n",
      "--------------------------------------------------\n",
      "템플릿 4: 이 내용은 {}과/와 관련이 있다.\n",
      "1위: 연예 (0.2015)\n",
      "2위: IT (0.2003)\n",
      "--------------------------------------------------\n",
      "\n",
      "📊 모델: beomi/KcELECTRA-base\n",
      "모델 beomi/KcELECTRA-base 로드 오류: cannot import name 'SequenceSummary' from 'transformers.modeling_utils' (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/modeling_utils.py)\n",
      "\n",
      "📊 모델: monologg/kobert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "A new version of the following files was downloaded from https://huggingface.co/monologg/kobert:\n",
      "- tokenization_kobert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "템플릿 1: 이 글의 주제는 {}에 관한 내용이다.\n",
      "1위: 경제 (0.2019)\n",
      "2위: 스포츠 (0.2010)\n",
      "✅ 경제가 1위!\n",
      "--------------------------------------------------\n",
      "템플릿 2: 이 문장은 {} 분야에 관련된다.\n",
      "1위: 스포츠 (0.2020)\n",
      "2위: 경제 (0.2010)\n",
      "--------------------------------------------------\n",
      "템플릿 3: 이것은 {} 카테고리의 뉴스이다.\n",
      "1위: 경제 (0.2047)\n",
      "2위: IT (0.2009)\n",
      "✅ 경제가 1위!\n",
      "--------------------------------------------------\n",
      "템플릿 4: 이 내용은 {}과/와 관련이 있다.\n",
      "1위: 연예 (0.3070)\n",
      "2위: 경제 (0.1804)\n",
      "--------------------------------------------------\n",
      "\n",
      "📊 모델: xlm-roberta-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "템플릿 1: 이 글의 주제는 {}에 관한 내용이다.\n",
      "1위: 스포츠 (0.2005)\n",
      "2위: 연예 (0.2005)\n",
      "--------------------------------------------------\n",
      "템플릿 2: 이 문장은 {} 분야에 관련된다.\n",
      "1위: 연예 (0.2004)\n",
      "2위: 경제 (0.2002)\n",
      "--------------------------------------------------\n",
      "템플릿 3: 이것은 {} 카테고리의 뉴스이다.\n",
      "1위: 스포츠 (0.2006)\n",
      "2위: 연예 (0.2004)\n",
      "--------------------------------------------------\n",
      "템플릿 4: 이 내용은 {}과/와 관련이 있다.\n",
      "1위: 스포츠 (0.2004)\n",
      "2위: IT (0.2001)\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# 방법 1: 한국어 특화 모델들 시도\n",
    "print(\"=== 방법 1: 다양한 한국어 모델 테스트 ===\")\n",
    "\n",
    "models_to_try = [\n",
    "    \"klue/roberta-large\",\n",
    "    \"beomi/KcELECTRA-base\",\n",
    "    \"monologg/kobert\",\n",
    "    \"xlm-roberta-large\"  # 다국어 모델\n",
    "]\n",
    "\n",
    "sequence = \"내일 주주총회에서는 차기 임원 선임 안건이 논의될 예정이다.\"\n",
    "labels = ['경제', '정치', 'IT', '스포츠', '연예']\n",
    "\n",
    "# 더 명확한 한국어 템플릿들 시도\n",
    "templates_to_try = [\n",
    "    \"이 글의 주제는 {}에 관한 내용이다.\",\n",
    "    \"이 문장은 {} 분야에 관련된다.\",\n",
    "    \"이것은 {} 카테고리의 뉴스이다.\",\n",
    "    \"이 내용은 {}과/와 관련이 있다.\"\n",
    "]\n",
    "\n",
    "for model_name in models_to_try:\n",
    "    try:\n",
    "        print(f\"\\n📊 모델: {model_name}\")\n",
    "        classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "\n",
    "        for i, template in enumerate(templates_to_try):\n",
    "            try:\n",
    "                result = classifier(sequence, labels, hypothesis_template=template)\n",
    "                print(f\"템플릿 {i+1}: {template}\")\n",
    "                print(f\"1위: {result['labels'][0]} ({result['scores'][0]:.4f})\")\n",
    "                print(f\"2위: {result['labels'][1]} ({result['scores'][1]:.4f})\")\n",
    "\n",
    "                if result['labels'][0] == '경제':\n",
    "                    print(\"✅ 경제가 1위!\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"템플릿 {i+1} 오류: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"모델 {model_name} 로드 오류: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKx74EkxKULc"
   },
   "source": [
    "- [추가 정보] 정보 추가해서 키워드 기반 분류 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "F-FFcJJhJj6K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 키워드 기반 분류 결과:\n",
      "\n",
      "1. 문장: 내일 주주총회에서는 차기 CEO 선임 안건이 논의될 예정이다.\n",
      "   분류: 경제 (신뢰도: 1.000)\n",
      "   상세 결과:\n",
      "     1위: 경제 (1.000) [키워드: 주주총회, CEO, 선임]\n",
      "     2위: 정치 (0.000)\n",
      "     3위: IT (0.000)\n",
      "\n",
      "2. 문장: 국회에서 새로운 법안이 통과되었습니다.\n",
      "   분류: 정치 (신뢰도: 1.000)\n",
      "   상세 결과:\n",
      "     1위: 정치 (1.000) [키워드: 국회, 법안]\n",
      "     2위: 경제 (0.000)\n",
      "     3위: IT (0.000)\n",
      "\n",
      "3. 문장: 새로운 AI 기술이 개발되어 화제가 되고 있다.\n",
      "   분류: IT (신뢰도: 1.000)\n",
      "   상세 결과:\n",
      "     1위: IT (1.000) [키워드: AI, 기술, 개발]\n",
      "     2위: 경제 (0.000)\n",
      "     3위: 정치 (0.000)\n",
      "\n",
      "4. 문장: 프로야구 시즌이 시작되어 팬들의 관심이 집중되고 있다.\n",
      "   분류: 스포츠 (신뢰도: 1.000)\n",
      "   상세 결과:\n",
      "     1위: 스포츠 (1.000) [키워드: 프로야구]\n",
      "     2위: 경제 (0.000)\n",
      "     3위: 정치 (0.000)\n",
      "\n",
      "5. 문장: 인기 배우가 새로운 드라마에 출연한다고 발표했다.\n",
      "   분류: 연예 (신뢰도: 1.000)\n",
      "   상세 결과:\n",
      "     1위: 연예 (1.000) [키워드: 배우, 드라마]\n",
      "     2위: 경제 (0.000)\n",
      "     3위: 정치 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 방법 : 키워드 기반 분류 시스템 (가장 실용적)\n",
    "# =============================================================================\n",
    "\n",
    "class KoreanTextClassifier:\n",
    "    def __init__(self):\n",
    "        # 각 카테고리별 키워드 사전 정의\n",
    "        self.category_keywords = {\n",
    "            '경제': [\n",
    "                # 기업 관련\n",
    "                '주주총회', 'CEO', '선임', '임명', '사장', '회장', '경영진', '이사회',\n",
    "                '기업', '회사', '법인', '계열사', '자회사', '모회사',\n",
    "                # 금융 관련\n",
    "                '투자', '자금', '예산', '매출', '영업이익', '순이익', '손실', '적자', '흑자',\n",
    "                '주가', '주식', '상장', 'IPO', '증권', '거래소', '코스피', '코스닥',\n",
    "                '은행', '금융', '대출', '이자', '환율', '원화', '달러',\n",
    "                # 사업 관련\n",
    "                '사업', '업계', '시장', '산업', '제조', '생산', '공급', '판매', '유통',\n",
    "                '계약', '협약', 'MOU', '인수합병', 'M&A'\n",
    "            ],\n",
    "            '정치': [\n",
    "                '정부', '국회', '대통령', '총리', '장관', '정책', '법안', '개정안',\n",
    "                '선거', '투표', '후보', '정당', '의원', '국정감사', '정치',\n",
    "                '행정부', '입법부', '사법부', '지방자치', '시장', '도지사'\n",
    "            ],\n",
    "            'IT': [\n",
    "                '소프트웨어', '하드웨어', '프로그램', '앱', '어플리케이션',\n",
    "                '인공지능', 'AI', '머신러닝', '딥러닝', '빅데이터', '데이터',\n",
    "                '컴퓨터', '서버', '클라우드', '네트워크', '인터넷', '웹',\n",
    "                '스마트폰', '태블릿', '기술', '개발', '프로그래밍', '코딩'\n",
    "            ],\n",
    "            '스포츠': [\n",
    "                '경기', '시합', '경쟁', '선수', '팀', '클럽', '감독', '코치',\n",
    "                '득점', '골', '승리', '패배', '우승', '준우승', '리그', '토너먼트',\n",
    "                '올림픽', '월드컵', '아시안게임', '프로야구', '축구', '농구', '배구'\n",
    "            ],\n",
    "            '연예': [\n",
    "                '배우', '가수', '연예인', '아이돌', '스타', '셀러브리티',\n",
    "                '드라마', '영화', '예능', '방송', 'TV', '라디오',\n",
    "                '콘서트', '공연', '무대', '앨범', '싱글', '뮤직비디오',\n",
    "                '엔터테인먼트', '기획사', '데뷔', '컴백'\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def classify_text(self, text, threshold=0.1):\n",
    "        \"\"\"텍스트 분류 실행\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        # 각 카테고리별 점수 계산\n",
    "        for category, keywords in self.category_keywords.items():\n",
    "            score = 0\n",
    "            matched_keywords = []\n",
    "\n",
    "            for keyword in keywords:\n",
    "                if keyword in text:\n",
    "                    # 키워드 길이에 따른 가중치 (긴 키워드일수록 더 정확)\n",
    "                    weight = len(keyword) / 10 + 1\n",
    "                    score += weight\n",
    "                    matched_keywords.append(keyword)\n",
    "\n",
    "            scores[category] = {\n",
    "                'score': score,\n",
    "                'matched_keywords': matched_keywords\n",
    "            }\n",
    "\n",
    "        # 점수 정규화\n",
    "        total_score = sum([s['score'] for s in scores.values()])\n",
    "\n",
    "        if total_score > 0:\n",
    "            for category in scores:\n",
    "                scores[category]['normalized_score'] = scores[category]['score'] / total_score\n",
    "        else:\n",
    "            # 키워드 매치가 없으면 균등 분배\n",
    "            for category in scores:\n",
    "                scores[category]['normalized_score'] = 1 / len(scores)\n",
    "\n",
    "        # 결과 정렬\n",
    "        sorted_categories = sorted(scores.items(),\n",
    "                                 key=lambda x: x[1]['normalized_score'],\n",
    "                                 reverse=True)\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'results': sorted_categories,\n",
    "            'top_category': sorted_categories[0][0],\n",
    "            'confidence': sorted_categories[0][1]['normalized_score']\n",
    "        }\n",
    "\n",
    "# 분류기 생성 및 테스트\n",
    "classifier = KoreanTextClassifier()\n",
    "\n",
    "# 테스트 문장들\n",
    "test_sentences = [\n",
    "    \"내일 주주총회에서는 차기 CEO 선임 안건이 논의될 예정이다.\",\n",
    "    \"국회에서 새로운 법안이 통과되었습니다.\",\n",
    "    \"새로운 AI 기술이 개발되어 화제가 되고 있다.\",\n",
    "    \"프로야구 시즌이 시작되어 팬들의 관심이 집중되고 있다.\",\n",
    "    \"인기 배우가 새로운 드라마에 출연한다고 발표했다.\"\n",
    "]\n",
    "\n",
    "print(\"\\n✅ 키워드 기반 분류 결과:\")\n",
    "for i, sentence in enumerate(test_sentences, 1):\n",
    "    result = classifier.classify_text(sentence)\n",
    "    print(f\"\\n{i}. 문장: {sentence}\")\n",
    "    print(f\"   분류: {result['top_category']} (신뢰도: {result['confidence']:.3f})\")\n",
    "\n",
    "\n",
    "    # 상위 3개 결과와 매칭된 키워드 보여주기\n",
    "    print(\"   상세 결과:\")\n",
    "    for rank, (category, info) in enumerate(result['results'][:3], 1):\n",
    "        keywords_str = ', '.join(info['matched_keywords'][:3])\n",
    "        if keywords_str:\n",
    "            keywords_str = f\" [키워드: {keywords_str}]\"\n",
    "        print(f\"     {rank}위: {category} ({info['normalized_score']:.3f}){keywords_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g36MizoMox8"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPq2rKGIxmZaqbRnbWxMLLQ",
   "gpuType": "A100",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
