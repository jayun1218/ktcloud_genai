{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAPO58qbDYi8"
   },
   "source": [
    "# **ì–¸ì–´ AI ì´í•´**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAmo5uhXQ46c"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHIcfXn8RArA"
   },
   "source": [
    "- ğŸ’¡ **NOTE**\n",
    "    - ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
    "    - **T4 GPU : 16GB VRAM**\n",
    "\n",
    "- ğŸ’¡**ì½”ë“œ ë‚´ìš©**\n",
    "    - ì–¸ì–´ AIì˜ ì´í•´ë¥¼ ë•ëŠ” ì½”ë“œ\n",
    "    - 2000ë…„ëŒ€ ì´ì „ì˜ ìì—°ì–´ ì²˜ë¦¬(NLP) ê³¼ì • ì´í•´ë¥¼ ë•ëŠ” ì˜ˆì œë¡œ êµ¬ì„±í•¨\n",
    "    - ì–´ë–¤ ëª¨ë¸ì€ ì‹¤í–‰ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ.(ì½”ë©ì—ì„œëŠ” RAMì„ ëª¨ë‘ ì‚¬ìš© í›„ ì„¸ì…˜ì´ ë‹¤ìš´ ë  ìˆ˜ ìˆìŒ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-OX9xcYMp_f"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TCZmmIJs4D-"
   },
   "source": [
    "# **[Quicktour] transformersë¡œ í™•ì¸í•˜ëŠ” ì–¸ì–´ AIì˜ ê¸°ëŠ¥ ì˜ˆ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSl3zLaYboW6"
   },
   "source": [
    "- **Hugging Face**\n",
    "    - Hugging FaceëŠ” AI ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ê³µìœ Â·í™œìš©í•  ìˆ˜ ìˆëŠ” ëŒ€í‘œì ì¸ ì˜¤í”ˆì†ŒìŠ¤ í”Œë«í¼, ì»¤ë®¤ë‹ˆí‹°\n",
    "        - **ëª¨ë¸ í—ˆë¸Œ(Model Hub)** : ìˆ˜ë§Œ ê°œì˜ ê³µê°œëœ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ëˆ„êµ¬ë‚˜ ë‹¤ìš´ë¡œë“œÂ·í™œìš© ê°€ëŠ¥\n",
    "        - **ë°ì´í„°ì…‹ í—ˆë¸Œ(Datasets)** : ë‹¤ì–‘í•œ í‘œì¤€/ë¹„í‘œì¤€ ë°ì´í„°ì…‹ì„ ê°„í¸í•˜ê²Œ ë¶ˆëŸ¬ì™€ ì‹¤í—˜ ê°€ëŠ¥\n",
    "        - **Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬** : BERT, GPT, T5, LLaMA ë“± ìµœì‹  NLPÂ·ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ì†ì‰½ê²Œ ì‚¬ìš© ê°€ëŠ¥\n",
    "        - **PEFT/Accelerate ë“± ë„êµ¬** : íŒŒì¸íŠœë‹Â·ë¶„ì‚° í•™ìŠµÂ·ìµœì í™” ì§€ì›\n",
    "        - **ì»¤ë®¤ë‹ˆí‹°**: ì—°êµ¬ìÂ·ê°œë°œìê°€ ëª¨ë¸ê³¼ ì½”ë“œë¥¼ ê³µìœ í•˜ê³  í˜‘ì—…í•  ìˆ˜ ìˆëŠ” ìƒíƒœê³„\n",
    "\n",
    "- **transformers**\n",
    "    - transformers library https://huggingface.co/docs/transformers/index\n",
    "    - Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ì‚¬ì „ í›ˆë ¨ëœ AI ëª¨ë¸ë“¤ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "    - ë³µì¡í•œ AI ëª¨ë¸ì„ ê°„ë‹¨í•œ ì½”ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„êµ¬\n",
    "\n",
    "- **pipeline**\n",
    "    - https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
    "    - pipelineì€ ìì—°ì–´ ì²˜ë¦¬(NLP)Â·ë¹„ì „Â·ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ AI íƒœìŠ¤í¬ë¥¼ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë¯¸ë¦¬ êµ¬ì„±ëœ ì¶”ë¡ (ì‹¤í–‰) ë„êµ¬\n",
    "    - íƒœìŠ¤í¬ ì´ë¦„(ì˜ˆ: \"sentiment-analysis\", \"translation\")ì„ ì…ë ¥í•˜ë©´,ìë™ìœ¼ë¡œ ì í•©í•œ ëª¨ë¸ + í† í¬ë‚˜ì´ì € + ì „/í›„ì²˜ë¦¬ ë¡œì§ì„ ë¶ˆëŸ¬ì™€,ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€/ì˜¤ë””ì˜¤ë¥¼ ë°”ë¡œ ë„£ì–´ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆê²Œ í•¨\n",
    "\n",
    "    - **pipeline(sentiment-analysis)**\n",
    "        - Hugging Face Pipelines Documentation :  \n",
    "        - í…ìŠ¤íŠ¸ì˜ ê°ì •(ê¸ì •/ë¶€ì •) ë¶„ì„ì— íŠ¹í™”ëœ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì˜ ì‘ì—…(task) ì´ë¦„\n",
    "        - ê°ì • ë¶„ì„ì— íŠ¹í™”ëœ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì‘ì—…(task) ì´ë¦„\n",
    "        - (AIëª¨ë¸ X) ë‚´ë¶€ì ìœ¼ë¡œ BERT, RoBERTa, DistilBERT ë“±ì˜ ì‹¤ì œ ì‹ ê²½ë§ ëª¨ë¸ì´ ë™ì‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLclNnCla-rt"
   },
   "source": [
    "## **ì˜ˆì œ: ë‚˜ë§Œì˜ ì˜í™” í‰ë¡  ë¶„ì„ê¸° (ìì—°ì–´ ì´í•´ - NLU)**\n",
    "- **ëª©í‘œ**: ì˜í™” ë¦¬ë·°ë¥¼ ì…ë ¥í•˜ë©´, í•´ë‹¹ ë¦¬ë·°ê°€ ê¸ì •ì ì¸ì§€ ë¶€ì •ì ì¸ì§€ë¥¼ ë§ì¶”ê³ , ë¦¬ë·°ì— ì–¸ê¸‰ëœ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë½‘ì•„ë‚´ëŠ” í”„ë¡œê·¸ë¨\n",
    "- **í•µì‹¬ ê¸°ìˆ **: ê°ì„± ë¶„ì„(Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.56.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nXxu78mQa-0C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê°ì„± ë¶„ì„(Sentiment Analysis) ê²°ê³¼\n",
      "ë¦¬ë·°: ì´ ì˜í™”ëŠ” ì •ë§ ì‹œê°„ ê°€ëŠ” ì¤„ ëª¨ë¥´ê³  ë´¤ì–´ìš”. ë°°ìš°ë“¤ ì—°ê¸°ê°€ ìµœê³ !\n",
      "ë¶„ì„ ê²°ê³¼: [{'label': 'POSITIVE', 'score': 0.9532296657562256}]\n"
     ]
    }
   ],
   "source": [
    "# Hugging Faceì˜ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
    "from transformers import pipeline\n",
    "\n",
    "# ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ ë¡œë“œ (sentiment-analysisëŠ” \"ì‘ì—… ìœ í˜•\"ì„ ì§€ì •í•˜ëŠ” ê²ƒ)\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")  # Task : sentiment-analysis\n",
    "\n",
    "review = \"ì´ ì˜í™”ëŠ” ì •ë§ ì‹œê°„ ê°€ëŠ” ì¤„ ëª¨ë¥´ê³  ë´¤ì–´ìš”. ë°°ìš°ë“¤ ì—°ê¸°ê°€ ìµœê³ !\"\n",
    "\n",
    "result = sentiment_analyzer(review)\n",
    "\n",
    "print('\\nâœ… ê°ì„± ë¶„ì„(Sentiment Analysis) ê²°ê³¼')\n",
    "print(f\"ë¦¬ë·°: {review}\")\n",
    "print(f\"ë¶„ì„ ê²°ê³¼: {result}\") # [{'label': 'POSITIVE', 'score': 0.99...}]\n",
    "\n",
    "# í•µì‹¬ êµ¬ë¬¸ ì¶”ì¶œì€ ë³„ë„ì˜ ëª¨ë¸ì´ë‚˜ ê¸°ë²•ì´ í•„ìš”\n",
    "# ì˜ˆì‹œ: \"ë°°ìš°ë“¤ ì—°ê¸°\", \"ì‹œê°„ ê°€ëŠ” ì¤„\" ë“±ì„ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JCRrWclPL0j"
   },
   "source": [
    "### **(AIëª¨ë¸ êµ¬ì„±íŒŒì¼) ë‹¤ìš´ë¡œë“œ ì§„í–‰ë°” On/Off**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Qqyjc1kL_iHN"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "# 1. ì›ë˜ initì„ ë°±ì—…\n",
    "tqdm_init_backup = tqdm.tqdm.__init__\n",
    "\n",
    "# # 2. ì§„í–‰ë°” ë„ê¸°\n",
    "# tqdm.tqdm.__init__ = lambda *args, **kwargs: None\n",
    "\n",
    "# 3. ë‹¤ì‹œ ì¼œê¸° (ë³µì›)\n",
    "tqdm.tqdm.__init__ = tqdm_init_backup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xf0z5da-_a"
   },
   "source": [
    "- **(AIëª¨ë¸ êµ¬ì„±íŒŒì¼) íŒŒì¼ êµ¬ì„± ì˜ˆ:(Taskë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤)**\n",
    "|íŒŒì¼ ì´ë¦„\t|ë¹„ìœ |\tí•µì‹¬ ì—­í• |\n",
    "|---|---|---|\n",
    "|model.safetensors\t|ğŸ§  AIì˜ ë‡Œ (ì—”ì§„)|\tëª¨ë¸ì˜ í•™ìŠµëœ ê°€ì¤‘ì¹˜(weights), ì¦‰ ì‹¤ì§ˆì ì¸ ì§€ëŠ¥ì´ ë‹´ê¸´ ê°€ì¥ í•µì‹¬ì ì¸ íŒŒì¼ì…ë‹ˆë‹¤.|\n",
    "|config.json|\tğŸ“œ AIì˜ ì„¤ê³„ë„|\tëª¨ë¸ì˜ êµ¬ì¡°(ëª‡ ê°œì˜ ì¸µ, ì–´ë–¤ ì¢…ë¥˜ì˜ ëª¨ë¸ ë“±)ê°€ ì •ì˜ëœ ì„¤ì • íŒŒì¼ì…ë‹ˆë‹¤.|\n",
    "|vocab.txt\t|ğŸ“– AIì˜ ë‹¨ì–´ ì‚¬ì „|\tëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë‹¨ì–´(í† í°)ì™€ ê·¸ì— í•´ë‹¹í•˜ëŠ” ê³ ìœ  ë²ˆí˜¸ ëª©ë¡ì…ë‹ˆë‹¤.|\n",
    "|tokenizer_config.json\t|ğŸ“ ì‚¬ì „ ì‚¬ìš© ì„¤ëª…ì„œ\t|ë‹¨ì–´ ì‚¬ì „ì„ ì–´ë–¤ ê·œì¹™(ì†Œë¬¸ìí™” ì—¬ë¶€, íŠ¹ìˆ˜ í† í° ë“±)ìœ¼ë¡œ ì‚¬ìš©í• ì§€ ì •ì˜í•œ íŒŒì¼ì…ë‹ˆë‹¤.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuGMeNFNgqZZ"
   },
   "source": [
    "- **(AIëª¨ë¸ êµ¬ì„±íŒŒì¼) ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ìœ„ì¹˜(ìºì‹œíŒŒì¼) : ì½”ë©**\n",
    "    - /root/.cache/huggingface/hub ~ /snapshots/...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QVputcVhgrFd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /root/.cache/huggingface/hub/: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# ìºì‹œ í´ë”ì— ì–´ë–¤ ëª¨ë¸ë“¤ì´ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ ëª©ë¡ì„ ë´…ë‹ˆë‹¤.\n",
    "!ls /root/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNcbyi4arCWH"
   },
   "source": [
    "### **ëª¨ë¸ ì§ì ‘ ì§€ì •í•˜ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3RBxHyjAq9Hb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê°ì„± ë¶„ì„(Sentiment Analysis) ê²°ê³¼\n",
      "                   text sentiment  confidence\n",
      "0   ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì¶”ì²œí•©ë‹ˆë‹¤.   5 stars    0.718316\n",
      "1  ë°°ì†¡ì´ ë„ˆë¬´ ëŠ¦ì—ˆì–´ìš”. ì‹¤ë§ìŠ¤ëŸ½ë„¤ìš”.    1 star    0.425818\n",
      "2     ê°€ê²© ëŒ€ë¹„ ê´œì°®ì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤.   3 stars    0.556177\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# ê°ì • ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
    "#   model=<ì—…ë¡œë”ì´ë¦„>/<ëª¨ë¸ì´ë¦„>\n",
    "#       nlptown â†’ ëª¨ë¸ì„ ê³µê°œí•œ Hugging Face ì‚¬ìš©ì(í˜¹ì€ ì¡°ì§) ê³„ì •ëª…\n",
    "#       bert-base-multilingual-uncased-sentiment â†’ ëª¨ë¸ì˜ ì´ë¦„\n",
    "#           BERT ê¸°ë°˜\n",
    "#           ë‹¤êµ­ì–´ ì§€ì›\n",
    "#           ëŒ€ì†Œë¬¸ì êµ¬ë¶„í•˜ì§€ ì•ŠìŒ (uncased)\n",
    "#           ê°ì„± ë¶„ì„ìš©ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\",\n",
    "                             model=\"nlptown/bert-base-multilingual-uncased-sentiment\" )\n",
    "\n",
    "\n",
    "# ìƒ˜í”Œ ë¦¬ë·° ë°ì´í„°\n",
    "reviews = [\n",
    "    \"ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì¶”ì²œí•©ë‹ˆë‹¤.\",\n",
    "    \"ë°°ì†¡ì´ ë„ˆë¬´ ëŠ¦ì—ˆì–´ìš”. ì‹¤ë§ìŠ¤ëŸ½ë„¤ìš”.\",\n",
    "    \"ê°€ê²© ëŒ€ë¹„ ê´œì°®ì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "results = []\n",
    "for review in reviews:\n",
    "    result = sentiment_analyzer(review)\n",
    "    results.append({\n",
    "        'text': review,\n",
    "        'sentiment': result[0]['label'],\n",
    "        'confidence': result[0]['score']\n",
    "    })\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print('\\nâœ… ê°ì„± ë¶„ì„(Sentiment Analysis) ê²°ê³¼')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDcR5MBOaN_l"
   },
   "source": [
    "- **Taskë³„ ê¸°ë³¸ëª¨ë¸ ì°¸ê³ ** : ë²„ì „ë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "|íƒœìŠ¤í¬ ì´ë¦„|ê¸°ë³¸ ëª¨ë¸ ì˜ˆì‹œ (ì§€ì •í•˜ì§€ ì•Šì„ ë•Œ)|\n",
    "|---|---|\n",
    "|text-generation | gpt2 |\n",
    "|text-classification / sentiment-analysis| distilbert-base-uncased-finetuned-sst-2-english |\n",
    "|fill-mask|bert-base-uncased|\n",
    "|ner / token-classification|dslim/bert-base-NER ë˜ëŠ” BERT ê¸°ë°˜ NER ëª¨ë¸|\n",
    "|question-answering | distilbert-base-uncased-distilled-squad ë˜ëŠ” BERT ê¸°ë°˜ QA ëª¨ë¸|\n",
    "|summarization | facebook/bart-large-cnn |\n",
    "|translation (ì˜ˆ: translation_en_to_fr) | Helsinki-NLP/opus-mt-en-fr |\n",
    "|zero-shot-classification  |facebook/bart-large-mnli |\n",
    "|conversational | microsoft/DialoGPT-small ë˜ëŠ” Chat ëª¨ë¸ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXPJs5hxa_M3"
   },
   "source": [
    "## **ì˜ˆì œ: ë¬¸ì¥ ì†Œì„¤ ì´ì–´ ì“°ê¸° (ìì—°ì–´ ìƒì„± - NLG)**\n",
    "- **ëª©í‘œ**: ì¬ë¯¸ìˆëŠ” ì†Œì„¤ì˜ ì²« ë¬¸ì¥ì„ ì œì‹œí•˜ë©´, AIê°€ ê·¸ëŸ´ë“¯í•œ ë‹¤ìŒ ë¬¸ì¥ë“¤ì„ ìë™ìœ¼ë¡œ ìƒì„±í•´ í•˜ë‚˜ì˜ ì§§ì€ ì´ì•¼ê¸°ë¥¼ ì™„ì„±í•˜ëŠ” í”„ë¡œê·¸ë¨\n",
    "- **í•µì‹¬ ê¸°ìˆ **: í…ìŠ¤íŠ¸ ìƒì„±(Text Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BITqxWoda_Tj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… í…ìŠ¤íŠ¸ ìƒì„±(Text Generation) ê²°ê³¼\n",
      "--- AIê°€ ì™„ì„±í•œ ì´ì•¼ê¸° ---\n",
      "ì–´ëŠ ë‚  ì•„ì¹¨, ì ì—ì„œ ê¹¨ì–´ë³´ë‹ˆ ë‚´ ë°©ì— ì½”ë¼ë¦¬ê°€ ìˆì—ˆë‹¤. ë•Œëª… ì´ìŠ¤ ìˆëŠ” ë°©ì— ì–´ëŠ ë‚  ì•„ì¹¨ë¡œ ì–´ëŠ ìˆì—ˆë‹¤.\n",
      "\n",
      "ë£¨ì•„ìŒ ë°©ì— ì–´ëŠ ë‚  ì•„ì¹¨ë¡œ ì–´ëŠ ìˆì—ˆë‹¤. ëª…ì§€ì„ êµ¬ì¶Œë¦¬ê°€ ìˆì—ˆë‹¤. ì•„ì¹¨ë¡œ ì–´ëŠ ìˆì—ˆë‹¤.\n",
      "\n",
      "ì˜¤ë“œ ì•„ì¹¨ë¡œ ì–´ëŠ ìˆì—ˆë‹¤. ëª…ì§€ì„ êµ¬ì¶Œë¦¬ê°€ ìˆì—ˆë‹¤. ëª…ì§€ì„ êµ¬ì¶Œë¦¬ê°€ ìˆì—ˆë‹¤.\n",
      "\n",
      "ï¿½\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ì–´ëŠ ë‚  ì•„ì¹¨, ì ì—ì„œ ê¹¨ì–´ë³´ë‹ˆ ë‚´ ë°©ì— ì½”ë¼ë¦¬ê°€ ìˆì—ˆë‹¤. ë•Œëª… ì´ìŠ¤ ìˆëŠ” ë°©ì— ì–´ëŠ ë‚  ì•„ì¹¨ë¡œ ì–´ëŠ ìˆì—ˆë‹¤.\\n\\në£¨ì•„ìŒ ë°©ì— ì–´ëŠ ë‚  ì•„ì¹¨ë¡œ ì–´ëŠ ìˆì—ˆë‹¤. ëª…ì§€ì„ êµ¬ì¶Œë¦¬ê°€ ìˆì—ˆë‹¤. ì•„ì¹¨ë¡œ ì–´ëŠ ìˆì—ˆë‹¤.\\n\\nì˜¤ë“œ ì•„ì¹¨ë¡œ ì–´ëŠ ìˆì—ˆë‹¤. ëª…ì§€ì„ êµ¬ì¶Œë¦¬ê°€ ìˆì—ˆë‹¤. ëª…ì§€ì„ êµ¬ì¶Œë¦¬ê°€ ìˆì—ˆë‹¤.\\n\\nï¿½'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hugging Faceì˜ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
    "from transformers import pipeline\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ (ì˜ˆ: GPT-2)\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "\n",
    "prompt = \"ì–´ëŠ ë‚  ì•„ì¹¨, ì ì—ì„œ ê¹¨ì–´ë³´ë‹ˆ ë‚´ ë°©ì— ì½”ë¼ë¦¬ê°€ ìˆì—ˆë‹¤.\"\n",
    "\n",
    "story = text_generator(prompt,\n",
    "                       max_length=100,\n",
    "                       num_return_sequences=1)\n",
    "\n",
    "print('\\nâœ… í…ìŠ¤íŠ¸ ìƒì„±(Text Generation) ê²°ê³¼')\n",
    "print(\"--- AIê°€ ì™„ì„±í•œ ì´ì•¼ê¸° ---\")\n",
    "print(story[0]['generated_text'])\n",
    "story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4z-C4ZcrXY1"
   },
   "source": [
    "## **ì˜ˆì œ 3: í…ìŠ¤íŠ¸ ìš”ì•½ (Text Summarization)**\n",
    "- **ëª©í‘œ**: ê¸´ ê¸€(ë‰´ìŠ¤ ê¸°ì‚¬, ë…¼ë¬¸, ë³´ê³ ì„œ ë“±)ì„ AIë¥¼ ì´ìš©í•´ í•µì‹¬ ë‚´ìš©ë§Œ ë‹´ì€ ì§§ì€ ê¸€ë¡œ ìë™ ìš”ì•½í•˜ëŠ” í”„ë¡œê·¸ë¨\n",
    "- **í•µì‹¬ ê¸°ìˆ **: í…ìŠ¤íŠ¸ ìš”ì•½ (Text Summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dQRCtJEzrXf_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… í…ìŠ¤íŠ¸ ìš”ì•½ (Text Summarization) ê²°ê³¼\n",
      "ì›ë¬¸ ê¸¸ì´: 62\n",
      "ìš”ì•½ë¬¸: Review of BERT, GPT, BERT and GPT-BERT systems. BERT:  PERT: 21   Â â€˜â€˜  í•˜â€™   â€˜ï¿½\n",
      "ìš”ì•½ë¬¸ ê¸¸ì´: 14\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# ìš”ì•½ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
    "summarizer = pipeline(\"summarization\",\n",
    "                     model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# ê¸´ í…ìŠ¤íŠ¸ ì˜ˆì‹œ\n",
    "long_text = \"\"\"\n",
    "ì¸ê³µì§€ëŠ¥(AI)ì€ 21ì„¸ê¸° ê°€ì¥ ì¤‘ìš”í•œ ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ ì—¬ê²¨ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "íŠ¹íˆ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œëŠ” BERT, GPTì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë“±ì¥ìœ¼ë¡œ\n",
    "ì¸í•´ ê¸°ê³„ê°€ ì¸ê°„ ìˆ˜ì¤€ì˜ ì–¸ì–´ ì´í•´ì™€ ìƒì„± ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "ì´ëŸ¬í•œ ë°œì „ì€ êµìœ¡, ì˜ë£Œ, ê¸ˆìœµ, ì—”í„°í…Œì¸ë¨¼íŠ¸ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ\n",
    "í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆìœ¼ë©°, ì•ìœ¼ë¡œë„ ê³„ì†í•´ì„œ ë°œì „í•  ê²ƒìœ¼ë¡œ\n",
    "ì˜ˆìƒë©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë™ì‹œì— ìœ¤ë¦¬ì  ë¬¸ì œ, ì¼ìë¦¬ ëŒ€ì²´, í¸í–¥ì„± ë“±ì˜\n",
    "ë¬¸ì œë„ ì œê¸°ë˜ê³  ìˆì–´ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "# ìš”ì•½ ìˆ˜í–‰\n",
    "summary = summarizer(long_text,\n",
    "                    max_length=50,\n",
    "                    min_length=10,\n",
    "                    do_sample=False)\n",
    "\n",
    "print('\\nâœ… í…ìŠ¤íŠ¸ ìš”ì•½ (Text Summarization) ê²°ê³¼')\n",
    "print(\"ì›ë¬¸ ê¸¸ì´:\", len(long_text.split()))\n",
    "print(\"ìš”ì•½ë¬¸:\", summary[0]['summary_text'])\n",
    "print(\"ìš”ì•½ë¬¸ ê¸¸ì´:\", len(summary[0]['summary_text'].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFrxAVx8ywRu"
   },
   "source": [
    "## **ì˜ˆì œ 4: ì œë¡œìƒ· í…ìŠ¤íŠ¸ ë¶„ë¥˜ (ZeroShotClassification)**\n",
    "- **ì œë¡œìƒ· í…ìŠ¤íŠ¸ ë¶„ë¥˜ (ZeroShotClassification)**\n",
    "    - ì •ì˜: í•™ìŠµ ë°ì´í„°ì— ì—†ëŠ” ìƒˆë¡œìš´ ë¼ë²¨(ì¹´í…Œê³ ë¦¬)ì— ëŒ€í•´ì„œë„, ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ëª¨ë¸ì„ í™œìš©í•´ ë¬¸ì¥ì„ í•´ë‹¹ ë¼ë²¨ë¡œ ë¶„ë¥˜í•˜ëŠ” ë°©ë²•\n",
    "    - ì›ë¦¬: ë¼ë²¨ì„ â€œì„¤ëª… ë¬¸ì¥(hypothesis)â€ìœ¼ë¡œ ë°”ê¿”ì„œ, ìì—°ì–´ ì¶”ë¡ (NLI, Natural Language Inference) ë¬¸ì œë¡œ ë³€í™˜ í›„ ëª¨ë¸ì´ ì°¸/ê±°ì§“ì„ íŒë‹¨í•˜ë„ë¡ í•¨.\n",
    "    - ì˜ˆ:\n",
    "        - ë¬¸ì¥: \"ì´ ì˜í™”ëŠ” ì •ë§ ì¬ë°Œì—ˆë‹¤\"\n",
    "        - ë¼ë²¨ í›„ë³´: [\"ê¸ì •\", \"ë¶€ì •\"]\n",
    "        - ë³€í™˜ â†’ \"ì´ ë¬¸ì¥ì€ ê¸ì •ì„ í‘œí˜„í•œë‹¤.\" (ì°¸/ê±°ì§“ ì˜ˆì¸¡)\n",
    "    -\n",
    "- **ëª©í‘œ**: ê° ë‹¨ì–´ì™€ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë¶„ë¥˜í•˜ëŠ” í”„ë¡œê·¸ë¨\n",
    "- **í•µì‹¬ ê¸°ìˆ **: ì œë¡œìƒ· ë¶„ë¥˜(ZeroShotClassification)--> ìì—°ì–´ ì¶”ë¡  (NLI, Natural Language Inference)\n",
    "    - NLI ëª¨ë¸ì€ ë‘ ë¬¸ì¥(ì „ì œ, ê°€ì„¤)ì„ ë³´ê³  ê·¸ ê´€ê³„ê°€ 'ì°¸(Entailment)', 'ëª¨ìˆœ(Contradiction)', 'ì¤‘ë¦½(Neutral)' ì¤‘ ë¬´ì—‡ì¸ì§€ íŒë‹¨í•˜ë„ë¡ í›ˆë ¨ë¨\n",
    "    - ê° ë‹¨ì–´ì™€ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë¶„ë¥˜ ì§„í–‰\n",
    "- **ì…ë ¥** :\n",
    "    - ë¶„ë¥˜í•  ë¬¸ì¥\n",
    "    - í›„ë³´ ë¼ë²¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HBMhCBJUy5n9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì œë¡œìƒ· ë¶„ë¥˜ (Zero-Shot Classification) ê²°ê³¼\n",
      "{'sequence': 'ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CED ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.', 'labels': ['ì •ì¹˜', 'ì—°ì˜ˆ', 'ê²½ì œ', 'ìŠ¤í¬ì¸ ', 'IT'], 'scores': [0.3559017479419708, 0.25379055738449097, 0.21660219132900238, 0.13524654507637024, 0.0384589321911335]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# ì œë¡œìƒ· ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# ë¶„ë¥˜í•  ë¬¸ì¥\n",
    "sequence_to_classify = \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CED ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\"\n",
    "\n",
    "# í›„ë³´ ë¼ë²¨ (ë¯¸ë¦¬ í•™ìŠµì‹œí‚¬ í•„ìš” ì—†ì´, ê·¸ëƒ¥ ì›í•˜ëŠ” ë¼ë²¨ì„ ë‚˜ì—´)\n",
    "candidate_labels = ['ê²½ì œ', 'ì •ì¹˜', 'IT', 'ìŠ¤í¬ì¸ ', 'ì—°ì˜ˆ']\n",
    "\n",
    "# ë¶„ë¥˜ ì‹¤í–‰\n",
    "result = classifier(sequence_to_classify, candidate_labels)\n",
    "\n",
    "# print ë¬¸ì˜ ì„¤ëª…ì„ 'ì œë¡œìƒ· ë¶„ë¥˜'ë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.\n",
    "print('\\nâœ… ì œë¡œìƒ· ë¶„ë¥˜ (Zero-Shot Classification) ê²°ê³¼')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.32.1\n"
     ]
    }
   ],
   "source": [
    "import google.protobuf\n",
    "print(google.protobuf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ íŒŒì´ì¬: /usr/local/bin/python3\n",
      "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (6.32.1)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "print(\"í˜„ì¬ íŒŒì´ì¬:\", sys.executable)\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"sentencepiece\", \"protobuf\", \"transformers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dW8TpnnFfT1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… mDeBERTa ê²°ê³¼\n",
      "{'sequence': 'ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CEO ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.', 'labels': ['ì •ì¹˜', 'ê²½ì œ', 'IT', 'ìŠ¤í¬ì¸ ', 'ì—°ì˜ˆ'], 'scores': [0.5355885028839111, 0.17627373337745667, 0.14330951869487762, 0.0727677196264267, 0.07206055521965027]}\n",
      "\n",
      "âœ… DeBERTa (ì˜ì–´ ìœ„ì£¼) ê²°ê³¼\n",
      "{'sequence': 'ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CEO ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.', 'labels': ['IT', 'ê²½ì œ', 'ì •ì¹˜', 'ì—°ì˜ˆ', 'ìŠ¤í¬ì¸ '], 'scores': [0.28434714674949646, 0.24767960608005524, 0.20274610817432404, 0.1659708321094513, 0.09925622493028641]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. XLM-RoBERTa ê¸°ë°˜ ë‹¤êµ­ì–´ ì œë¡œìƒ· ë¶„ë¥˜\n",
    "# classifier_xlm = pipeline(\"zero-shot-classification\",\n",
    "                          # model=\"joeddav/xlm-roberta-large-xnli\")\n",
    "\n",
    "# 2. mDeBERTa-v3 ê¸°ë°˜ ë‹¤êµ­ì–´ ì œë¡œìƒ· ë¶„ë¥˜\n",
    "classifier_mdeberta = pipeline(\"zero-shot-classification\",\n",
    "                               model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
    "\n",
    "# 3. DeBERTa-v3 ê¸°ë°˜ ì˜ì–´ ì „ìš© ì œë¡œìƒ· ë¶„ë¥˜\n",
    "classifier_deberta = pipeline(\"zero-shot-classification\",\n",
    "                              model=\"cross-encoder/nli-deberta-v3-base\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥\n",
    "sequence = \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CEO ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\"\n",
    "candidate_labels = [\"ê²½ì œ\", \"ì •ì¹˜\", \"IT\", \"ìŠ¤í¬ì¸ \", \"ì—°ì˜ˆ\"]\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "# print(\"âœ… XLM-RoBERTa ê²°ê³¼\")\n",
    "# print(classifier_xlm(sequence, candidate_labels))\n",
    "\n",
    "print(\"\\nâœ… mDeBERTa ê²°ê³¼\")\n",
    "print(classifier_mdeberta(sequence, candidate_labels))\n",
    "\n",
    "print(\"\\nâœ… DeBERTa (ì˜ì–´ ìœ„ì£¼) ê²°ê³¼\")\n",
    "print(classifier_deberta(sequence, candidate_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUNj37MpB12F"
   },
   "source": [
    "- **[ì£¼ì˜!]** ëª¨ë¸ì„ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´, ê¸°ë³¸ì ìœ¼ë¡œ ì˜ì–´ ë°ì´í„° ìœ„ì£¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ ì‚¬ìš©ë¨\n",
    "    - í•´ê²° ë°©ë²•: í•œêµ­ì–´ ëª¨ë¸ + í•œêµ­ì–´ ê°€ì„¤ í…œí”Œë¦¿ ì‚¬ìš©\n",
    "        - (1) í•œêµ­ì–´ ì„±ëŠ¥ì´ ê²€ì¦ëœ ëª¨ë¸ ì‚¬ìš©í•˜ê³ ,\n",
    "        - (2) ê°€ì„¤ í…œí”Œë¦¿ ë˜í•œ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ì§€ì •í•˜ì—¬ ëª¨ë¸ì´ ì˜¨ì „íˆ í•œêµ­ì–´ í™˜ê²½ì—ì„œë§Œ ì¶”ë¡ í•˜ë„ë¡ í•¨\n",
    "    - klue/roberta-large\n",
    "        - KLUE(Korean Language Understanding Evaluation) ë²¤ì¹˜ë§ˆí¬ëŠ” í•œêµ­ì–´ ëª¨ë¸ ì„±ëŠ¥ì˜ í‘œì¤€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "YBE30a04B0nW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… KLUE ëª¨ë¸ê³¼ í•œêµ­ì–´ í…œí”Œë¦¿ ì ìš© í›„ ê²°ê³¼\n",
      "{'sequence': 'ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° ì„ì› ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.', 'labels': ['ì •ì¹˜', 'IT', 'ìŠ¤í¬ì¸ ', 'ê²½ì œ', 'ì—°ì˜ˆ'], 'scores': [0.20047549903392792, 0.20003601908683777, 0.19996817409992218, 0.19976912438869476, 0.19975115358829498]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. í•œêµ­ì–´ ì„±ëŠ¥ì´ ê²€ì¦ëœ KLUE ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "# classifier = pipeline(\"zero-shot-classification\",\n",
    "#                       model=\"klue/roberta-large\")\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"klue/roberta-large\")\n",
    "\n",
    "sequence = \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° ì„ì› ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\"\n",
    "labels = ['ê²½ì œ', 'ì •ì¹˜', 'IT', 'ìŠ¤í¬ì¸ ', 'ì—°ì˜ˆ']\n",
    "\n",
    "# 2. ëª¨ë¸ì´ ì¶”ë¡ í•  ê°€ì„¤ì˜ í˜•íƒœë¥¼ í•œêµ­ì–´ë¡œ ëª…í™•íˆ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "hypothesis_template = \"ì´ê²ƒì€ {} ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ì´ë‹¤.\"   # ì´ ë‚´ìš©ì€ {}ê³¼/ì™€ ê´€ë ¨ì´ ìˆë‹¤.\n",
    "\n",
    "# ë¶„ë¥˜ ì‹¤í–‰ ì‹œ í…œí”Œë¦¿ì„ í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "result = classifier(sequence, labels, hypothesis_template=hypothesis_template)\n",
    "\n",
    "print('\\nâœ… KLUE ëª¨ë¸ê³¼ í•œêµ­ì–´ í…œí”Œë¦¿ ì ìš© í›„ ê²°ê³¼')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkobzHPyewgk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05pJ1ow0GgWW"
   },
   "source": [
    "- [ì¶”ê°€ ì •ë³´] ëª¨ë¸ê³¼ í…œí”Œë¦¿ ì¶”ì²œ ì˜ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oUp5cPIgFDFU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ë°©ë²• 1: ë‹¤ì–‘í•œ í•œêµ­ì–´ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ===\n",
      "\n",
      "ğŸ“Š ëª¨ë¸: klue/roberta-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…œí”Œë¦¿ 1: ì´ ê¸€ì˜ ì£¼ì œëŠ” {}ì— ê´€í•œ ë‚´ìš©ì´ë‹¤.\n",
      "1ìœ„: ì •ì¹˜ (0.2003)\n",
      "2ìœ„: ìŠ¤í¬ì¸  (0.2002)\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 2: ì´ ë¬¸ì¥ì€ {} ë¶„ì•¼ì— ê´€ë ¨ëœë‹¤.\n",
      "1ìœ„: ì—°ì˜ˆ (0.2004)\n",
      "2ìœ„: ìŠ¤í¬ì¸  (0.2001)\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 3: ì´ê²ƒì€ {} ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ì´ë‹¤.\n",
      "1ìœ„: ì •ì¹˜ (0.2007)\n",
      "2ìœ„: ìŠ¤í¬ì¸  (0.2007)\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 4: ì´ ë‚´ìš©ì€ {}ê³¼/ì™€ ê´€ë ¨ì´ ìˆë‹¤.\n",
      "1ìœ„: ì—°ì˜ˆ (0.2015)\n",
      "2ìœ„: IT (0.2003)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“Š ëª¨ë¸: beomi/KcELECTRA-base\n",
      "ëª¨ë¸ beomi/KcELECTRA-base ë¡œë“œ ì˜¤ë¥˜: cannot import name 'SequenceSummary' from 'transformers.modeling_utils' (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/modeling_utils.py)\n",
      "\n",
      "ğŸ“Š ëª¨ë¸: monologg/kobert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "A new version of the following files was downloaded from https://huggingface.co/monologg/kobert:\n",
      "- tokenization_kobert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…œí”Œë¦¿ 1: ì´ ê¸€ì˜ ì£¼ì œëŠ” {}ì— ê´€í•œ ë‚´ìš©ì´ë‹¤.\n",
      "1ìœ„: ê²½ì œ (0.2019)\n",
      "2ìœ„: ìŠ¤í¬ì¸  (0.2010)\n",
      "âœ… ê²½ì œê°€ 1ìœ„!\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 2: ì´ ë¬¸ì¥ì€ {} ë¶„ì•¼ì— ê´€ë ¨ëœë‹¤.\n",
      "1ìœ„: ìŠ¤í¬ì¸  (0.2020)\n",
      "2ìœ„: ê²½ì œ (0.2010)\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 3: ì´ê²ƒì€ {} ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ì´ë‹¤.\n",
      "1ìœ„: ê²½ì œ (0.2047)\n",
      "2ìœ„: IT (0.2009)\n",
      "âœ… ê²½ì œê°€ 1ìœ„!\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 4: ì´ ë‚´ìš©ì€ {}ê³¼/ì™€ ê´€ë ¨ì´ ìˆë‹¤.\n",
      "1ìœ„: ì—°ì˜ˆ (0.3070)\n",
      "2ìœ„: ê²½ì œ (0.1804)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“Š ëª¨ë¸: xlm-roberta-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…œí”Œë¦¿ 1: ì´ ê¸€ì˜ ì£¼ì œëŠ” {}ì— ê´€í•œ ë‚´ìš©ì´ë‹¤.\n",
      "1ìœ„: ìŠ¤í¬ì¸  (0.2005)\n",
      "2ìœ„: ì—°ì˜ˆ (0.2005)\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 2: ì´ ë¬¸ì¥ì€ {} ë¶„ì•¼ì— ê´€ë ¨ëœë‹¤.\n",
      "1ìœ„: ì—°ì˜ˆ (0.2004)\n",
      "2ìœ„: ê²½ì œ (0.2002)\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 3: ì´ê²ƒì€ {} ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ì´ë‹¤.\n",
      "1ìœ„: ìŠ¤í¬ì¸  (0.2006)\n",
      "2ìœ„: ì—°ì˜ˆ (0.2004)\n",
      "--------------------------------------------------\n",
      "í…œí”Œë¦¿ 4: ì´ ë‚´ìš©ì€ {}ê³¼/ì™€ ê´€ë ¨ì´ ìˆë‹¤.\n",
      "1ìœ„: ìŠ¤í¬ì¸  (0.2004)\n",
      "2ìœ„: IT (0.2001)\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# ë°©ë²• 1: í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ë“¤ ì‹œë„\n",
    "print(\"=== ë°©ë²• 1: ë‹¤ì–‘í•œ í•œêµ­ì–´ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ===\")\n",
    "\n",
    "models_to_try = [\n",
    "    \"klue/roberta-large\",\n",
    "    \"beomi/KcELECTRA-base\",\n",
    "    \"monologg/kobert\",\n",
    "    \"xlm-roberta-large\"  # ë‹¤êµ­ì–´ ëª¨ë¸\n",
    "]\n",
    "\n",
    "sequence = \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° ì„ì› ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\"\n",
    "labels = ['ê²½ì œ', 'ì •ì¹˜', 'IT', 'ìŠ¤í¬ì¸ ', 'ì—°ì˜ˆ']\n",
    "\n",
    "# ë” ëª…í™•í•œ í•œêµ­ì–´ í…œí”Œë¦¿ë“¤ ì‹œë„\n",
    "templates_to_try = [\n",
    "    \"ì´ ê¸€ì˜ ì£¼ì œëŠ” {}ì— ê´€í•œ ë‚´ìš©ì´ë‹¤.\",\n",
    "    \"ì´ ë¬¸ì¥ì€ {} ë¶„ì•¼ì— ê´€ë ¨ëœë‹¤.\",\n",
    "    \"ì´ê²ƒì€ {} ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ì´ë‹¤.\",\n",
    "    \"ì´ ë‚´ìš©ì€ {}ê³¼/ì™€ ê´€ë ¨ì´ ìˆë‹¤.\"\n",
    "]\n",
    "\n",
    "for model_name in models_to_try:\n",
    "    try:\n",
    "        print(f\"\\nğŸ“Š ëª¨ë¸: {model_name}\")\n",
    "        classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "\n",
    "        for i, template in enumerate(templates_to_try):\n",
    "            try:\n",
    "                result = classifier(sequence, labels, hypothesis_template=template)\n",
    "                print(f\"í…œí”Œë¦¿ {i+1}: {template}\")\n",
    "                print(f\"1ìœ„: {result['labels'][0]} ({result['scores'][0]:.4f})\")\n",
    "                print(f\"2ìœ„: {result['labels'][1]} ({result['scores'][1]:.4f})\")\n",
    "\n",
    "                if result['labels'][0] == 'ê²½ì œ':\n",
    "                    print(\"âœ… ê²½ì œê°€ 1ìœ„!\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"í…œí”Œë¦¿ {i+1} ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ëª¨ë¸ {model_name} ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKx74EkxKULc"
   },
   "source": [
    "- [ì¶”ê°€ ì •ë³´] ì •ë³´ ì¶”ê°€í•´ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "F-FFcJJhJj6K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ê²°ê³¼:\n",
      "\n",
      "1. ë¬¸ì¥: ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CEO ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\n",
      "   ë¶„ë¥˜: ê²½ì œ (ì‹ ë¢°ë„: 1.000)\n",
      "   ìƒì„¸ ê²°ê³¼:\n",
      "     1ìœ„: ê²½ì œ (1.000) [í‚¤ì›Œë“œ: ì£¼ì£¼ì´íšŒ, CEO, ì„ ì„]\n",
      "     2ìœ„: ì •ì¹˜ (0.000)\n",
      "     3ìœ„: IT (0.000)\n",
      "\n",
      "2. ë¬¸ì¥: êµ­íšŒì—ì„œ ìƒˆë¡œìš´ ë²•ì•ˆì´ í†µê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "   ë¶„ë¥˜: ì •ì¹˜ (ì‹ ë¢°ë„: 1.000)\n",
      "   ìƒì„¸ ê²°ê³¼:\n",
      "     1ìœ„: ì •ì¹˜ (1.000) [í‚¤ì›Œë“œ: êµ­íšŒ, ë²•ì•ˆ]\n",
      "     2ìœ„: ê²½ì œ (0.000)\n",
      "     3ìœ„: IT (0.000)\n",
      "\n",
      "3. ë¬¸ì¥: ìƒˆë¡œìš´ AI ê¸°ìˆ ì´ ê°œë°œë˜ì–´ í™”ì œê°€ ë˜ê³  ìˆë‹¤.\n",
      "   ë¶„ë¥˜: IT (ì‹ ë¢°ë„: 1.000)\n",
      "   ìƒì„¸ ê²°ê³¼:\n",
      "     1ìœ„: IT (1.000) [í‚¤ì›Œë“œ: AI, ê¸°ìˆ , ê°œë°œ]\n",
      "     2ìœ„: ê²½ì œ (0.000)\n",
      "     3ìœ„: ì •ì¹˜ (0.000)\n",
      "\n",
      "4. ë¬¸ì¥: í”„ë¡œì•¼êµ¬ ì‹œì¦Œì´ ì‹œì‘ë˜ì–´ íŒ¬ë“¤ì˜ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ê³  ìˆë‹¤.\n",
      "   ë¶„ë¥˜: ìŠ¤í¬ì¸  (ì‹ ë¢°ë„: 1.000)\n",
      "   ìƒì„¸ ê²°ê³¼:\n",
      "     1ìœ„: ìŠ¤í¬ì¸  (1.000) [í‚¤ì›Œë“œ: í”„ë¡œì•¼êµ¬]\n",
      "     2ìœ„: ê²½ì œ (0.000)\n",
      "     3ìœ„: ì •ì¹˜ (0.000)\n",
      "\n",
      "5. ë¬¸ì¥: ì¸ê¸° ë°°ìš°ê°€ ìƒˆë¡œìš´ ë“œë¼ë§ˆì— ì¶œì—°í•œë‹¤ê³  ë°œí‘œí–ˆë‹¤.\n",
      "   ë¶„ë¥˜: ì—°ì˜ˆ (ì‹ ë¢°ë„: 1.000)\n",
      "   ìƒì„¸ ê²°ê³¼:\n",
      "     1ìœ„: ì—°ì˜ˆ (1.000) [í‚¤ì›Œë“œ: ë°°ìš°, ë“œë¼ë§ˆ]\n",
      "     2ìœ„: ê²½ì œ (0.000)\n",
      "     3ìœ„: ì •ì¹˜ (0.000)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ë°©ë²• : í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ (ê°€ì¥ ì‹¤ìš©ì )\n",
    "# =============================================================================\n",
    "\n",
    "class KoreanTextClassifier:\n",
    "    def __init__(self):\n",
    "        # ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì‚¬ì „ ì •ì˜\n",
    "        self.category_keywords = {\n",
    "            'ê²½ì œ': [\n",
    "                # ê¸°ì—… ê´€ë ¨\n",
    "                'ì£¼ì£¼ì´íšŒ', 'CEO', 'ì„ ì„', 'ì„ëª…', 'ì‚¬ì¥', 'íšŒì¥', 'ê²½ì˜ì§„', 'ì´ì‚¬íšŒ',\n",
    "                'ê¸°ì—…', 'íšŒì‚¬', 'ë²•ì¸', 'ê³„ì—´ì‚¬', 'ìíšŒì‚¬', 'ëª¨íšŒì‚¬',\n",
    "                # ê¸ˆìœµ ê´€ë ¨\n",
    "                'íˆ¬ì', 'ìê¸ˆ', 'ì˜ˆì‚°', 'ë§¤ì¶œ', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ', 'ì†ì‹¤', 'ì ì', 'í‘ì',\n",
    "                'ì£¼ê°€', 'ì£¼ì‹', 'ìƒì¥', 'IPO', 'ì¦ê¶Œ', 'ê±°ë˜ì†Œ', 'ì½”ìŠ¤í”¼', 'ì½”ìŠ¤ë‹¥',\n",
    "                'ì€í–‰', 'ê¸ˆìœµ', 'ëŒ€ì¶œ', 'ì´ì', 'í™˜ìœ¨', 'ì›í™”', 'ë‹¬ëŸ¬',\n",
    "                # ì‚¬ì—… ê´€ë ¨\n",
    "                'ì‚¬ì—…', 'ì—…ê³„', 'ì‹œì¥', 'ì‚°ì—…', 'ì œì¡°', 'ìƒì‚°', 'ê³µê¸‰', 'íŒë§¤', 'ìœ í†µ',\n",
    "                'ê³„ì•½', 'í˜‘ì•½', 'MOU', 'ì¸ìˆ˜í•©ë³‘', 'M&A'\n",
    "            ],\n",
    "            'ì •ì¹˜': [\n",
    "                'ì •ë¶€', 'êµ­íšŒ', 'ëŒ€í†µë ¹', 'ì´ë¦¬', 'ì¥ê´€', 'ì •ì±…', 'ë²•ì•ˆ', 'ê°œì •ì•ˆ',\n",
    "                'ì„ ê±°', 'íˆ¬í‘œ', 'í›„ë³´', 'ì •ë‹¹', 'ì˜ì›', 'êµ­ì •ê°ì‚¬', 'ì •ì¹˜',\n",
    "                'í–‰ì •ë¶€', 'ì…ë²•ë¶€', 'ì‚¬ë²•ë¶€', 'ì§€ë°©ìì¹˜', 'ì‹œì¥', 'ë„ì§€ì‚¬'\n",
    "            ],\n",
    "            'IT': [\n",
    "                'ì†Œí”„íŠ¸ì›¨ì–´', 'í•˜ë“œì›¨ì–´', 'í”„ë¡œê·¸ë¨', 'ì•±', 'ì–´í”Œë¦¬ì¼€ì´ì…˜',\n",
    "                'ì¸ê³µì§€ëŠ¥', 'AI', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'ë¹…ë°ì´í„°', 'ë°ì´í„°',\n",
    "                'ì»´í“¨í„°', 'ì„œë²„', 'í´ë¼ìš°ë“œ', 'ë„¤íŠ¸ì›Œí¬', 'ì¸í„°ë„·', 'ì›¹',\n",
    "                'ìŠ¤ë§ˆíŠ¸í°', 'íƒœë¸”ë¦¿', 'ê¸°ìˆ ', 'ê°œë°œ', 'í”„ë¡œê·¸ë˜ë°', 'ì½”ë”©'\n",
    "            ],\n",
    "            'ìŠ¤í¬ì¸ ': [\n",
    "                'ê²½ê¸°', 'ì‹œí•©', 'ê²½ìŸ', 'ì„ ìˆ˜', 'íŒ€', 'í´ëŸ½', 'ê°ë…', 'ì½”ì¹˜',\n",
    "                'ë“ì ', 'ê³¨', 'ìŠ¹ë¦¬', 'íŒ¨ë°°', 'ìš°ìŠ¹', 'ì¤€ìš°ìŠ¹', 'ë¦¬ê·¸', 'í† ë„ˆë¨¼íŠ¸',\n",
    "                'ì˜¬ë¦¼í”½', 'ì›”ë“œì»µ', 'ì•„ì‹œì•ˆê²Œì„', 'í”„ë¡œì•¼êµ¬', 'ì¶•êµ¬', 'ë†êµ¬', 'ë°°êµ¬'\n",
    "            ],\n",
    "            'ì—°ì˜ˆ': [\n",
    "                'ë°°ìš°', 'ê°€ìˆ˜', 'ì—°ì˜ˆì¸', 'ì•„ì´ëŒ', 'ìŠ¤íƒ€', 'ì…€ëŸ¬ë¸Œë¦¬í‹°',\n",
    "                'ë“œë¼ë§ˆ', 'ì˜í™”', 'ì˜ˆëŠ¥', 'ë°©ì†¡', 'TV', 'ë¼ë””ì˜¤',\n",
    "                'ì½˜ì„œíŠ¸', 'ê³µì—°', 'ë¬´ëŒ€', 'ì•¨ë²”', 'ì‹±ê¸€', 'ë®¤ì§ë¹„ë””ì˜¤',\n",
    "                'ì—”í„°í…Œì¸ë¨¼íŠ¸', 'ê¸°íšì‚¬', 'ë°ë·”', 'ì»´ë°±'\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def classify_text(self, text, threshold=0.1):\n",
    "        \"\"\"í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‹¤í–‰\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°\n",
    "        for category, keywords in self.category_keywords.items():\n",
    "            score = 0\n",
    "            matched_keywords = []\n",
    "\n",
    "            for keyword in keywords:\n",
    "                if keyword in text:\n",
    "                    # í‚¤ì›Œë“œ ê¸¸ì´ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ (ê¸´ í‚¤ì›Œë“œì¼ìˆ˜ë¡ ë” ì •í™•)\n",
    "                    weight = len(keyword) / 10 + 1\n",
    "                    score += weight\n",
    "                    matched_keywords.append(keyword)\n",
    "\n",
    "            scores[category] = {\n",
    "                'score': score,\n",
    "                'matched_keywords': matched_keywords\n",
    "            }\n",
    "\n",
    "        # ì ìˆ˜ ì •ê·œí™”\n",
    "        total_score = sum([s['score'] for s in scores.values()])\n",
    "\n",
    "        if total_score > 0:\n",
    "            for category in scores:\n",
    "                scores[category]['normalized_score'] = scores[category]['score'] / total_score\n",
    "        else:\n",
    "            # í‚¤ì›Œë“œ ë§¤ì¹˜ê°€ ì—†ìœ¼ë©´ ê· ë“± ë¶„ë°°\n",
    "            for category in scores:\n",
    "                scores[category]['normalized_score'] = 1 / len(scores)\n",
    "\n",
    "        # ê²°ê³¼ ì •ë ¬\n",
    "        sorted_categories = sorted(scores.items(),\n",
    "                                 key=lambda x: x[1]['normalized_score'],\n",
    "                                 reverse=True)\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'results': sorted_categories,\n",
    "            'top_category': sorted_categories[0][0],\n",
    "            'confidence': sorted_categories[0][1]['normalized_score']\n",
    "        }\n",
    "\n",
    "# ë¶„ë¥˜ê¸° ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
    "classifier = KoreanTextClassifier()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤\n",
    "test_sentences = [\n",
    "    \"ë‚´ì¼ ì£¼ì£¼ì´íšŒì—ì„œëŠ” ì°¨ê¸° CEO ì„ ì„ ì•ˆê±´ì´ ë…¼ì˜ë  ì˜ˆì •ì´ë‹¤.\",\n",
    "    \"êµ­íšŒì—ì„œ ìƒˆë¡œìš´ ë²•ì•ˆì´ í†µê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ìƒˆë¡œìš´ AI ê¸°ìˆ ì´ ê°œë°œë˜ì–´ í™”ì œê°€ ë˜ê³  ìˆë‹¤.\",\n",
    "    \"í”„ë¡œì•¼êµ¬ ì‹œì¦Œì´ ì‹œì‘ë˜ì–´ íŒ¬ë“¤ì˜ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ê³  ìˆë‹¤.\",\n",
    "    \"ì¸ê¸° ë°°ìš°ê°€ ìƒˆë¡œìš´ ë“œë¼ë§ˆì— ì¶œì—°í•œë‹¤ê³  ë°œí‘œí–ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "print(\"\\nâœ… í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ê²°ê³¼:\")\n",
    "for i, sentence in enumerate(test_sentences, 1):\n",
    "    result = classifier.classify_text(sentence)\n",
    "    print(f\"\\n{i}. ë¬¸ì¥: {sentence}\")\n",
    "    print(f\"   ë¶„ë¥˜: {result['top_category']} (ì‹ ë¢°ë„: {result['confidence']:.3f})\")\n",
    "\n",
    "\n",
    "    # ìƒìœ„ 3ê°œ ê²°ê³¼ì™€ ë§¤ì¹­ëœ í‚¤ì›Œë“œ ë³´ì—¬ì£¼ê¸°\n",
    "    print(\"   ìƒì„¸ ê²°ê³¼:\")\n",
    "    for rank, (category, info) in enumerate(result['results'][:3], 1):\n",
    "        keywords_str = ', '.join(info['matched_keywords'][:3])\n",
    "        if keywords_str:\n",
    "            keywords_str = f\" [í‚¤ì›Œë“œ: {keywords_str}]\"\n",
    "        print(f\"     {rank}ìœ„: {category} ({info['normalized_score']:.3f}){keywords_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g36MizoMox8"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPq2rKGIxmZaqbRnbWxMLLQ",
   "gpuType": "A100",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
