{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAPO58qbDYi8"
   },
   "source": [
    "# **2010년대 이후 언어 AI흐름**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAmo5uhXQ46c"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHIcfXn8RArA"
   },
   "source": [
    "- 💡**코드 내용**\n",
    "    - 언어 AI의 2010년 이후의 대략적인 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-OX9xcYMp_f"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTlhVOfCa3jo"
   },
   "source": [
    "# **QuickTour**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TCZmmIJs4D-"
   },
   "source": [
    "## **예제 1: 딥러닝 이전의 방식 - 단어 빈도로 감성 분석하기 (TF-IDF)**\n",
    "\n",
    "- 2010년대 이전, 단어의 출현 빈도를 중요한 특징(Feature)으로 사용했던 고전적인 방식\n",
    "- scikit-learn 라이브러리를 사용\n",
    "- **TfidfVectorizer**를 사용해 사람이 직접 **'단어의 빈도수'라는 특징을 추출** -->  '특징 공학'의 예시\n",
    "- 딥러닝 모델처럼 단어의 의미나 문맥을 스스로 학습하는 것이 아니라 **통계에 기반**한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6S4m0IoMIgDJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 예제 1: 딥러닝 이전의 고전적인 감성 분석 -----------\n",
      "단어 사전: ['가는' '강력' '기대했는데' '너무' '다시는' '돈이' '모르고' '배우들' '볼래요' '봤네요' '스토리가' '시간'\n",
      " '실망했어요' '아까운' '연기도' '영화' '재미있어요' '정말' '지루해요' '최고' '추천합니다']\n",
      "TF-IDF 벡터 (첫 번째 문장): [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.42176478 0.         0.         0.         0.\n",
      "  0.         0.         0.42176478 0.3325242  0.42176478 0.42176478\n",
      "  0.         0.42176478 0.        ]]\n",
      "\n",
      "테스트 문장: '배우들 연기가 아쉬웠지만 스토리는 흥미로웠어요.'\n",
      "예측 결과: 긍정 😀\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# pip install scikit-learn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"----------- 예제 1: 딥러닝 이전의 고전적인 감성 분석 -----------\")\n",
    "\n",
    "# 훈련 데이터: 영화 리뷰와 긍정(1)/부정(0) 레이블\n",
    "train_text = [\n",
    "    \"이 영화 정말 재미있어요. 배우들 연기도 최고!\",\n",
    "    \"시간 가는 줄 모르고 봤네요. 강력 추천합니다.\",\n",
    "    \"기대했는데 너무 실망했어요. 스토리가 지루해요.\",\n",
    "    \"돈이 아까운 영화. 다시는 안 볼래요.\"\n",
    "]\n",
    "train_labels = [1, 1, 0, 0] # 1: 긍정, 0: 부정\n",
    "\n",
    "# 1. 특징 공학(Feature Engineering): TF-IDF로 문장을 숫자 벡터로 변환\n",
    "# TF-IDF: 단어의 중요도를 계산하는 통계적 방법\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train = tfidf_vectorizer.fit_transform(train_text)\n",
    "\n",
    "# 단어 사전과 변환된 벡터 확인\n",
    "print(\"단어 사전:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF 벡터 (첫 번째 문장):\", X_train[0].toarray())\n",
    "\n",
    "\n",
    "# 2. 모델 학습: 로지스틱 회귀 모델로 학습\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, train_labels)\n",
    "\n",
    "# 3. 새로운 데이터로 예측\n",
    "test_text = [\"배우들 연기가 아쉬웠지만 스토리는 흥미로웠어요.\"]\n",
    "X_test = tfidf_vectorizer.transform(test_text)\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print(f\"\\n테스트 문장: '{test_text[0]}'\")\n",
    "print(\"예측 결과:\", \"긍정 😀\" if prediction[0] == 1 else \"부정 😞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpepkUF0JGEz"
   },
   "source": [
    "## **예제 2: 단어의 의미를 벡터로! - 분산 표현 (Word2Vec)**\n",
    "\n",
    "- **gensim** : 문서 유사도 분석 등 여러 NLP 알고리즘을 구현한 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZPkLgNvJcXc"
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "geQkVMOBIgIq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------- 예제 2: Word2Vec으로 단어의 분산 표현 학습하기 -----------\n",
      "\n",
      "✅ Word2Vec 모델 학습 완료!\n",
      "\n",
      "✅ '왕'의 벡터 (일부): [-0.00713902  0.00124103 -0.00717672 -0.00224462  0.0037193 ]...\n",
      "\n",
      "✅ '왕'과 가장 유사한 단어: [('여왕', 0.17018884420394897), ('강하다', 0.15016479790210724), ('우아함', 0.13887980580329895), ('지배', 0.034764934331178665), ('여자', 0.004503019154071808), ('아름답다', -0.005896796938031912), ('권력', -0.027750343084335327), ('사랑', -0.028491010889410973), ('남자', -0.04461711272597313), ('지혜', -0.06900332868099213)]\n",
      "\n",
      "✅ '여왕' + '남자' - '여자' ≈ [('지배', 0.1776057779788971), ('지혜', 0.1415826678276062), ('아름답다', 0.12113002687692642), ('우아함', 0.10962973535060883), ('왕', 0.07128649204969406), ('사랑', 0.05836382880806923), ('힘', 0.026670295745134354), ('강하다', 0.024092452600598335), ('일', -0.06268469244241714), ('권력', -0.09019282460212708)]\n",
      "\n",
      "✅ '왕' - '남자' + '여자' ≈ [('여왕', 0.09298086166381836), ('강하다', 0.09050668030977249), ('권력', 0.0424610935151577), ('우아함', 0.00974997691810131), ('아름답다', -0.02259502001106739), ('일', -0.057878993451595306), ('지혜', -0.06410805881023407), ('지배', -0.07025597989559174), ('사랑', -0.07574485242366791), ('힘', -0.23598840832710266)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(\"\\n\\n----------- 예제 2: Word2Vec으로 단어의 분산 표현 학습하기 -----------\")\n",
    "\n",
    "# Word2Vec 학습을 위한 샘플 문장 (토크나이징 된 형태)\n",
    "sentences = [\n",
    "    ['왕', '남자', '강하다'],\n",
    "    ['여왕', '여자', '아름답다'],\n",
    "    ['남자', '힘', '일'],\n",
    "    ['여자', '지혜', '사랑'],\n",
    "    ['왕', '권력', '지배'],\n",
    "    ['여왕', '권력', '우아함']\n",
    "]\n",
    "\n",
    "# 1. Word2Vec 모델 학습 (분산 표현 학습)\n",
    "# vector_size: 단어를 표현할 벡터의 차원\n",
    "# window: 주변 단어를 몇 개까지 볼 것인지\n",
    "# min_count: 최소 등장 횟수\n",
    "# sg=1: Skip-Gram 방식 사용 (주변 단어 예측)\n",
    "model = Word2Vec(sentences, vector_size=100, window=2, min_count=1, sg=1)\n",
    "print(\"\\n✅ Word2Vec 모델 학습 완료!\")\n",
    "\n",
    "\n",
    "# 2. 학습된 단어 벡터 확인\n",
    "king_vector = model.wv['왕']\n",
    "print(f\"\\n✅ '왕'의 벡터 (일부): {king_vector[:5]}...\")\n",
    "\n",
    "\n",
    "# 3. 단어 간의 유사도 계산\n",
    "# '왕'과 가장 유사한 단어는 무엇일까요?\n",
    "similar_words = model.wv.most_similar('왕')\n",
    "print(\"\\n✅ '왕'과 가장 유사한 단어:\", similar_words)\n",
    "\n",
    "\n",
    "# 4. 재미있는 단어 산술 연산!\n",
    "# '왕' - '남자' + '여자' = ?\n",
    "try:\n",
    "    result = model.wv.most_similar(positive=['여왕', '남자'], negative=['여자'])\n",
    "    print(\"\\n✅ '여왕' + '남자' - '여자' ≈\", result)\n",
    "\n",
    "    result = model.wv.most_similar(positive=['왕', '여자'], negative=['남자'])\n",
    "    print(\"\\n✅ '왕' - '남자' + '여자' ≈\", result)\n",
    "except KeyError as e:\n",
    "    print(f\"\\n✅ 아쉽게도 '{e.args[0]}' 단어가 사전에 없어 계산할 수 없어요. 더 많은 데이터로 학습하면 가능해집니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SDkRMI_9MODY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- '여왕'이 반드시 정답으로 나오도록 강제 학습시킨 모델 -----------\n",
      "Word2Vec 모델 학습 완료!\n",
      "\n",
      "'왕' - '남자' + '여자' ≈ [('배우', 0.9614136815071106), ('여왕', 0.9587641358375549), ('배우자', 0.9567920565605164)]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# pip install gensim\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(\"----------- '여왕'이 반드시 정답으로 나오도록 강제 학습시킨 모델 -----------\")\n",
    "\n",
    "# 1. 데이터 재구성: 관계 강제 학습을 위한 초고반복/단순화 데이터\n",
    "# '남자'와 '여자'의 벡터 차이가 '성별'임을 명확히 암기시키기 위해\n",
    "# 동일한 구조의 문장을 여러 단어 쌍에 걸쳐 극단적으로 반복합니다.\n",
    "\n",
    "force_learning_sentences = [\n",
    "    # --- 핵심 평행 구조 (왕/여왕) 반복 ---\n",
    "    ['왕', '남자', '군주'],\n",
    "    ['여왕', '여자', '군주'],\n",
    "    ['왕', '남자', '왕족'],\n",
    "    ['여왕', '여자', '왕족'],\n",
    "    ['왕', '남자', '리더'],\n",
    "    ['여왕', '여자', '리더'],\n",
    "\n",
    "    # --- 다른 단어 쌍으로 동일한 구조 반복 (성별 관계 일반화) ---\n",
    "    ['왕자', '남자', '후계자'],\n",
    "    ['공주', '여자', '후계자'],\n",
    "    ['아버지', '남자', '부모'],\n",
    "    ['어머니', '여자', '부모'],\n",
    "    ['아들', '남자', '자식'],\n",
    "    ['딸', '여자', '자식'],\n",
    "    ['남편', '남자', '배우자'],\n",
    "    ['아내', '여자', '배우자'],\n",
    "    ['삼촌', '남자', '친척'],\n",
    "    ['이모', '여자', '친척'],\n",
    "    ['남배우', '남자', '배우'],\n",
    "    ['여배우', '여자', '배우'],\n",
    "\n",
    "    # --- 추가적인 문맥을 최소화하여 혼란 방지 ---\n",
    "    ['남자', '강인함'],\n",
    "    ['여자', '섬세함'],\n",
    "    ['왕', '권위'],\n",
    "    ['여왕', '품위']\n",
    "]\n",
    "\n",
    "\n",
    "# 2. 모델 학습 (epochs를 늘려 작은 데이터를 반복 학습)\n",
    "model = Word2Vec(\n",
    "    sentences=force_learning_sentences,\n",
    "    vector_size=50,     # 작은 데이터셋이므로 벡터 차원을 줄여 집중 학습\n",
    "    window=2,           # 주변 단어 범위\n",
    "    min_count=1,        # 최소 단어 빈도\n",
    "    sg=1,               # Skip-Gram 모델 사용\n",
    "    epochs=1000,         # !! 작은 데이터를 500번 반복 학습하여 관계를 각인시킴\n",
    "    seed=42             # 결과 재현을 위한 시드 값 고정\n",
    ")\n",
    "print(\"Word2Vec 모델 학습 완료!\")\n",
    "\n",
    "\n",
    "# 3. 결과 확인: '왕 - 남자 + 여자' 연산\n",
    "try:\n",
    "    # positive: 더할 벡터들, negative: 뺄 벡터\n",
    "    result = model.wv.most_similar(positive=['왕', '여자'], negative=['남자'], topn=3)\n",
    "    print(f\"\\n'왕' - '남자' + '여자' ≈ {result}\")\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"\\n계산에 필요한 단어 '{e.args[0]}'가 학습되지 않았습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swxXfWZNOpm1"
   },
   "source": [
    "## **예제 3: End-to-End 모델 수행하기**\n",
    "\n",
    "- 원본 텍스트를 입력하면 바로 결과가 나오는 End-to-End 모델\n",
    "- Hugging Face의 transformers 라이브러리를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ogYxl9SZIgSK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------- 예제 3: End-to-End 모델로 즉시 감성 분석하기 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문장: '이 강의는 정말 유익하고 미래에 큰 도움이 될 것 같아요!'\n",
      "결과: 부정 😞 (97.27% 확률)\n",
      "\n",
      "문장: '내용이 너무 어려워서 하나도 이해가 안돼요...'\n",
      "결과: 부정 😞 (95.91% 확률)\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# pip install transformers\n",
    "# pip install torch # 또는 tensorflow\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"\\n\\n----------- 예제 3: End-to-End 모델로 즉시 감성 분석하기 -----------\")\n",
    "\n",
    "# 1. 미리 학습된 End-to-End 모델 로드\n",
    "# Hugging Face 라이브러리는 수많은 최신 AI 모델을 몇 줄의 코드로 불러올 수 있게 해줍니다.\n",
    "# 모델이 알아서 토크나이징, 임베딩, 추론까지 모든 과정을 처리합니다.\n",
    "sentiment_analyzer = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model='matthewburke/korean_sentiment' # 한국어 감성 분석에 특화된 모델\n",
    ")\n",
    "\n",
    "# 2. 문장을 입력하고 바로 결과 확인\n",
    "text1 = \"이 강의는 정말 유익하고 미래에 큰 도움이 될 것 같아요!\"\n",
    "text2 = \"내용이 너무 어려워서 하나도 이해가 안돼요...\"\n",
    "\n",
    "results = sentiment_analyzer([text1, text2])\n",
    "\n",
    "# 3. 결과 출력\n",
    "for text, result in zip([text1, text2], results):\n",
    "    label = \"긍정 😀\" if result['label'] == 'positive' else \"부정 😞\"\n",
    "    score = result['score'] * 100\n",
    "    print(f\"\\n문장: '{text}'\")\n",
    "    print(f\"결과: {label} ({score:.2f}% 확률)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej3JWUxwIguu"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g36MizoMox8"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNkuxQaDMBt5"
   },
   "source": [
    "# **NLP 딥러닝 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vCdKDfUM9Lw"
   },
   "source": [
    "---\n",
    "- 💡 **NOTE**\n",
    "    - NLP(자연어처리) 발전과정에 기여한 딥러닝 모델 소개\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lS1P0kbZ_iU"
   },
   "source": [
    "## 딥러닝 모델의 발전\n",
    "- **핵심 과제**\n",
    "    -  **장거리 의존성 문제**(long-term dependency problem)와\n",
    "    - **병렬 처리의 한계를 해결**하는 방향으로 발전\n",
    "- **대표적인 아키텍처(매커니즘)**\n",
    "    - 2010년대 초반: **RNN** 기반 언어 모델 등장\n",
    "    - 2014년: **Seq2Seq** 모델 제안 (Sutskever et al., Google)\n",
    "    - 2015년: **Attention** 메커니즘 도입 (Bahdanau et al.)\n",
    "    - 2017년: **Transformer** 아키텍처 등장 (Vaswani et al., Google),  \"Attention is All You Need\" 논문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWII-JwZa7rJ"
   },
   "source": [
    "- **각 모델의 특징 비교**\n",
    "\n",
    "|구분|RNN|Seq2Seq|Attention|Transformer|\n",
    "|---|---|---|---|---|\n",
    "|등장 시기|2010년대 초|2014년|2015년|2017년|\n",
    "|핵심 아이디어|순차적 정보 처리|Encoder-Decoder 구조|중요한 부분에 집중|Self-Attention, 병렬 처리|\n",
    "|장거리 의존성|매우 약함 (기울기 소실)|약함 (고정 길이 벡터)|개선됨|매우 강함|\n",
    "|병렬 처리|불가능 (순차적)|불가능 (순차적)|부분적 가능|완전 병렬 처리|\n",
    "|계산 복잡도|O(n)|O(n)|O(n²) (Attention 계산)|O(n²) (Self-Attention)|\n",
    "|주요 문제점|기울기 소실/폭발|정보 병목 현상|여전히 순차적 처리|계산량 많음|\n",
    "|대표 논문|Elman(1990)|Sutskever(2014)|Bahdanau(2015)|Vaswani(2017)|\n",
    "|현재 사용|거의 사용 안 함|레거시 시스템|일부 특수 용도|주류(BERT, GPT 등)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPcm74RoEnQ2"
   },
   "source": [
    "## **RNN(Recurrent Neural Network)**\n",
    "- **메모리를 가진 신경망**\n",
    "-  마치 사람이 책을 읽을 때 앞 문장의 내용을 기억하면서 다음 문장을 이해하는 것과 유사\n",
    "- 역사적 배경\n",
    "    - 1986년: David Rumelhart가 순환 신경망 개념 제안\n",
    "    - 배경: 기존 피드포워드 신경망은 순서가 있는 데이터(시계열, 자연어)를 처리하기 어려웠음\n",
    "    - 혁신점: 시간적 의존성을 모델링할 수 있게 됨\n",
    "- 아키텍쳐 (참고: https://wikidocs.net/22886)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zl5uXcJ9QQ8-"
   },
   "source": [
    "![RNN](https://wikidocs.net/images/page/22886/rnn_image2_ver3.PNG \"RNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ovGt97LQSez"
   },
   "source": [
    "### 예제 : 스펨메일 분류기\n",
    "\n",
    "- **1.학습용 데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u90YliAPQRMp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 5572\n",
      "결측값 여부 : False\n",
      "v2열의 유니크한 값 : 5169\n",
      "총 샘플의 수 : 5169\n",
      "정상 메일과 스팸 메일의 개수\n",
      "   v1  count\n",
      "0   0   4516\n",
      "1   1    653\n",
      "------------------------------\n",
      "정상 메일의 비율 = 87.367%\n",
      "스팸 메일의 비율 = 12.633%\n",
      "메일 본문의 개수: 5169\n",
      "레이블의 개수: 5169\n",
      "--------훈련 데이터의 비율-----------\n",
      "정상 메일 = 87.376%\n",
      "스팸 메일 = 12.624%\n",
      "--------테스트 데이터의 비율-----------\n",
      "정상 메일 = 87.331%\n",
      "스팸 메일 = 12.669%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/crjnksy947ncy2v2lcqj29bh0000gn/T/ipykernel_16628/3913874534.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 스펨메일 데이터셋 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/spam.csv\", filename=\"spam.csv\")\n",
    "data = pd.read_csv('spam.csv', encoding='latin1')\n",
    "print('총 샘플의 수 :',len(data))\n",
    "\n",
    "# 불필요한 컬럼 삭제\n",
    "del data['Unnamed: 2']\n",
    "del data['Unnamed: 3']\n",
    "del data['Unnamed: 4']\n",
    "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\n",
    "\n",
    "\n",
    "# 데이터 확인\n",
    "print('결측값 여부 :',data.isnull().values.any())\n",
    "print('v2열의 유니크한 값 :',data['v2'].nunique())\n",
    "\n",
    "# v2 열에서 중복인 내용이 있다면 중복 제거\n",
    "data.drop_duplicates(subset=['v2'], inplace=True)\n",
    "print('총 샘플의 수 :',len(data))\n",
    "print('정상 메일과 스팸 메일의 개수')\n",
    "print(data.groupby('v1').size().reset_index(name='count'))\n",
    "print('-' * 30)\n",
    "print(f'정상 메일의 비율 = {round(data[\"v1\"].value_counts()[0]/len(data) * 100,3)}%')\n",
    "print(f'스팸 메일의 비율 = {round(data[\"v1\"].value_counts()[1]/len(data) * 100,3)}%')\n",
    "\n",
    "\n",
    "# 훈련 데이터 & 테스트 데이터 분리\n",
    "X_data = data['v2']\n",
    "y_data = data['v1']\n",
    "print('메일 본문의 개수: {}'.format(len(X_data)))\n",
    "print('레이블의 개수: {}'.format(len(y_data)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data,\n",
    "                                                    test_size=0.2, random_state=0, stratify=y_data)\n",
    "\n",
    "print('--------훈련 데이터의 비율-----------')\n",
    "print(f'정상 메일 = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
    "print(f'스팸 메일 = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
    "\n",
    "print('--------테스트 데이터의 비율-----------')\n",
    "print(f'정상 메일 = {round(y_test.value_counts()[0]/len(y_test) * 100,3)}%')\n",
    "print(f'스팸 메일 = {round(y_test.value_counts()[1]/len(y_test) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9uUxhOYBSlcr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메일의 토큰화 결과(5개):\n",
      " [[102, 1, 210, 230, 3, 17, 39], [1, 59, 8, 427, 17, 5, 137, 2, 2326], [157, 180, 12, 13, 98, 93, 47, 9, 40, 3485, 247, 8, 7, 87, 6, 80, 1312, 5, 3486, 7, 2327, 11, 660, 306, 20, 25, 467, 708, 1028, 203, 129, 193, 800, 2328, 23, 1, 144, 71, 2, 111, 78, 43, 2, 130, 11, 800, 186, 122, 1512], [1, 1154, 13, 104, 292], [222, 622, 857, 540, 623, 22, 23, 83, 10, 47, 6, 257, 32, 6, 26, 64, 936, 407]]\n",
      "\n",
      "토큰에 부여된 정수:\n",
      " {'i': 1, 'to': 2, 'you': 3, 'a': 4, 'the': 5, 'u': 6, 'and': 7, 'in': 8, 'is': 9, 'me': 10, 'my': 11, 'for': 12, 'your': 13, 'it': 14, 'of': 15, 'have': 16, 'on': 17, 'call': 18, 'that': 19, 'are': 20, '2': 21, 'now': 22, 'so': 23, 'but': 24, 'not': 25, 'can': 26, 'or': 27, \"i'm\": 28, 'get': 29, 'at': 30, 'do': 31, 'if': 32, 'be': 33, 'will': 34, 'just': 35, 'with': 36, 'we': 37, 'no': 38, 'this': 39, 'ur': 40, 'up': 41, '4': 42, 'how': 43, 'gt': 44, 'lt': 45, 'go': 46, 'when': 47, 'from': 48, 'what': 49, 'ok': 50, 'out': 51, 'know': 52, 'free': 53, 'all': 54, 'like': 55, 'then': 56, 'got': 57, 'good': 58, 'am': 59, 'time': 60, 'was': 61, 'come': 62, 'its': 63, 'love': 64, 'want': 65, 'text': 66, 'he': 67, 'only': 68, 'there': 69, 'day': 70, 'need': 71, 'going': 72, 'lor': 73, 'send': 74, 'one': 75, 'as': 76, 'home': 77, 'about': 78, 'back': 79, 'still': 80, 'k': 81, 'see': 82, 'txt': 83, 'by': 84, 'da': 85, 'stop': 86, 'r': 87, 'any': 88, 'tell': 89, 'dont': 90, \"i'll\": 91, \"don't\": 92, 'today': 93, 'our': 94, 'she': 95, 'please': 96, 'hi': 97, 'reply': 98, 'n': 99, 'take': 100, 'ì': 101, 'sorry': 102, 'her': 103, 'new': 104, 'oh': 105, 'mobile': 106, 'hey': 107, 'some': 108, 'they': 109, 'him': 110, 'think': 111, 'night': 112, 'here': 113, 'been': 114, 'great': 115, 'did': 116, 'phone': 117, 'much': 118, 'too': 119, 'hope': 120, 'week': 121, 'later': 122, 'more': 123, '1': 124, 'pls': 125, 'had': 126, 'well': 127, 'should': 128, 'has': 129, 'make': 130, 'where': 131, 'dear': 132, 'wat': 133, 'msg': 134, 'e': 135, 'claim': 136, 'way': 137, 'c': 138, 'already': 139, 'yes': 140, 'number': 141, 'say': 142, 'ask': 143, 'really': 144, 'yeah': 145, 'an': 146, 'right': 147, 'prize': 148, 'give': 149, \"it's\": 150, 'who': 151, 'meet': 152, 'doing': 153, 'www': 154, 'work': 155, 'after': 156, 'thanks': 157, 'would': 158, 'why': 159, 'b': 160, 'im': 161, 'life': 162, 'anything': 163, '3': 164, 'them': 165, 'cos': 166, 'happy': 167, 'message': 168, 'tomorrow': 169, 'something': 170, 'lol': 171, 'let': 172, 'sure': 173, 'every': 174, 'cash': 175, 'last': 176, 'babe': 177, 'said': 178, 'find': 179, 'again': 180, 'miss': 181, 'buy': 182, 'urgent': 183, \"i've\": 184, 'very': 185, 'money': 186, 'around': 187, 'keep': 188, 'over': 189, 'min': 190, 'next': 191, 'sent': 192, 'his': 193, 'before': 194, 'morning': 195, 'wait': 196, 'd': 197, 'com': 198, 'us': 199, 'first': 200, 'care': 201, 'tonight': 202, 'also': 203, 'thing': 204, 'off': 205, 'ìï': 206, 'someone': 207, '150p': 208, 't': 209, \"can't\": 210, 'could': 211, 'even': 212, 'were': 213, 'won': 214, 'sleep': 215, 'ya': 216, 'uk': 217, 'pick': 218, 'contact': 219, 'dun': 220, 's': 221, 'hello': 222, \"that's\": 223, 'win': 224, 'v': 225, 'chat': 226, 'late': 227, 'told': 228, 'amp': 229, 'help': 230, 'which': 231, 'down': 232, 'feel': 233, 'x': 234, 'soon': 235, 'cant': 236, 'nokia': 237, 'thk': 238, 'wan': 239, \"you're\": 240, 'done': 241, 'per': 242, 'getting': 243, 'many': 244, 'place': 245, 'leave': 246, 'coming': 247, 'always': 248, 'other': 249, 'nice': 250, 'waiting': 251, 'use': 252, 'haha': 253, 'friend': 254, 'gonna': 255, 'guaranteed': 256, 'finish': 257, 'wish': 258, 'went': 259, 'same': 260, 'best': 261, 'thought': 262, 'friends': 263, 'tone': 264, 'customer': 265, 'talk': 266, 'long': 267, 'gud': 268, 'try': 269, 'co': 270, 'year': 271, 'sms': 272, 'yet': 273, 'y': 274, '5': 275, 'end': 276, 'fine': 277, 'than': 278, 'mins': 279, 'stuff': 280, 'ready': 281, '50': 282, '18': 283, 'name': 284, 'cool': 285, 'service': 286, 'ill': 287, 'class': 288, 'job': 289, 'yo': 290, 'bit': 291, 'house': 292, 'wk': 293, 'lunch': 294, 'draw': 295, 'never': 296, 'lar': 297, '16': 298, 'smile': 299, \"didn't\": 300, 'man': 301, 'better': 302, 'line': 303, 'days': 304, 'trying': 305, 'things': 306, 'yup': 307, 'liao': 308, 'having': 309, 'problem': 310, 'few': 311, 'enjoy': 312, 'cs': 313, '6': 314, 'wanna': 315, 'might': 316, 'shopping': 317, 'people': 318, 'early': 319, 'real': 320, 'shows': 321, 'being': 322, 'dat': 323, 'may': 324, 'ah': 325, 'half': 326, 'den': 327, 'dinner': 328, 'person': 329, '7': 330, 'thanx': 331, 'car': 332, 'holiday': 333, 'thats': 334, 'ever': 335, 'account': 336, 'another': 337, 'aight': 338, 'guys': 339, 'jus': 340, 'because': 341, 'check': 342, 'word': 343, 'guess': 344, 'shall': 345, 'hear': 346, 'face': 347, 'video': 348, \"there's\": 349, 'awarded': 350, 'quite': 351, 'eat': 352, 'live': 353, 'big': 354, 'm': 355, 'latest': 356, 'watch': 357, 'everything': 358, 'maybe': 359, 'reach': 360, 'sat': 361, 'å£1': 362, 'town': 363, 'sir': 364, 'meeting': 365, 'code': 366, 'into': 367, 'box': 368, 'lot': 369, 'plan': 370, 'dunno': 371, 'room': 372, 'bed': 373, 'chance': 374, 'pay': 375, 'shit': 376, 'heart': 377, 'look': 378, 'baby': 379, 'nothing': 380, 'special': 381, 'mind': 382, '150ppm': 383, 'minutes': 384, 'leh': 385, 'probably': 386, 'month': 387, \"he's\": 388, '1st': 389, 'wanted': 390, 'kiss': 391, 'weekend': 392, 'start': 393, 'texts': 394, 'orange': 395, 'apply': 396, 'girl': 397, 'once': 398, 'watching': 399, '10': 400, 'll': 401, 'luv': 402, 'called': 403, 'fun': 404, 'wont': 405, 'remember': 406, 'xxx': 407, 'pa': 408, 'bad': 409, 'alright': 410, 'receive': 411, 'speak': 412, 'cost': 413, '000': 414, 'ringtone': 415, 'camera': 416, 'does': 417, 'abt': 418, 'offer': 419, 'landline': 420, 'able': 421, 'goes': 422, 'looking': 423, 'left': 424, 'enough': 425, 'mail': 426, 'bus': 427, 'actually': 428, 'å£1000': 429, 'put': 430, 'sweet': 431, 'must': 432, 'juz': 433, 'making': 434, 'po': 435, 'forgot': 436, 'network': 437, 'school': 438, 'worry': 439, 'fuck': 440, 'away': 441, 'play': 442, 'office': 443, 'dad': 444, 'princess': 445, 'lei': 446, 'birthday': 447, '2nd': 448, 'years': 449, 'didnt': 450, 'book': 451, 'award': 452, 'show': 453, '9': 454, 'important': 455, 'working': 456, 'sch': 457, 'collect': 458, 'tmr': 459, 'haf': 460, 'rate': 461, 'though': 462, 'stay': 463, 'says': 464, 'those': 465, 'asked': 466, 'easy': 467, 'thank': 468, 'anyway': 469, 'havent': 470, 'means': 471, 'busy': 472, 'hair': 473, 'huh': 474, 'online': 475, 're': 476, 'world': 477, 'chikku': 478, 'wif': 479, 'tot': 480, 'most': 481, 'came': 482, 'tv': 483, 'pain': 484, 'else': 485, 'join': 486, 'bring': 487, 'hour': 488, 'bt': 489, 'little': 490, 'evening': 491, 'valid': 492, 'wake': 493, 'boy': 494, 'true': 495, 'oso': 496, 'net': 497, 'two': 498, 'driving': 499, 'order': 500, 'times': 501, 'gift': 502, 'dis': 503, 'ard': 504, 'goin': 505, 'saw': 506, 'part': 507, 'hot': 508, 'sexy': 509, 'these': 510, 'missed': 511, 'http': 512, 'hav': 513, 'until': 514, 'movie': 515, 'without': 516, 'wot': 517, 'while': 518, 'happen': 519, 'afternoon': 520, 'hurt': 521, 'made': 522, 'missing': 523, 'colour': 524, 'yourself': 525, 'both': 526, 'update': 527, 'trip': 528, 'god': 529, 'nite': 530, \"we're\": 531, 'run': 532, 'guy': 533, 'details': 534, 'since': 535, 'g': 536, 'price': 537, 'started': 538, \"what's\": 539, 'finished': 540, 'full': 541, 'yesterday': 542, 'food': 543, 'selected': 544, 'old': 545, 'mean': 546, \"we'll\": 547, 'head': 548, 'charge': 549, 'test': 550, 'collection': 551, 'poly': 552, 'xmas': 553, '8': 554, 'attempt': 555, 'de': 556, 'plz': 557, 'okay': 558, \"how's\": 559, 'noe': 560, 'bonus': 561, 'believe': 562, 'change': 563, 'tried': 564, 'til': 565, 'pics': 566, 'å£2000': 567, '10p': 568, 'feeling': 569, 'å£100': 570, 'ring': 571, 'points': 572, 'calls': 573, 'drink': 574, 'thinking': 575, 'address': 576, 'alone': 577, 'xx': 578, 'national': 579, \"haven't\": 580, 'dude': 581, 'beautiful': 582, 'tomo': 583, 'rite': 584, '12hrs': 585, 'neva': 586, 'drive': 587, 'makes': 588, 'sun': 589, 'top': 590, 'gd': 591, 'services': 592, 'entry': 593, 'weekly': 594, 'wants': 595, 'nt': 596, 'date': 597, 'wife': 598, 'walk': 599, 'yours': 600, 'bored': 601, 'sae': 602, 'words': 603, 'messages': 604, 'plus': 605, 'between': 606, 'saying': 607, 'calling': 608, 'double': 609, 'brother': 610, 'shop': 611, 'land': 612, 'fri': 613, 'wen': 614, 'taking': 615, 'id': 616, 'loving': 617, 'needs': 618, \"won't\": 619, 'delivery': 620, 'smoke': 621, 'darlin': 622, 'college': 623, 'outside': 624, 'boytoy': 625, 'far': 626, 'touch': 627, 'private': 628, 'identifier': 629, 'expires': 630, '11': 631, 'lets': 632, 'sis': 633, 'company': 634, 'oredi': 635, 'ltd': 636, 'happened': 637, 'voucher': 638, 'tones': 639, 'nope': 640, 'second': 641, 'w': 642, 'open': 643, 'mob': 644, 'hours': 645, 'mum': 646, 'till': 647, 'took': 648, 'todays': 649, 'tho': 650, 'ha': 651, 'cause': 652, 'family': 653, 'telling': 654, 'game': 655, 'question': 656, 'dreams': 657, 'auction': 658, 'lesson': 659, 'sister': 660, 'girls': 661, 'aft': 662, 'awesome': 663, 'break': 664, 'unlimited': 665, 'sleeping': 666, 'å£500': 667, 'music': 668, 'statement': 669, 'choose': 670, 'msgs': 671, 'wit': 672, 'smth': 673, 'decimal': 674, 'player': 675, 'kind': 676, 'fucking': 677, 'leaving': 678, 'pub': 679, 'sad': 680, \"doesn't\": 681, 'await': 682, 'lucky': 683, 'everyone': 684, 'knw': 685, 'freemsg': 686, 'treat': 687, 'unsubscribe': 688, 'takes': 689, 'carlos': 690, '8007': 691, 'club': 692, 'games': 693, 'hungry': 694, \"you'll\": 695, 'each': 696, 'whole': 697, '750': 698, 'anytime': 699, 'earlier': 700, 'whats': 701, 'caller': 702, 'answer': 703, 'gas': 704, 'bout': 705, 'listen': 706, 'whatever': 707, 'uncle': 708, 'congrats': 709, 'couple': 710, 'snow': 711, 'lots': 712, \"she's\": 713, 'okie': 714, 'gone': 715, \"you've\": 716, 'pic': 717, 'congratulations': 718, 'sounds': 719, '800': 720, 'un': 721, 'pm': 722, 'minute': 723, 'hee': 724, '08000930705': 725, 'found': 726, \"c's\": 727, 'news': 728, 'hmmm': 729, 'finally': 730, 'available': 731, 'mu': 732, 'yr': 733, 'anyone': 734, 'content': 735, 'hit': 736, 'hmm': 737, 'frnd': 738, 'close': 739, 'forget': 740, 'yar': 741, 'seen': 742, 'row': 743, 'drop': 744, 'together': 745, 'talking': 746, 'mine': 747, 'prob': 748, '500': 749, 'å£2': 750, 'age': 751, '03': 752, '30': 753, 'read': 754, 'lovely': 755, 'hows': 756, 'cut': 757, 'charged': 758, 'abiola': 759, 'set': 760, 'either': 761, 'vouchers': 762, '2003': 763, 'redeemed': 764, 'search': 765, 'friday': 766, 'reason': 767, 'exam': 768, \"i'd\": 769, 'card': 770, '100': 771, 'camcorder': 772, 'gr8': 773, 'used': 774, 'saturday': 775, 'å£5000': 776, 'bank': 777, 'smiling': 778, 'decided': 779, 'st': 780, '\\x89û': 781, 'park': 782, 'tel': 783, 'grins': 784, 'fr': 785, 'india': 786, 'hard': 787, 'don': 788, 'pounds': 789, 'wonderful': 790, 'wow': 791, 'å£250': 792, 'eve': 793, 'worth': 794, 'b4': 795, 'darren': 796, 'wil': 797, 'fancy': 798, 'sea': 799, 'own': 800, 'safe': 801, 'store': 802, 'welcome': 803, 'wana': 804, 'worried': 805, 'side': 806, 'opt': 807, 'fone': 808, '04': 809, 'friendship': 810, '08000839402': 811, 'gotta': 812, 'pass': 813, 'almost': 814, 'computer': 815, 'story': 816, 'wid': 817, 'sell': 818, 'point': 819, 'chennai': 820, 'their': 821, 'mate': 822, 'log': 823, 'ans': 824, 'ago': 825, 'coz': 826, 'confirm': 827, 'comes': 828, 'muz': 829, 'meant': 830, 'ugh': 831, 'download': 832, 'wap': 833, 'knew': 834, '86688': 835, 'link': 836, 'swing': 837, 'project': 838, 'jay': 839, 'through': 840, 'final': 841, 'frnds': 842, 'crazy': 843, 'info': 844, 'å£3': 845, 'doin': 846, 'asap': 847, 'ass': 848, 'o': 849, 'rs': 850, 'visit': 851, 'case': 852, 'march': 853, 'dating': 854, 'lose': 855, 'loved': 856, 'ive': 857, 'disturb': 858, 'credit': 859, 'light': 860, 'ex': 861, 'operator': 862, 'wonder': 863, 'hiya': 864, 'monday': 865, 'parents': 866, 'understand': 867, 'lost': 868, 'forever': 869, 'itself': 870, 'bathe': 871, 'sunday': 872, \"isn't\": 873, \"''\": 874, 'felt': 875, 'mr': 876, 'street': 877, 'type': 878, 'rest': 879, 'mates': 880, 'less': 881, 'ones': 882, 'weeks': 883, 'information': 884, 'semester': 885, 'th': 886, 'extra': 887, 'correct': 888, 'study': 889, 'direct': 890, 'red': 891, 'laugh': 892, 'comp': 893, 'post': 894, 'na': 895, 'nah': 896, 'spend': 897, 'gym': 898, 'course': 899, 'somewhere': 900, 'knows': 901, 'bath': 902, 'party': 903, 'dead': 904, 'tonite': 905, 'tired': 906, 'myself': 907, 'il': 908, 'cum': 909, 'tickets': 910, 'fast': 911, 'rental': 912, 'email': 913, 'wrong': 914, 'heard': 915, 'usf': 916, 'mobileupd8': 917, 'slow': 918, 'ringtones': 919, 'normal': 920, 'support': 921, 'sort': 922, 'lessons': 923, 'sending': 924, 'song': 925, 'charity': 926, 'asking': 927, 'thinks': 928, 'truth': 929, 'ten': 930, '0800': 931, 'pretty': 932, 'sex': 933, 'comin': 934, 'figure': 935, 'kate': 936, 'immediately': 937, 'lazy': 938, 'age16': 939, 'winner': 940, 'facebook': 941, 'met': 942, 'training': 943, '87066': 944, 'area': 945, 'mobiles': 946, 'happiness': 947, 'water': 948, 'least': 949, 'moment': 950, 'picking': 951, 'stupid': 952, 'surprise': 953, 'ar': 954, '\\x89ûò': 955, 'complimentary': 956, 'men': 957, 'fact': 958, 'valentine': 959, 'christmas': 960, 'weed': 961, 'film': 962, 'etc': 963, 'england': 964, 'eg': 965, '20': 966, \"wasn't\": 967, 'match': 968, 'pc': 969, 'ts': 970, 'fantastic': 971, 'somebody': 972, 'frm': 973, 'sick': 974, 'ac': 975, 'others': 976, 'ice': 977, 'ipod': 978, 'mom': 979, 'txting': 980, 'ni8': 981, 'laptop': 982, 'angry': 983, 'custcare': 984, 'questions': 985, 'glad': 986, 'rock': 987, 'mayb': 988, '150': 989, 'crave': 990, 'numbers': 991, 'rates': 992, 'goodmorning': 993, 'warm': 994, 'drugs': 995, 'booked': 996, 'luck': 997, 'mrt': 998, 'catch': 999, 'aha': 1000, 'suite342': 1001, '2lands': 1002, 'daddy': 1003, 'mah': 1004, 'enter': 1005, '2day': 1006, 'lect': 1007, 'urself': 1008, 'supposed': 1009, 'move': 1010, 'unless': 1011, 'currently': 1012, 'library': 1013, 'yep': 1014, '02': 1015, 'secret': 1016, 'meh': 1017, 'orchard': 1018, 'whenever': 1019, 'mm': 1020, 'wkly': 1021, 'em': 1022, 'gets': 1023, 'starting': 1024, 'eh': 1025, 'wondering': 1026, 'pete': 1027, 'john': 1028, 'å£200': 1029, 'thinkin': 1030, 'mon': 1031, 'cheap': 1032, 'depends': 1033, 'vl': 1034, 'loads': 1035, 'reference': 1036, 'arrive': 1037, 'deal': 1038, 'checking': 1039, '11mths': 1040, 'cuz': 1041, '25p': 1042, 'reached': 1043, 'using': 1044, 'nigeria': 1045, 'train': 1046, 'rent': 1047, 'road': 1048, '20p': 1049, 'ntt': 1050, 'kids': 1051, 'entered': 1052, 'invited': 1053, 'sofa': 1054, 'clean': 1055, 'å£10': 1056, 'tc': 1057, 'studying': 1058, 'quiz': 1059, 'high': 1060, 'cheers': 1061, 'near': 1062, '87077': 1063, 'mistake': 1064, 'cold': 1065, 'sense': 1066, 'bucks': 1067, 'reward': 1068, 'user': 1069, 'difficult': 1070, 'credits': 1071, 'comuk': 1072, 'access': 1073, 'pobox': 1074, 'page': 1075, 'woke': 1076, 'polys': 1077, 'insurance': 1078, 'small': 1079, 'paying': 1080, '3030': 1081, 'months': 1082, 'hurry': 1083, 'sound': 1084, 'hold': 1085, 'shd': 1086, 'goto': 1087, 'promise': 1088, 'shower': 1089, 'mark': 1090, 'father': 1091, 'however': 1092, 'tampa': 1093, 'eyes': 1094, 'interested': 1095, 'sale': 1096, 'during': 1097, \"they're\": 1098, 'å£350': 1099, '12': 1100, 'wun': 1101, 'blue': 1102, 'imma': 1103, 'mp3': 1104, 'honey': 1105, 'torch': 1106, 'sitting': 1107, 'present': 1108, 'planning': 1109, 'sometimes': 1110, 'hand': 1111, 'pray': 1112, '06': 1113, 'txts': 1114, 'motorola': 1115, 'oops': 1116, 'king': 1117, 'door': 1118, 'yest': 1119, 'bb': 1120, 'umma': 1121, 'wishing': 1122, 'appreciate': 1123, 'save': 1124, 'omg': 1125, 'paid': 1126, 'seeing': 1127, 'write': 1128, 'shuhui': 1129, 'nyt': 1130, 'yahoo': 1131, 'bcoz': 1132, 'midnight': 1133, 'anymore': 1134, 'die': 1135, 'stand': 1136, 'trust': 1137, 'mo': 1138, 'rather': 1139, 'gay': 1140, 'voice': 1141, '08712460324': 1142, 'across': 1143, 'sucks': 1144, 'within': 1145, 'pizza': 1146, 'bid': 1147, 'behind': 1148, 'reading': 1149, 'workin': 1150, 'staying': 1151, 'kinda': 1152, 'via': 1153, 'liked': 1154, 'plans': 1155, 'posted': 1156, 'yoga': 1157, 'spree': 1158, 'definitely': 1159, 'specially': 1160, \"u're\": 1161, 'hospital': 1162, 'nxt': 1163, \"'\": 1164, 'press': 1165, 'ldew': 1166, 'ends': 1167, 'different': 1168, 'happening': 1169, 'bill': 1170, 'dog': 1171, 'ldn': 1172, 'simple': 1173, 'hw': 1174, 'tea': 1175, 'askd': 1176, 'holla': 1177, 'nobody': 1178, 'add': 1179, 'sp': 1180, 'cute': 1181, 'none': 1182, 'bugis': 1183, '50p': 1184, 'cancel': 1185, 'decide': 1186, 'team': 1187, 'holder': 1188, 'awaiting': 1189, 'cell': 1190, 'login': 1191, 'registered': 1192, 'gee': 1193, 'slave': 1194, 'paper': 1195, 'hrs': 1196, 'std': 1197, 'single': 1198, 'bother': 1199, 'seems': 1200, 'spent': 1201, 'sub': 1202, 'valentines': 1203, 'rcvd': 1204, 'hurts': 1205, 'trouble': 1206, \"you'd\": 1207, 'photo': 1208, 'alex': 1209, 'bag': 1210, 'except': 1211, 'balance': 1212, 'xy': 1213, 'p': 1214, 'entitled': 1215, 'ending': 1216, 'weight': 1217, 'texting': 1218, 'strong': 1219, 'ticket': 1220, 'poor': 1221, 'yrs': 1222, 'power': 1223, 'loan': 1224, 'against': 1225, 'forward': 1226, 'naughty': 1227, 'system': 1228, 'eatin': 1229, 'gave': 1230, 'internet': 1231, 'w1j6hl': 1232, 'following': 1233, 'situation': 1234, 'fat': 1235, 'dvd': 1236, 'loves': 1237, 'doctor': 1238, '2nite': 1239, 'dream': 1240, 'phones': 1241, 'mrng': 1242, 'doesnt': 1243, 'aiyo': 1244, 'bold': 1245, 'matter': 1246, 'lemme': 1247, 'future': 1248, 'rply': 1249, 'wats': 1250, 'bak': 1251, 'discount': 1252, 'offers': 1253, 'sony': 1254, 'call2optout': 1255, 'omw': 1256, 'realy': 1257, 'slept': 1258, 'reaching': 1259, 'funny': 1260, 'goodnight': 1261, 'hotel': 1262, 'valued': 1263, 'turns': 1264, 'tht': 1265, 'lookin': 1266, 'hoping': 1267, 'cine': 1268, 'kb': 1269, 'hr': 1270, 'reveal': 1271, 'mode': 1272, \"t's\": 1273, 'past': 1274, 'raining': 1275, 'fault': 1276, 'coffee': 1277, 'bslvyl': 1278, 'eating': 1279, 'forwarded': 1280, 'tough': 1281, 'boys': 1282, 'weekends': 1283, 'frens': 1284, 'hell': 1285, 'expensive': 1286, 'law': 1287, 'battery': 1288, 'loverboy': 1289, 'flirt': 1290, 'sport': 1291, 'merry': 1292, 'wednesday': 1293, 'inc': 1294, 'click': 1295, '2004': 1296, \"u'll\": 1297, 'blood': 1298, 'excellent': 1299, 'feels': 1300, 'dogging': 1301, 'gal': 1302, 'longer': 1303, 'directly': 1304, 'starts': 1305, 'wiv': 1306, 'straight': 1307, 'biz': 1308, 'empty': 1309, 'recently': 1310, 'gettin': 1311, 'buying': 1312, 'relax': 1313, 'fb': 1314, 'waking': 1315, 'hook': 1316, 'summer': 1317, 'la': 1318, 'izzit': 1319, 'cal': 1320, 'din': 1321, 'vikky': 1322, 'joined': 1323, 'request': 1324, 'cd': 1325, 'tncs': 1326, 'romantic': 1327, '21': 1328, 'hun': 1329, 'horny': 1330, 'towards': 1331, \"where's\": 1332, 'wet': 1333, 'super': 1334, \"who's\": 1335, 'wine': 1336, 'swt': 1337, 'gals': 1338, 'rakhesh': 1339, 'airport': 1340, 'pple': 1341, '1327': 1342, 'croydon': 1343, 'cr9': 1344, '5wb': 1345, '0870': 1346, 'boss': 1347, 'announcement': 1348, 'model': 1349, 'sura': 1350, 'slowly': 1351, '434': 1352, '82277': 1353, 'ho': 1354, 'fixed': 1355, 'hate': 1356, \"couldn't\": 1357, 'remove': 1358, 'isnt': 1359, 'informed': 1360, \"he'll\": 1361, 'onto': 1362, 'urawinner': 1363, 'quick': 1364, 'thts': 1365, 'yijue': 1366, 'replied': 1367, 'representative': 1368, 'receipt': 1369, '80062': 1370, 'tuition': 1371, 'worries': 1372, 'rain': 1373, '4u': 1374, 'body': 1375, 'belly': 1376, 'willing': 1377, 'boring': 1378, 'broke': 1379, 'no1': 1380, 'getzed': 1381, 'january': 1382, \"today's\": 1383, 'become': 1384, 'simply': 1385, 'ish': 1386, 'village': 1387, 'zed': 1388, 'heavy': 1389, 'changed': 1390, '25': 1391, 'report': 1392, '08718720201': 1393, 'website': 1394, 'style': 1395, 'cancer': 1396, 'bin': 1397, 'amount': 1398, 'acc': 1399, 'standard': 1400, 'app': 1401, 'teach': 1402, 'cars': 1403, '8th': 1404, 'horrible': 1405, 'bf': 1406, 'country': 1407, 'budget': 1408, 'social': 1409, 'ride': 1410, 'cinema': 1411, 'advice': 1412, 'track': 1413, 'wed': 1414, 'vote': 1415, 'movies': 1416, 'especially': 1417, 'rd': 1418, 'lmao': 1419, 'moan': 1420, 'south': 1421, '10am': 1422, 'thurs': 1423, 'arrange': 1424, 'energy': 1425, 'matches': 1426, 'imagine': 1427, 'teasing': 1428, \"did't\": 1429, 'j': 1430, 'damn': 1431, 'lady': 1432, 'putting': 1433, 'guide': 1434, 'giving': 1435, 'air': 1436, 'pix': 1437, 'brings': 1438, 'themob': 1439, 'uni': 1440, 'don\\x89û÷t': 1441, 'planned': 1442, 'woman': 1443, 'savamob': 1444, '00': 1445, 'noon': 1446, 'bluetooth': 1447, 'station': 1448, 'exams': 1449, 'kano': 1450, 'green': 1451, 'cheaper': 1452, '05': 1453, 'lead': 1454, 'ta': 1455, 'aftr': 1456, 'pound': 1457, 'children': 1458, 'num': 1459, 'inside': 1460, 'flag': 1461, 'alrite': 1462, 'hg': 1463, 'admirer': 1464, 'plenty': 1465, 'dey': 1466, 'remind': 1467, 'five': 1468, '40gb': 1469, '83355': 1470, 'hop': 1471, 'joke': 1472, 'kallis': 1473, 'looks': 1474, 'round': 1475, 'pilates': 1476, 'happens': 1477, 'short': 1478, 'gives': 1479, '2mrw': 1480, 'april': 1481, 'ahead': 1482, 'fyi': 1483, 'askin': 1484, 'ahmad': 1485, 'mother': 1486, 'handset': 1487, 'tyler': 1488, 'list': 1489, 'rose': 1490, 'advance': 1491, 'records': 1492, 'fetch': 1493, 'sup': 1494, \"god's\": 1495, 'brand': 1496, 'medical': 1497, 'deliver': 1498, 'hai': 1499, 'weather': 1500, 'notice': 1501, 'lover': 1502, 'babes': 1503, '80488': 1504, 'tenerife': 1505, 'hostel': 1506, 'l8r': 1507, 'gentle': 1508, 'del': 1509, 'tuesday': 1510, 'deep': 1511, 'sha': 1512, '88039': 1513, 'skilgme': 1514, 'usual': 1515, 'chinese': 1516, \"ain't\": 1517, '7pm': 1518, 'cafe': 1519, 'awake': 1520, 'bet': 1521, 'living': 1522, 'pictures': 1523, 'shoot': 1524, 'callertune': 1525, 'copy': 1526, 'sec': 1527, 'thursday': 1528, 'connection': 1529, 'meal': 1530, 'share': 1531, 'timing': 1532, \"we've\": 1533, 'spoken': 1534, 'pie': 1535, 'daily': 1536, 'idiot': 1537, 'problems': 1538, 'fantasies': 1539, '08707509020': 1540, 'waitin': 1541, \"b'day\": 1542, 'colleagues': 1543, 'bedroom': 1544, 'mood': 1545, 'cake': 1546, 'screaming': 1547, 'taken': 1548, 'loyalty': 1549, 'bye': 1550, 'theatre': 1551, 'wherever': 1552, 'pleasure': 1553, 'hanging': 1554, 'ibiza': 1555, 'unsub': 1556, 'cleaning': 1557, '3510i': 1558, '300': 1559, 'digital': 1560, 'players': 1561, 'season': 1562, '87131': 1563, 'freephone': 1564, 'inclusive': 1565, 'subscriber': 1566, 'yan': 1567, 'jiu': 1568, 'aiyah': 1569, 'porn': 1570, '24': 1571, 'btw': 1572, 'learn': 1573, 'clock': 1574, '36504': 1575, 'closed': 1576, 'including': 1577, 'fever': 1578, 'dropped': 1579, 'surprised': 1580, 'password': 1581, 'travel': 1582, 'pussy': 1583, 'dint': 1584, 'abi': 1585, 'partner': 1586, 'kept': 1587, 'space': 1588, 'wear': 1589, 'answering': 1590, 'earth': 1591, 'nvm': 1592, 'drivin': 1593, 'f': 1594, 'alert': 1595, 'dnt': 1596, 'pack': 1597, 'yun': 1598, 'voda': 1599, '08712300220': 1600, 'quoting': 1601, 'jess': 1602, 'cup': 1603, 'radio': 1604, 'expect': 1605, 'arms': 1606, 'al': 1607, 'pongal': 1608, 'possible': 1609, 'yetunde': 1610, 'mid': 1611, 'return': 1612, 'legal': 1613, 'wylie': 1614, 'menu': 1615, 'xchat': 1616, 'ma': 1617, 'fingers': 1618, '6hrs': 1619, 'campus': 1620, 'charges': 1621, 'scream': 1622, 'quality': 1623, 'callså£1': 1624, 'choice': 1625, \"u've\": 1626, 'cha': 1627, 'thatåõs': 1628, 'sing': 1629, 'flat': 1630, 'london': 1631, 'step': 1632, 'fall': 1633, 'leaves': 1634, 'ache': 1635, 'somethin': 1636, 'mite': 1637, 'donåõt': 1638, 'keeping': 1639, 'moon': 1640, 'role': 1641, 'looked': 1642, 'sunshine': 1643, 'mmm': 1644, 'ate': 1645, 'basically': 1646, 'unique': 1647, \"shouldn't\": 1648, 'intelligent': 1649, 'hill': 1650, 'ages': 1651, 'google': 1652, 'å£150': 1653, 'member': 1654, 'cbe': 1655, 'wkend': 1656, 'group': 1657, 'holding': 1658, 'expecting': 1659, 'tariffs': 1660, 'prepare': 1661, 'coins': 1662, 'black': 1663, 'nw': 1664, 'masters': 1665, 'shame': 1666, \"wat's\": 1667, 'moji': 1668, 'polyphonic': 1669, 'original': 1670, 'marriage': 1671, 'pobox84': 1672, 'english': 1673, 'oni': 1674, 'pleased': 1675, 'kerala': 1676, \"joy's\": 1677, 'process': 1678, 'common': 1679, '530': 1680, 'yogasana': 1681, 'photos': 1682, 'gorgeous': 1683, 'along': 1684, 'official': 1685, 'salary': 1686, '3g': 1687, 'lift': 1688, 'profit': 1689, '1x150p': 1690, 'obviously': 1691, 'bought': 1692, 'picked': 1693, 'skype': 1694, 'tear': 1695, 'appt': 1696, 'twice': 1697, 'ad': 1698, 'ave': 1699, 'adult': 1700, 'å£900': 1701, 'wanting': 1702, 'å£400': 1703, 'mtmsgrcvd18': 1704, '86021': 1705, 'barely': 1706, 'completely': 1707, 'walking': 1708, 'passionate': 1709, 'bloody': 1710, 'journey': 1711, 'series': 1712, 'basic': 1713, 'intro': 1714, 'competition': 1715, 'beer': 1716, 'netcollex': 1717, 'joking': 1718, 'tour': 1719, 'december': 1720, 'research': 1721, 'reasons': 1722, 'usually': 1723, 'added': 1724, 'q': 1725, 'answers': 1726, 'surely': 1727, 'smiles': 1728, 'worse': 1729, 'vomit': 1730, 'self': 1731, 'embarassed': 1732, 'selection': 1733, 'brought': 1734, 'paris': 1735, '60p': 1736, \"uk's\": 1737, 'marry': 1738, 'rem': 1739, 'schedule': 1740, 'total': 1741, 'grand': 1742, 'queen': 1743, 'sighs': 1744, 'feb': 1745, 'married': 1746, 'respect': 1747, 'weak': 1748, 'serious': 1749, 'howz': 1750, 'terms': 1751, 'accept': 1752, 'closer': 1753, 'complete': 1754, 'opportunity': 1755, 'opinion': 1756, 'fifteen': 1757, 'pg': 1758, 'pissed': 1759, \"mom's\": 1760, 'otherwise': 1761, 'sooner': 1762, 'thangam': 1763, 'roger': 1764, 'works': 1765, 'buzz': 1766, 'nights': 1767, 'flights': 1768, 'outta': 1769, 'jazz': 1770, 'under': 1771, 'contract': 1772, 'asleep': 1773, 'meetin': 1774, '28': 1775, 'ladies': 1776, 'sept': 1777, 'version': 1778, \"she'll\": 1779, 'drug': 1780, 'costs': 1781, 'receiving': 1782, 'blackberry': 1783, 'santa': 1784, 'scared': 1785, 'ru': 1786, 'excuse': 1787, 'wishes': 1788, 'replying': 1789, 'amazing': 1790, 'dirty': 1791, 'activate': 1792, 'blank': 1793, 'grl': 1794, 'cds': 1795, 'å£800': 1796, 'ppl': 1797, 'cry': 1798, 'shortly': 1799, 'ttyl': 1800, 'sky': 1801, \"aren't\": 1802, 'fullonsms': 1803, 'rush': 1804, 'vip': 1805, 'unable': 1806, 'ref': 1807, 'explain': 1808, 'iåõm': 1809, 'cover': 1810, 'upset': 1811, 'score': 1812, 'aiyar': 1813, 'city': 1814, 'tscs087147403231winawk': 1815, '50perwksub': 1816, 'seemed': 1817, 'prefer': 1818, 'sunny': 1819, 'fill': 1820, 'personal': 1821, 'com1win150ppmx3age16': 1822, '88066': 1823, 'stranger': 1824, 'released': 1825, 'italian': 1826, 'freefone': 1827, 'infernal': 1828, 'finishes': 1829, 'egg': 1830, 'remembered': 1831, 'brothas': 1832, 'moments': 1833, 'anyways': 1834, 'wc1n3xx': 1835, 'exhausted': 1836, 'normally': 1837, 'cuddle': 1838, 'shesil': 1839, 'nap': 1840, 'essential': 1841, 'running': 1842, 'considering': 1843, 'previous': 1844, 'naked': 1845, 'raise': 1846, 'rofl': 1847, 'anti': 1848, 'txtauction': 1849, 'lecture': 1850, 'elsewhere': 1851, 'followed': 1852, 'software': 1853, 'sk3': 1854, '8wp': 1855, 'moby': 1856, 'cornwall': 1857, 'bathing': 1858, 'deliveredtomorrow': 1859, '0207': 1860, 'yay': 1861, 'interview': 1862, 'hug': 1863, 'alcohol': 1864, '250': 1865, 'gautham': 1866, 'decision': 1867, 'wales': 1868, 'handle': 1869, 'album': 1870, 'instead': 1871, 'dry': 1872, 'tlp': 1873, 'apparently': 1874, 'åð': 1875, 'random': 1876, 'saved': 1877, 'shld': 1878, 'rich': 1879, '3qxj9': 1880, '08702840625': 1881, '9ae': 1882, 'feet': 1883, 'july': 1884, 'ended': 1885, 'hardcore': 1886, 'response': 1887, '4th': 1888, 'milk': 1889, 'pod': 1890, 'petrol': 1891, 'meaning': 1892, 'gap': 1893, 'w45wq': 1894, 'norm150p': 1895, 'maid': 1896, 'murderer': 1897, 'murdered': 1898, 'contents': 1899, 'child': 1900, 'dark': 1901, 'fml': 1902, 'logo': 1903, 'tick': 1904, 'changes': 1905, 'lifetime': 1906, '83600': 1907, 'deleted': 1908, 'cat': 1909, 'enuff': 1910, 'gona': 1911, 'jst': 1912, 'hella': 1913, 'ym': 1914, 'inviting': 1915, '62468': 1916, 'monthly': 1917, 'terrible': 1918, 'finishing': 1919, 'checked': 1920, 'cannot': 1921, 'vary': 1922, 'lab': 1923, 'pieces': 1924, 'ppm': 1925, 'missin': 1926, 'february': 1927, 'respond': 1928, 'indians': 1929, 'indian': 1930, 'roads': 1931, 'citizen': 1932, 'that\\x89û÷s': 1933, 'beyond': 1934, 'accordingly': 1935, 'files': 1936, 'gary': 1937, 'ptbo': 1938, 'generally': 1939, 'iouri': 1940, 'takin': 1941, 'whenevr': 1942, 'seven': 1943, 'msgrcvdhg': 1944, '18yrs': 1945, 'prabha': 1946, '2morow': 1947, 'madam': 1948, 'clear': 1949, 'tells': 1950, 'totally': 1951, 'handed': 1952, 'billed': 1953, 'flash': 1954, 'jealous': 1955, 'philosophy': 1956, 'unsold': 1957, 'singles': 1958, 'claire': 1959, 'havin': 1960, 'comedy': 1961, '80082': 1962, 'nan': 1963, 'letter': 1964, 'female': 1965, 'white': 1966, '6pm': 1967, 'walmart': 1968, 'james': 1969, 'derek': 1970, 'four': 1971, 'received': 1972, 'mths': 1973, 'thnk': 1974, 'whom': 1975, 'catching': 1976, 'songs': 1977, 'boye': 1978, 'caught': 1979, 'miracle': 1980, 'alive': 1981, 'roast': 1982, 'drinks': 1983, 'collecting': 1984, 'attend': 1985, 'arrested': 1986, 'package': 1987, 'term': 1988, 'chicken': 1989, 'cardiff': 1990, 'walls': 1991, '87239': 1992, 'result': 1993, 'burger': 1994, 'assume': 1995, 'ure': 1996, 'moms': 1997, 'likely': 1998, 'issues': 1999, 'key': 2000, 'likes': 2001, 'dislikes': 2002, '85023': 2003, 'sen': 2004, 'taunton': 2005, 'warner': 2006, 'center': 2007, 'urgnt': 2008, 'maximize': 2009, 'cc': 2010, 'w1': 2011, 'letters': 2012, 'enjoyed': 2013, 'begin': 2014, 'box97n7qp': 2015, 'sonyericsson': 2016, 'eight': 2017, 'boo': 2018, 'thru': 2019, 'created': 2020, 'vry': 2021, 'hands': 2022, 'legs': 2023, 'wnt': 2024, 'giv': 2025, 'review': 2026, 'chain': 2027, 'issue': 2028, 'pending': 2029, 'laughing': 2030, 'vava': 2031, 'playing': 2032, 'mono': 2033, '29': 2034, 'skip': 2035, 'mall': 2036, 'fix': 2037, '3gbp': 2038, \"'til\": 2039, 'thanksgiving': 2040, 'apologise': 2041, 'callin': 2042, 'confirmed': 2043, 'we\\x89û÷re': 2044, 'regret': 2045, 'kindly': 2046, 'quickly': 2047, 'tis': 2048, 'birth': 2049, 'lick': 2050, 'diff': 2051, 'fuckin': 2052, 'okey': 2053, 'police': 2054, 'tt': 2055, 'bitch': 2056, 'eng': 2057, 'ron': 2058, 'wearing': 2059, 'ip4': 2060, '5we': 2061, '150pm': 2062, 'june': 2063, '5p': 2064, 'alfie': 2065, \"moon's\": 2066, 'm8s': 2067, 'nokias': 2068, '08701417012': 2069, 'slippers': 2070, 'silent': 2071, 'ge': 2072, 'stock': 2073, 'action': 2074, 'eggs': 2075, 'contacted': 2076, 'fees': 2077, 'minmobsmorelkpobox177hp51fl': 2078, 'business': 2079, 'picture': 2080, 'def': 2081, 'experience': 2082, 'searching': 2083, 'å£4': 2084, 'wallpaper': 2085, 'avent': 2086, 'suntec': 2087, 'rule': 2088, 'argument': 2089, 'birds': 2090, 'mt': 2091, 'k52': 2092, 'shirt': 2093, '08715705022': 2094, 'innings': 2095, 'fighting': 2096, 'constantly': 2097, 'ic': 2098, 'staff': 2099, 'greetings': 2100, 'wins': 2101, 'optout': 2102, '08718727870': 2103, \"dsn't\": 2104, 'networking': 2105, 'record': 2106, 'losing': 2107, 'doors': 2108, 'gimme': 2109, 'films': 2110, 'august': 2111, 'stress': 2112, 'local': 2113, 'knackered': 2114, 'lives': 2115, 'greet': 2116, '08002986906': 2117, 'bell': 2118, 'books': 2119, '84128': 2120, '08712405020': 2121, 'scary': 2122, 'esplanade': 2123, 'credited': 2124, 'buns': 2125, 'adore': 2126, 'jordan': 2127, 'lie': 2128, 'sam': 2129, 'recd': 2130, 'o2': 2131, 'hmv': 2132, 'fran': 2133, 'bigger': 2134, 'mnth': 2135, 'file': 2136, \"'ll\": 2137, 'bday': 2138, 'played': 2139, 'miles': 2140, 'malaria': 2141, 'loss': 2142, 'meds': 2143, 'middle': 2144, 'kisses': 2145, 'wedding': 2146, 'foreign': 2147, 'stamps': 2148, '786': 2149, 'unredeemed': 2150, 'died': 2151, 'moral': 2152, 'butt': 2153, 'jason': 2154, 'dare': 2155, 'texted': 2156, 'gang': 2157, 'nature': 2158, 'faster': 2159, 'headache': 2160, 'tog': 2161, '09066362231': 2162, '07xxxxxxxxx': 2163, 'fair': 2164, 'pages': 2165, \"month's\": 2166, 'stopped': 2167, 'nat': 2168, 'ignore': 2169, 'reality': 2170, 'fantasy': 2171, 'inches': 2172, 'shot': 2173, 'subscribed': 2174, 'spk': 2175, 'aint': 2176, 'bat': 2177, 'textcomp': 2178, 'armand': 2179, 'tests': 2180, '9pm': 2181, 'carry': 2182, 'lotr': 2183, 'hint': 2184, 'american': 2185, 'caring': 2186, 'doggy': 2187, 'laid': 2188, 'stuck': 2189, 'gram': 2190, '31': 2191, 'quit': 2192, 'practice': 2193, \"blake's\": 2194, 'blah': 2195, 'crab': 2196, 'footprints': 2197, 'leona': 2198, 'mad': 2199, 'requests': 2200, 'norm': 2201, 'url': 2202, 'kick': 2203, 'accident': 2204, '09066612661': 2205, 'islands': 2206, 'darling': 2207, 'science': 2208, 'confidence': 2209, 'wer': 2210, 'plane': 2211, 'students': 2212, 'spoke': 2213, 'promises': 2214, 'apps': 2215, 'current': 2216, 'measure': 2217, 'sugar': 2218, 'ful': 2219, 'in2': 2220, 'machan': 2221, 'avatar': 2222, 'geeee': 2223, 'tom': 2224, 'dai': 2225, 'exe': 2226, 'sim': 2227, 'chatting': 2228, 'se': 2229, '89555': 2230, 'textoperator': 2231, 'settled': 2232, 'tat': 2233, 'ground': 2234, '2optout': 2235, 'sometime': 2236, 'ideas': 2237, 'wtf': 2238, 'fave': 2239, 'lines': 2240, 'sign': 2241, 'pin': 2242, \"mum's\": 2243, 'freak': 2244, '3mins': 2245, '88600': 2246, 'ibhltd': 2247, 'ldnw15h': 2248, 'evng': 2249, 'purchase': 2250, \"cann't\": 2251, 'whos': 2252, '542': 2253, 'dollars': 2254, 'perfect': 2255, 'concert': 2256, 'cw25wx': 2257, 'favourite': 2258, 'nearly': 2259, 'yeh': 2260, 'understood': 2261, 'i\\x89û÷ll': 2262, 'convey': 2263, 'turn': 2264, 'cam': 2265, 'shipping': 2266, 'hopefully': 2267, 'dave': 2268, '5000': 2269, 'tcs': 2270, 'quote': 2271, 'waste': 2272, \"let's\": 2273, '1000s': 2274, 'docs': 2275, 'cud': 2276, 'sore': 2277, 'usc': 2278, 'tm': 2279, '2moro': 2280, 'irritating': 2281, 'seem': 2282, 'downloads': 2283, 'gossip': 2284, 'arsenal': 2285, 'rang': 2286, 'subscription': 2287, 'costa': 2288, 'sol': 2289, 'sk38xh': 2290, 'knowing': 2291, 'male': 2292, '0871': 2293, 'box95qu': 2294, 'it\\x89û÷s': 2295, 'aiya': 2296, 'born': 2297, 'easier': 2298, 'auto': 2299, 'booking': 2300, 'fren': 2301, 'hl': 2302, 'invite': 2303, 'proof': 2304, 'snake': 2305, 'bite': 2306, \"week's\": 2307, 'frying': 2308, 'some1': 2309, 'medicine': 2310, 'management': 2311, '3d': 2312, '09': 2313, 'tb': 2314, 'discuss': 2315, 'bud': 2316, 'escape': 2317, 'prolly': 2318, 'teacher': 2319, 'ubi': 2320, 'everybody': 2321, 'transfer': 2322, 'dick': 2323, 'often': 2324, 'sheets': 2325, 'calicut': 2326, 'bags': 2327, 'bills': 2328, 'selfish': 2329, 'register': 2330, 'shorter': 2331, 'fringe': 2332, 'distract': 2333, 'resume': 2334, 'loans': 2335, 'purpose': 2336, 'tenants': 2337, \"there're\": 2338, 'colours': 2339, 'remains': 2340, 'bros': 2341, 'call09050000327': 2342, '4eva': 2343, 'x49': 2344, '09065989182': 2345, 'remembr': 2346, 'oru': 2347, 'callers': 2348, 'bahamas': 2349, 'sry': 2350, 'cancelled': 2351, 'str': 2352, 'option': 2353, 'oranges': 2354, 'upd8': 2355, '2stoptxt': 2356, '2go': 2357, '4a': 2358, 'hes': 2359, 'textbuddy': 2360, 'postcode': 2361, 'gaytextbuddy': 2362, '89693': 2363, 'mummy': 2364, 'affairs': 2365, 'potato': 2366, 'needed': 2367, 'nalla': 2368, '121': 2369, 'rooms': 2370, 'aah': 2371, 'lush': 2372, 'soup': 2373, 'silently': 2374, 'drms': 2375, 'kicks': 2376, '630': 2377, 'roommates': 2378, \"did'nt\": 2379, 'cabin': 2380, 'apartment': 2381, \"''ok''\": 2382, 'sed': 2383, 'minuts': 2384, 'latr': 2385, 'kidz': 2386, 'dough': 2387, 'invest': 2388, 'teeth': 2389, 'sarcasm': 2390, '81151': 2391, '4t': 2392, 'tee': 2393, 'premier': 2394, 'kent': 2395, 'vale': 2396, \"dat's\": 2397, 'fujitsu': 2398, 'toshiba': 2399, 'skyped': 2400, 'kz': 2401, 'given': 2402, 'ultimatum': 2403, 'countin': 2404, 'aburo': 2405, 'er': 2406, 'didn\\x89û÷t': 2407, 'names': 2408, 'penis': 2409, 'duchess': 2410, '008704050406': 2411, 'testing': 2412, 'figures': 2413, \"priscilla's\": 2414, 'bowl': 2415, 'desert': 2416, 'upgrade': 2417, '153': 2418, 'lik': 2419, 'donno': 2420, 'mini': 2421, 'chocolate': 2422, 'disturbing': 2423, 'goals': 2424, 'scotland': 2425, '4txt': 2426, 'traffic': 2427, \"when's\": 2428, 'due': 2429, 'coast': 2430, 'becomes': 2431, 'habit': 2432, 'follow': 2433, 'spell': 2434, 'foot': 2435, 'forgotten': 2436, 'ordered': 2437, 'processed': 2438, '2find': 2439, 'difficulties': 2440, 'jenny': 2441, 'uncles': 2442, 'atlanta': 2443, 'seconds': 2444, 'officially': 2445, 'sar': 2446, 'di': 2447, 'onwards': 2448, 'kaiez': 2449, 'pouts': 2450, 'stomps': 2451, 'blind': 2452, 'dates': 2453, '26th': 2454, 'dearly': 2455, 'rub': 2456, 'propose': 2457, 'sptv': 2458, 'detroit': 2459, 'regarding': 2460, 'rhythm': 2461, 'meets': 2462, '80182': 2463, '08452810073': 2464, 'h': 2465, 'evn': 2466, 'alwys': 2467, '9t': 2468, 'public': 2469, 'govt': 2470, 'instituitions': 2471, 'afraid': 2472, 'completed': 2473, 'joining': 2474, 'finance': 2475, 'collected': 2476, 'verify': 2477, 'hang': 2478, 'hyde': 2479, 'spook': 2480, 'subs': 2481, 'ee': 2482, 'stretch': 2483, 'vewy': 2484, 'ding': 2485, 'senthil': 2486, 'hsbc': 2487, 'lousy': 2488, 'qatar': 2489, 'allah': 2490, 'mb': 2491, 'elaine': 2492, 'module': 2493, 'throat': 2494, 'erm': 2495, 'telephone': 2496, 'planet': 2497, 'haiz': 2498, 'helen': 2499, 've': 2500, 'reboot': 2501, '910': 2502, '6months': 2503, 'morn': 2504, 'mistakes': 2505, '10k': 2506, 'tablets': 2507, 'mmmmmm': 2508, 'yummy': 2509, '09066350750': 2510, 'bootydelious': 2511, '350': 2512, 'ship': 2513, 'favorite': 2514, 'stomach': 2515, 'loose': 2516, 'weird': 2517, 'juan': 2518, 'actor': 2519, 'becoz': 2520, 'jan': 2521, 'whn': 2522, 'ofice': 2523, 'cn': 2524, 'swiss': 2525, 'crore': 2526, 'banks': 2527, 'jobs': 2528, 'lane': 2529, 'politicians': 2530, 'rights': 2531, 'fight': 2532, 'returned': 2533, 'jogging': 2534, 'os': 2535, 'installing': 2536, 'repair': 2537, 'drinkin': 2538, 'prescription': 2539, '220': 2540, 'cm2': 2541, 'bar': 2542, 'error': 2543, 'hundred': 2544, '2marrow': 2545, 'murder': 2546, 'exactly': 2547, 'unfortunately': 2548, 'uks': 2549, 'plm': 2550, 'mis': 2551, 'dining': 2552, 'asp': 2553, 'zoe': 2554, 'fan': 2555, 'sorting': 2556, 'bristol': 2557, 'flight': 2558, 'shu': 2559, 'siva': 2560, 'railway': 2561, 'moves': 2562, 'celebration': 2563, 'sells': 2564, 'mids': 2565, 'chart': 2566, 'borin': 2567, 'minmoremobsemspobox45po139wa': 2568, 'worst': 2569, 'woken': 2570, 'knock': 2571, 'tirunelvali': 2572, '0776xxxxxxx': 2573, 'selling': 2574, 'happend': 2575, 'kothi': 2576, 'doubt': 2577, 'moving': 2578, 'caroline': 2579, 'causing': 2580, 'stores': 2581, 'taylor': 2582, 'vodafone': 2583, 'ruin': 2584, 'cared': 2585, 'rays': 2586, 'diet': 2587, 'window': 2588, 'sary': 2589, 'centre': 2590, 'upload': 2591, 'bec': 2592, '2geva': 2593, 'xxxx': 2594, 'plaza': 2595, '700': 2596, '900': 2597, 'breathe': 2598, 'en': 2599, 'settings': 2600, 'chasing': 2601, 'possession': 2602, '4d': 2603, '7ish': 2604, 'racing': 2605, 'consider': 2606, 'peaceful': 2607, 'killing': 2608, '2u': 2609, 'amy': 2610, 'walked': 2611, 'abj': 2612, 'california': 2613, 'lou': 2614, 'båõday': 2615, 'tacos': 2616, 'persons': 2617, 'popcorn': 2618, 'kiosk': 2619, 'painting': 2620, 'rec': 2621, '114': 2622, '14': 2623, 'tcr': 2624, 'birla': 2625, 'soft': 2626, 'avoiding': 2627, 'msn': 2628, 'mojibiola': 2629, 'avoid': 2630, 'gender': 2631, 'usb': 2632, '1000': 2633, 'eta': 2634, 'brah': 2635, 'kidding': 2636, 'range': 2637, 'impossible': 2638, 'chill': 2639, 'tons': 2640, 'castor': 2641, 'sum1': 2642, 'contacts': 2643, 'pink': 2644, 'bck': 2645, 'color': 2646, 'incident': 2647, 'violence': 2648, 'women': 2649, 'winning': 2650, 'hoped': 2651, 'cld': 2652, 'slide': 2653, 'scold': 2654, 'chosen': 2655, 'easter': 2656, 'stops': 2657, 'necessary': 2658, 'recognise': 2659, 'thesis': 2660, 'front': 2661, 'pull': 2662, 'distance': 2663, 'speechless': 2664, 'custom': 2665, '69669': 2666, 'billion': 2667, 'kappa': 2668, 'placement': 2669, 'lions': 2670, 'lionm': 2671, 'lionp': 2672, 'lyfu': 2673, 'lyf': 2674, 'ali': 2675, 'program': 2676, 'meow': 2677, 'oi': 2678, 'makin': 2679, 'm263uz': 2680, 'print': 2681, '9ja': 2682, 'hamster': 2683, 'properly': 2684, 'advise': 2685, 'recent': 2686, 'å£1500': 2687, 'buses': 2688, 'trains': 2689, 'sit': 2690, 'rgds': 2691, 'field': 2692, 'administrator': 2693, 'iq': 2694, 'sacrifice': 2695, 'mmmm': 2696, 'licks': 2697, 'pop': 2698, 'cashbin': 2699, 'biggest': 2700, 'lido': 2701, 'dokey': 2702, 'size': 2703, 'solve': 2704, 'cook': 2705, 'cooking': 2706, 'brilliant': 2707, 'satisfy': 2708, 'randy': 2709, 'waited': 2710, 'lk': 2711, 'useful': 2712, 'stars': 2713, 'effects': 2714, 'excuses': 2715, 'beauty': 2716, 'pimples': 2717, 'yer': 2718, '84199': 2719, 'box39822': 2720, 'w111wx': 2721, 'revision': 2722, 'seriously': 2723, 'exact': 2724, 'fool': 2725, 'wise': 2726, 'howard': 2727, 'boat': 2728, 'slip': 2729, 'videophones': 2730, 'videochat': 2731, 'java': 2732, 'dload': 2733, 'noline': 2734, 'rentl': 2735, 'bx420': 2736, 'sight': 2737, 'remain': 2738, 'practical': 2739, 'rude': 2740, 'answered': 2741, 'linerental': 2742, '09058094565': 2743, 'fish': 2744, 'jokin': 2745, \"roommate's\": 2746, 'itåõs': 2747, 'tight': 2748, 'beg': 2749, '80608': 2750, 'movietrivia': 2751, '08712405022': 2752, 'oooh': 2753, 'ow': 2754, 'argue': 2755, 'pobox45w2tg150p': 2756, 'fret': 2757, 'history': 2758, 'everyday': 2759, 'canada': 2760, '2morro': 2761, 'understanding': 2762, 'lag': 2763, 'guessing': 2764, 'flaked': 2765, 'clearly': 2766, 'agree': 2767, 'ipad': 2768, 'macho': 2769, 'items': 2770, 'falls': 2771, 'swimming': 2772, 'pool': 2773, 'violated': 2774, 'morphine': 2775, 'captain': 2776, 'langport': 2777, 'goodnoon': 2778, 'spider': 2779, 'boyfriend': 2780, 'si': 2781, 'practicing': 2782, 'serving': 2783, 'yuo': 2784, 'tihs': 2785, 'valuable': 2786, 'aunt': 2787, 'nit': 2788, 'garbage': 2789, 'bishan': 2790, 'anythin': 2791, 'forevr': 2792, 'showing': 2793, 'jamster': 2794, '88888': 2795, 'telugu': 2796, '08002888812': 2797, 'gent': 2798, '09064012160': 2799, 'booty': 2800, 'floor': 2801, 'filthy': 2802, 'tree': 2803, 'tap': 2804, 'spile': 2805, 'broad': 2806, 'canal': 2807, 'gr8prizes': 2808, '80878': 2809, 'tech': 2810, 'slap': 2811, 'fell': 2812, 'stayed': 2813, '7250i': 2814, 'w1jhl': 2815, 'outstanding': 2816, 'parco': 2817, 'nb': 2818, '1030': 2819, 'hip': 2820, 'lotta': 2821, 'clearing': 2822, 'joy': 2823, 'anthony': 2824, '21870000': 2825, 'mailbox': 2826, 'messaging': 2827, '09056242159': 2828, 'retrieve': 2829, 'å£50': 2830, 'property': 2831, 'spanish': 2832, 'evry': 2833, 'ear': 2834, 'premium': 2835, '09061790121': 2836, 'bread': 2837, 'sends': 2838, 'membership': 2839, 'china': 2840, 'gn': 2841, 'guilty': 2842, 'tmrw': 2843, 'onion': 2844, 'scrounge': 2845, \"wouldn't\": 2846, 'lip': 2847, 'theres': 2848, 'infront': 2849, 'commercial': 2850, 'dorm': 2851, 'vegas': 2852, 'stays': 2853, 'i\\x89û÷m': 2854, 'wah': 2855, 'refused': 2856, \"'help'\": 2857, 'noun': 2858, 'dictionary': 2859, 'telly': 2860, 'student': 2861, 'textpod': 2862, 'depressed': 2863, 'pouch': 2864, 'curious': 2865, 'childish': 2866, 'further': 2867, 'crash': 2868, 'taxi': 2869, 'transaction': 2870, 'saucy': 2871, 'celeb': 2872, 'pocketbabe': 2873, 'tease': 2874, 'prey': 2875, 'pence': 2876, 'continue': 2877, 'select': 2878, 'benefits': 2879, 'lil': 2880, 'tomarrow': 2881, 'realize': 2882, 'goodnite': 2883, 'visionsms': 2884, 'yunny': 2885, 'cochin': 2886, 'oic': 2887, 'settle': 2888, 'runs': 2889, 'blame': 2890, 'expressoffer': 2891, 'difference': 2892, 'keeps': 2893, 'reckon': 2894, 'transport': 2895, 'temp': 2896, 'prospects': 2897, 'ringtoneking': 2898, 'messy': 2899, 'throw': 2900, 'superb': 2901, \"hasn't\": 2902, 'gently': 2903, 'hrishi': 2904, 'cookies': 2905, 'xxxmobilemovieclub': 2906, 'named': 2907, 'buff': 2908, 'massive': 2909, '45239': 2910, 'yor': 2911, 'tank': 2912, '2007': 2913, 'phoned': 2914, 'boston': 2915, 'location': 2916, 'nyc': 2917, 'exciting': 2918, \"1000's\": 2919, '4fil': 2920, 'allowed': 2921, 'perhaps': 2922, 'craziest': 2923, 'adventure': 2924, 'appreciated': 2925, 'broken': 2926, 'subpoly': 2927, '81618': 2928, 'hm': 2929, 'flies': 2930, 'earn': 2931, 'bc': 2932, 'jiayin': 2933, 'karaoke': 2934, 'pushes': 2935, 'renewal': 2936, 'geeeee': 2937, 'inconsiderate': 2938, 'nag': 2939, 'recession': 2940, 'hence': 2941, 'xuhui': 2942, '8am': 2943, 'cream': 2944, 'nasty': 2945, 'slo': 2946, 'aka': 2947, 'xavier': 2948, 'three': 2949, 'mails': 2950, 'wee': 2951, 'desparate': 2952, 'fake': 2953, 'gravity': 2954, 'carefully': 2955, 'speaking': 2956, 'networks': 2957, 'accidentally': 2958, 'helpline': 2959, '08706091795': 2960, 'spending': 2961, 'spoiled': 2962, 'jsco': 2963, 'cashto': 2964, '08000407165': 2965, 'getstop': 2966, '88222': 2967, 'php': 2968, 'market': 2969, 'hv': 2970, 'lacs': 2971, 'sweetie': 2972, 'cust': 2973, 'epsilon': 2974, 'ovulation': 2975, 'edge': 2976, 'sac': 2977, 'messaged': 2978, 'bringing': 2979, 'department': 2980, 'fathima': 2981, 'cares': 2982, 'ben': 2983, 'dubsack': 2984, 'batch': 2985, 'thm': 2986, 'boost': 2987, 'drinking': 2988, 'gain': 2989, 'demand': 2990, 'husband': 2991, 'creepy': 2992, 'inform': 2993, 'application': 2994, 'airtel': 2995, 'bbd': 2996, 'community': 2997, 'thoughts': 2998, 'spare': 2999, '24hrs': 3000, 'channel': 3001, 'standing': 3002, 'locations': 3003, 'largest': 3004, 'ec2a': 3005, '31p': 3006, 'aww': 3007, 'bruce': 3008, '40533': 3009, 'gudnite': 3010, 'minor': 3011, 'crisis': 3012, 'av': 3013, 'status': 3014, 'mcat': 3015, 'specific': 3016, 'waves': 3017, 'cleared': 3018, '125gift': 3019, 'shock': 3020, 'frndship': 3021, 'arts': 3022, 'tms': 3023, 'widelive': 3024, 'index': 3025, 'wml': 3026, 'maga': 3027, '09061213237': 3028, '177': 3029, 'm227xy': 3030, 'toot': 3031, 'theory': 3032, 'setting': 3033, 'indicate': 3034, 'west': 3035, '08000776320': 3036, 'envelope': 3037, 'luxury': 3038, 'canary': 3039, 'doc': 3040, 'hubby': 3041, 'technical': 3042, 'flip': 3043, 'mnths': 3044, 'callback': 3045, 'nus': 3046, 'edu': 3047, 'height': 3048, 'wrk': 3049, 'sleepin': 3050, 'tirupur': 3051, 'belovd': 3052, '08718738001': 3053, 'nichols': 3054, 'actual': 3055, '08718726270': 3056, 'blessings': 3057, 'sipix': 3058, '09061221066': 3059, 'fromm': 3060, 'sweetheart': 3061, 'stones': 3062, 'atlast': 3063, 'diamonds': 3064, 'screamed': 3065, '83383': 3066, 'talks': 3067, 'ericsson': 3068, '2waxsto': 3069, 'major': 3070, 'cuddling': 3071, 'yck': 3072, 'opinions': 3073, 'downloaded': 3074, 'mystery': 3075, 'jolt': 3076, 'suzy': 3077, 'low': 3078, '7250': 3079, 'hunny': 3080, 'xxxxx': 3081, 'addie': 3082, 'develop': 3083, 'drunk': 3084, 'necessarily': 3085, 'shut': 3086, 'nahi': 3087, 'zindgi': 3088, 'wo': 3089, 'jo': 3090, 'talent': 3091, '08700621170150p': 3092, 'g696ga': 3093, 'dancing': 3094, 'table': 3095, 'constant': 3096, 'regards': 3097, 'idk': 3098, 'miserable': 3099, 'control': 3100, 'cramps': 3101, 'impatient': 3102, 'explicit': 3103, 'secs': 3104, '02073162414': 3105, 'concentrate': 3106, 'career': 3107, 'farm': 3108, 'durban': 3109, 'web': 3110, '2stop': 3111, 'stick': 3112, 'indeed': 3113, '89545': 3114, '087187262701': 3115, '50gbp': 3116, 'mtmsg18': 3117, 'regular': 3118, 'appointment': 3119, 'position': 3120, 'melt': 3121, 'sunlight': 3122, '80086': 3123, 'txttowin': 3124, 'jacket': 3125, 'held': 3126, 'value': 3127, 'realized': 3128, 'interflora': 3129, 'express': 3130, 'effect': 3131, 'apart': 3132, 'fit': 3133, 'dollar': 3134, 'turning': 3135, 'revealed': 3136, 'nervous': 3137, 'flirting': 3138, 'bloke': 3139, 'hol': 3140, 'havenåõt': 3141, 'roommate': 3142, 'exeter': 3143, 'wkg': 3144, 'favour': 3145, 'tension': 3146, 'royal': 3147, 'birthdate': 3148, 'dr': 3149, 'fo': 3150, \"everybody's\": 3151, 'peace': 3152, 'jesus': 3153, 'ikea': 3154, 'among': 3155, 'mess': 3156, 'pole': 3157, 'reg': 3158, 'audition': 3159, 'eek': 3160, 'singing': 3161, '0578': 3162, 'abta': 3163, 'cooked': 3164, '30ish': 3165, 'toa': 3166, 'payoh': 3167, 'piss': 3168, 'realise': 3169, 'snowman': 3170, 'convincing': 3171, 'fly': 3172, 'sumthin': 3173, 'lucy': 3174, 'kadeem': 3175, 'results': 3176, 'euro': 3177, 'relation': 3178, 'swatch': 3179, 'prepared': 3180, 'rcv': 3181, 'lies': 3182, 'twelve': 3183, 'treated': 3184, 'nimya': 3185, 'heater': 3186, 'vodka': 3187, '2000': 3188, 'agalla': 3189, 'polo': 3190, 'suite': 3191, '373': 3192, 'w1j': 3193, '6hl': 3194, 'wipro': 3195, 'connections': 3196, 'admin': 3197, '2wks': 3198, 'cheese': 3199, 'weirdest': 3200, 'txt82228': 3201, 'wifi': 3202, '40': 3203, '09061743806': 3204, 'box326': 3205, 'speed': 3206, 'speedchat': 3207, 'pobox36504w45wq': 3208, '09065171142': 3209, 'stopsms': 3210, 'thousands': 3211, 'supply': 3212, 'smokes': 3213, 'begging': 3214, '200': 3215, 'smith': 3216, 'ey': 3217, 'up4': 3218, 'enemy': 3219, 'ranjith': 3220, '5min': 3221, 'bless': 3222, 'manage': 3223, 'delivered': 3224, 'bears': 3225, 'vth': 3226, 'messenger': 3227, 'opening': 3228, 'bloomberg': 3229, 'urn': 3230, 'combine': 3231, 'secretary': 3232, 'engin': 3233, 'football': 3234, 'desperate': 3235, 'capital': 3236, 'trade': 3237, 'salon': 3238, 'decisions': 3239, 'mental': 3240, 'switch': 3241, 'sweets': 3242, 'picsfree1': 3243, 'vid': 3244, 'surfing': 3245, 'six': 3246, 'jane': 3247, 'newest': 3248, 'funky': 3249, '82468': 3250, 'moved': 3251, 'goal': 3252, 'henry': 3253, 'liverpool': 3254, 'scores': 3255, 'thgt': 3256, 'force': 3257, 'confused': 3258, 'pig': 3259, 'bleh': 3260, 'expression': 3261, 'shy': 3262, 'lovable': 3263, 'welp': 3264, 'flaky': 3265, 'parent': 3266, '09050003091': 3267, 'c52': 3268, 'ola': 3269, 'nd': 3270, 'argh': 3271, 'places': 3272, 'probs': 3273, '09050090044': 3274, 'toclaim': 3275, 'pobox334': 3276, 'stockport': 3277, 'costå£1': 3278, 'max10mins': 3279, 'jeans': 3280, 'gbp': 3281, 'strange': 3282, 'pre': 3283, 'smoking': 3284, 'paperwork': 3285, '08709222922': 3286, '8p': 3287, 'peak': 3288, 'coping': 3289, 'individual': 3290, 'fights': 3291, \"jay's\": 3292, 'galileo': 3293, 'lately': 3294, '08': 3295, 'divorce': 3296, 'wave': 3297, 'charles': 3298, 'uh': 3299, 'faggy': 3300, 'm26': 3301, '3uz': 3302, '86888': 3303, 'subscribe6gbp': 3304, '3hrs': 3305, 'txtstop': 3306, 'bright': 3307, 'flower': 3308, 'ruining': 3309, 'blu': 3310, 'smsco': 3311, 'keys': 3312, '88877': 3313, 'topic': 3314, 'ba': 3315, 'dress': 3316, 'sleepy': 3317, 'ques': 3318, 'suits': 3319, 'fastest': 3320, 'growing': 3321, 'privacy': 3322, 'listening': 3323, 'lounge': 3324, '87575': 3325, 'sake': 3326, 'sorted': 3327, 'idea': 3328, 'building': 3329, 'coat': 3330, 'tool': 3331, 'adoring': 3332, 'panic': 3333, 'å£1450': 3334, 'partnership': 3335, 'arent': 3336, 'slightly': 3337, 'wud': 3338, 'gentleman': 3339, 'dignity': 3340, 'thread': 3341, '69698': 3342, 'map': 3343, 'sachin': 3344, 'dealing': 3345, 'andros': 3346, 'shoes': 3347, 'behave': 3348, 'relatives': 3349, 'anywhere': 3350, 'praying': 3351, 'eighth': 3352, 'l': 3353, 'oz': 3354, 'genius': 3355, '15': 3356, 'ps': 3357, 'bang': 3358, 'sarcastic': 3359, 'language': 3360, 'members': 3361, 'tscs': 3362, 'skillgame': 3363, '1winaweek': 3364, '150ppermesssubscription': 3365, 'juicy': 3366, 'papers': 3367, 'convinced': 3368, 'gotten': 3369, 'tues': 3370, 'wks': 3371, 'bottom': 3372, '872': 3373, 'eaten': 3374, 'lovers': 3375, 'sender': 3376, 'sn': 3377, 'attached': 3378, 'valid12hrs': 3379, 'nitros': 3380, 'schools': 3381, 'bids': 3382, 'neck': 3383, 'include': 3384, 'discussed': 3385, 'poop': 3386, 'affair': 3387, 'goldviking': 3388, '762': 3389, 'darlings': 3390, 'modules': 3391, 'touched': 3392, 'lux': 3393, 'oil': 3394, 'tape': 3395, 'cross': 3396, 'ntwk': 3397, 'despite': 3398, 'txtin': 3399, '4info': 3400, 'truly': 3401, 'deus': 3402, \"that'll\": 3403, 'csbcm4235wc1n3xx': 3404, 'maxå£7': 3405, 'site': 3406, 'hugs': 3407, 'snogs': 3408, 'beloved': 3409, 'voicemail': 3410, 'dresser': 3411, 'wld': 3412, 'meanwhile': 3413, 'inch': 3414, 'academic': 3415, 'executive': 3416, 'calculation': 3417, 'killed': 3418, 'bein': 3419, 'lonely': 3420, 'math': 3421, 'germany': 3422, '85': 3423, 'dime': 3424, 'sue': 3425, 'thot': 3426, '4mths': 3427, 'mobilesdirect': 3428, '08000938767': 3429, 'or2stoptxt': 3430, 'suggest': 3431, 'electricity': 3432, 'passed': 3433, 'prof': 3434, 'sem': 3435, 'lov': 3436, 'transfered': 3437, 'shoppin': 3438, 'ability': 3439, 'slice': 3440, 'holy': 3441, 'condition': 3442, '0': 3443, 'dan': 3444, 'teaches': 3445, 'conducts': 3446, 'ne': 3447, 'interesting': 3448, 'hor': 3449, 'definite': 3450, 'donate': 3451, 'denis': 3452, 'forums': 3453, '26': 3454, 'lookatme': 3455, 'symbol': 3456, 'upto': 3457, 'delay': 3458, 'wrc': 3459, 'rally': 3460, 'lucozade': 3461, 'randomly': 3462, 'fav': 3463, 'huge': 3464, 'supervisor': 3465, 'annoying': 3466, '08712402050': 3467, '10ppm': 3468, 'ag': 3469, 'promo': 3470, 'sports': 3471, 'ansr': 3472, 'tyrone': 3473, '41685': 3474, '07': 3475, 'unemployed': 3476, 'pan': 3477, '2p': 3478, 'mumtaz': 3479, \"mumtaz's\": 3480, 'postcard': 3481, 'bottle': 3482, 'arcade': 3483, 'cme': 3484, 'visa': 3485, 'gucci': 3486, '08712402779': 3487, 'sometext': 3488, 'motivating': 3489, 'sharing': 3490, 'atm': 3491, 'cupboard': 3492, 'length': 3493, 'restocked': 3494, 'promotion': 3495, '8714714': 3496, 'noworriesloans': 3497, '08717111821': 3498, \"guy's\": 3499, 'darker': 3500, 'styling': 3501, 'tagged': 3502, 'count': 3503, 'whether': 3504, 'western': 3505, 'smell': 3506, 'tobacco': 3507, 'bro': 3508, 'amongst': 3509, '087147123779am': 3510, '08712402902': 3511, 'recharged': 3512, 'piggy': 3513, 'pansy': 3514, 'jungle': 3515, 'africa': 3516, 'avin': 3517, 'silver': 3518, 'truro': 3519, 'ext': 3520, 'completing': 3521, 'league': 3522, 'ambrith': 3523, 'madurai': 3524, 'arun': 3525, 'dha': 3526, 'marrge': 3527, \"'melle\": 3528, 'melle': 3529, 'minnaminunginte': 3530, 'nurungu': 3531, 'vettam': 3532, 'callfreefone': 3533, '08081560665': 3534, 'cruise': 3535, 'ofå£2000': 3536, '07786200117': 3537, '85233': 3538, 'å£12': 3539, '08718738002': 3540, '48922': 3541, 'stands': 3542, 'nitz': 3543, \"no's\": 3544, 'cosign': 3545, 'refund': 3546, 'onbus': 3547, 'donyt': 3548, 'latelyxxx': 3549, 'handsome': 3550, 'finding': 3551, 'goodo': 3552, 'ratio': 3553, 'tortilla': 3554, 'attracts': 3555, 'bluray': 3556, 'hack': 3557, 'backdoor': 3558, 'fraction': 3559, 'neo69': 3560, '09050280520': 3561, 'subscribe': 3562, 'dps': 3563, 'bcm': 3564, '8027': 3565, 'survey': 3566, 'habba': 3567, 'fumbling': 3568, \"harish's\": 3569, 'transfred': 3570, 'acnt': 3571, 'unni': 3572, 'recharge': 3573, 'fried': 3574, 'spares': 3575, 'looovvve': 3576, 'ip': 3577, 'minecraft': 3578, 'server': 3579, 'puttin': 3580, 'suggestion': 3581, 'lands': 3582, 'helps': 3583, 'forgt': 3584, 'toyota': 3585, 'camry': 3586, \"olayiwola's\": 3587, 'mileage': 3588, 'landing': 3589, 'betta': 3590, 'aging': 3591, 'products': 3592, 'paining': 3593, 'corect': 3594, 'speling': 3595, 'nokia6650': 3596, 'ctxt': 3597, 'mtmsg': 3598, 'cheery': 3599, 'ibm': 3600, 'hp': 3601, 'limping': 3602, 'aa': 3603, 'exhaust': 3604, 'chillaxin': 3605, 'designation': 3606, 'developer': 3607, '09066649731from': 3608, 'arrow': 3609, 'stil': 3610, 'fucked': 3611, 'tobed': 3612, '430': 3613, 'pathaya': 3614, 'enketa': 3615, 'maraikara': 3616, \"pa'\": 3617, 'gosh': 3618, 'spose': 3619, 'piece': 3620, 'salad': 3621, 'beers': 3622, '44': 3623, '7732584351': 3624, '9996': 3625, '14thmarch': 3626, 'availa': 3627, 'ignoring': 3628, 'bluff': 3629, 'squeeeeeze': 3630, 'frndshp': 3631, 'luvd': 3632, 'envy': 3633, \"see's\": 3634, 'scorable': 3635, 'dying': 3636, 'snap': 3637, 'quizclub': 3638, '80122300p': 3639, 'rwm': 3640, 'ph': 3641, '08704050406': 3642, 'supose': 3643, 'babysit': 3644, '84025': 3645, 'web2mobile': 3646, 'txt250': 3647, 'box139': 3648, 'la32wu': 3649, 'txtx': 3650, 'approve': 3651, 'panalam': 3652, 'posts': 3653, 'yah': 3654, 'simpler': 3655, 'magical': 3656, 'maggi': 3657, 'mee': 3658, 'rob': 3659, 'mack': 3660, 'gf': 3661, 'theater': 3662, 'macedonia': 3663, 'ì¼1': 3664, 'poboxox36504w45wq': 3665, 'victoria': 3666, 'island': 3667, 'postponed': 3668, 'stocked': 3669, 'logging': 3670, 'geoenvironmental': 3671, 'implications': 3672, 'east': 3673, 'washob': 3674, 'nobbing': 3675, 'nickey': 3676, 'platt': 3677, 'recpt': 3678, 'pose': 3679, 'comb': 3680, 'dryer': 3681, 'youi': 3682, '0789xxxxxxx': 3683, 'errors': 3684, 'correction': 3685, 'bffs': 3686, 'carly': 3687, 'cruisin': 3688, 'gower': 3689, 'åômorrow': 3690, 'philosophical': 3691, 'hole': 3692, 'nightnight': 3693, 'youdoing': 3694, 'physics': 3695, 'abbey': 3696, 'newspapers': 3697, 'esaplanade': 3698, '0845': 3699, '2814032': 3700, '3xå£150pw': 3701, 'eå£nd': 3702, 'referin': 3703, \"mei's\": 3704, '0808': 3705, '145': 3706, '4742': 3707, '9am': 3708, '11pm': 3709, 'gotto': 3710, '220cm2': 3711, 'church': 3712, 'olympics': 3713, 'beta': 3714, 'needy': 3715, 'drizzling': 3716, 'rodds1': 3717, 'aberdeen': 3718, 'united': 3719, 'kingdom': 3720, 'img': 3721, 'icmb3cktz8r7': 3722, 'hide': 3723, \"phone's\": 3724, 'vibrate': 3725, 'acting': 3726, 'i\\x89û÷ve': 3727, 'salt': 3728, 'wounds': 3729, 'copied': 3730, '69200': 3731, 'chrgd': 3732, '2exit': 3733, 'dizzamn': 3734, 'suitemates': 3735, 'powerful': 3736, 'weapon': 3737, 'occupy': 3738, \"'heart'\": 3739, 'jersey': 3740, 'devils': 3741, 'wings': 3742, 'hockey': 3743, 'incorrect': 3744, 'beerage': 3745, 'commit': 3746, 'establish': 3747, 'ree': 3748, 'pump': 3749, 'dump': 3750, 'heap': 3751, 'lowes': 3752, 'justbeen': 3753, 'overa': 3754, 'brains': 3755, 'mush': 3756, 'reception': 3757, 'luton': 3758, '0125698789': 3759, 'corporation': 3760, \"fr'ndship\": 3761, 'needle': 3762, 'itz': 3763, '4few': 3764, 'conected': 3765, 'explicitly': 3766, 'nora': 3767, 'teenager': 3768, 'degree': 3769, 'famamus': 3770, 'suffering': 3771, 'dysentry': 3772, 'stairs': 3773, 'phews': 3774, 'french': 3775, 'fooled': 3776, 'mix': 3777, '85069': 3778, 'usher': 3779, 'britney': 3780, 'westshore': 3781, 'halloween': 3782, 'eerie': 3783, '08701417012150p': 3784, 'yellow': 3785, 'expired': 3786, 'monoc': 3787, 'monos': 3788, 'polyc': 3789, 'stream': 3790, '0871212025016': 3791, 'nothin': 3792, 'hanger': 3793, 'poortiyagi': 3794, 'odalebeku': 3795, 'hanumanji': 3796, 'hanuman': 3797, 'bajarangabali': 3798, 'maruti': 3799, 'pavanaputra': 3800, 'sankatmochan': 3801, 'ramaduth': 3802, 'mahaveer': 3803, 'janarige': 3804, 'ivatte': 3805, 'kalisidare': 3806, 'olage': 3807, 'ondu': 3808, 'keluviri': 3809, 'maretare': 3810, 'inde': 3811, 'dodda': 3812, 'problum': 3813, 'nalli': 3814, 'siguviri': 3815, 'idu': 3816, 'matra': 3817, 'neglet': 3818, 'club4mobiles': 3819, '87070': 3820, 'club4': 3821, 'box1146': 3822, 'mk45': 3823, '2wt': 3824, 'iphone': 3825, 'congratulation': 3826, 'lubly': 3827, 'fassyole': 3828, 'blacko': 3829, 'londn': 3830, 'freezing': 3831, 'craving': 3832, 'blogging': 3833, 'magicalsongs': 3834, 'blogspot': 3835, 'onam': 3836, 'sirji': 3837, 'insha': 3838, 'tata': 3839, 'aig': 3840, 'tissco': 3841, 'tayseer': 3842, 'garments': 3843, 'shirts': 3844, 'nudist': 3845, 'themed': 3846, 'grab': 3847, 'cultures': 3848, 'everyones': 3849, 'babysitting': 3850, 'woodland': 3851, 'avenue': 3852, 'parish': 3853, 'magazine': 3854, 'ijust': 3855, 'talked': 3856, 'skint': 3857, 'fancied': 3858, 'bevies': 3859, 'waz': 3860, 'othrs': 3861, 'spoon': 3862, 'watchng': 3863, 'comfey': 3864, \"aunty's\": 3865, 'affidavit': 3866, 'twiggs': 3867, 'division': 3868, 'courtroom': 3869, 'weekdays': 3870, 'nails': 3871, 'tddnewsletter': 3872, 'emc1': 3873, 'thedailydraw': 3874, 'dozens': 3875, 'prizeswith': 3876, 'wisheds': 3877, 'goigng': 3878, 'perfume': 3879, 'lyricalladie': 3880, 'hmmross': 3881, 'pleasant': 3882, 'statements': 3883, '09064018838': 3884, 'cro1327': 3885, \"all's\": 3886, '09058094455': 3887, 'goggles': 3888, 'cloth': 3889, 'anybody': 3890, 'asks': 3891, 'arabian': 3892, 'steed': 3893, 'giggle': 3894, 'possibly': 3895, 'person2die': 3896, 'nvq': 3897, '32': 3898, 'squeezed': 3899, '08002986030': 3900, '7548': 3901, '4041': 3902, '2hrs': 3903, 'oyster': 3904, 'sashimi': 3905, 'rumbling': 3906, 'bird': 3907, 'purchases': 3908, 'magic': 3909, 'northampton': 3910, 'presents': 3911, 'nicky': 3912, 'womdarfull': 3913, 'mushy': 3914, 'embarrassed': 3915, 'hundreds': 3916, 'handsomes': 3917, 'beauties': 3918, 'aunties': 3919, 'apology': 3920, 'scarcasim': 3921, 'duffer': 3922, \"dip's\": 3923, 'pee': 3924, 'burns': 3925, 'directors': 3926, 'lac': 3927, 'deposited': 3928, \"'taxless'\": 3929, 'delhi': 3930, 'suply': 3931, 'projects': 3932, 'imf': 3933, 'blocked': 3934, 'corrupt': 3935, 'itna': 3936, 'karo': 3937, 'ki': 3938, 'pura': 3939, 'padhe': 3940, 'apes': 3941, 'death': 3942, 'period': 3943, 'guai': 3944, 'ubandu': 3945, 'disk': 3946, 'dancin': 3947, 'grr': 3948, 'pharmacy': 3949, 'split': 3950, \"ryan's\": 3951, 'resent': 3952, 'failed': 3953, 'queries': 3954, 'customersqueries': 3955, 'netvision': 3956, 'arguing': 3957, 'catches': 3958, 'wallet': 3959, 'linear': 3960, 'algebra': 3961, 'gray': 3962, 'listn': 3963, 'watevr': 3964, 'bangbabes': 3965, 'bangb': 3966, 'brother\\x89û÷s': 3967, 'scraped': 3968, 'barrel': 3969, 'misfits': 3970, 'seventeen': 3971, 'ml': 3972, 'listed': 3973, '08715500022': 3974, 'rpl': 3975, 'cnl': 3976, '2nights': 3977, 'uve': 3978, 'wildest': 3979, 'presnts': 3980, 'bcz': 3981, 'jeevithathile': 3982, 'irulinae': 3983, 'neekunna': 3984, 'prakasamanu': 3985, 'sneham': 3986, 'prakasam': 3987, 'ennal': 3988, \"'that\": 3989, 'mns': 3990, \"is'love'\": 3991, 'experiencehttp': 3992, 'vouch4me': 3993, 'etlp': 3994, 'shitin': 3995, 'defo': 3996, 'hardest': 3997, 'millions': 3998, 'lekdog': 3999, 'confuses': 4000, 'doesn\\x89û÷t': 4001, 'narcotics': 4002, 'buttons': 4003, 'rats': 4004, 'themes': 4005, 'guild': 4006, 'singapore': 4007, 'tats': 4008, 'copies': 4009, 'urgh': 4010, 'coach': 4011, 'smells': 4012, 'chip': 4013, 'duvet': 4014, 'predictive': 4015, 'fortune': 4016, 'healthy': 4017, 'alibi': 4018, 'cutting': 4019, 'snickering': 4020, 'chords': 4021, 'requirements': 4022, 'mega': 4023, 'asda': 4024, 'counts': 4025, \"ashley's\": 4026, 'shortcode': 4027, '83332': 4028, '08081263000': 4029, 'refunded': 4030, 'evo': 4031, 'gibbs': 4032, 'mike': 4033, 'hussey': 4034, 'lara': 4035, '09099725823': 4036, 'poorly': 4037, 'punishment': 4038, 'brb': 4039, 'kill': 4040, 'ahhhh': 4041, 'whose': 4042, 'tkls': 4043, 'stoptxtstopå£1': 4044, 'reserve': 4045, 'thirunelvali': 4046, 'tackle': 4047, 'quiteamuzing': 4048, 'thatåõscool': 4049, 'hen': 4050, '8pm': 4051, 'printer': 4052, 'groovy': 4053, 'groovying': 4054, 'practising': 4055, 'curtsey': 4056, 'gota': 4057, 'responce': 4058, 'yalrigu': 4059, 'heltini': 4060, 'iyo': 4061, 'shared': 4062, 'uttered': 4063, 'trusting': 4064, 'hu': 4065, 'preferably': 4066, 'smart': 4067, 'navigate': 4068, 'choosing': 4069, 'require': 4070, 'guidance': 4071, \"finn's\": 4072, 'lamp': 4073, 'cps': 4074, 'outages': 4075, 'conserve': 4076, 'kilos': 4077, 'fudge': 4078, 'oreos': 4079, 'farting': 4080, 'chit': 4081, 'logon': 4082, '8883': 4083, 'cm': 4084, '4217': 4085, 'w1a': 4086, '6zf': 4087, '118p': 4088, 'mouse': 4089, 'desk': 4090, '0089': 4091, 'digits': 4092, '09063442151': 4093, 'foward': 4094, 'icic': 4095, 'necesity': 4096, 'witout': 4097, \"hw'd\": 4098, 'colleg': 4099, \"wat'll\": 4100, 'wth': 4101, 'functions': 4102, 'events': 4103, \"espe'll\": 4104, 'irritated': 4105, '4wrd': 4106, 'wthout': 4107, 'takecare': 4108, 'sayy': 4109, 'cards': 4110, 'impressed': 4111, 'funs': 4112, 'secretly': 4113, 'fancies': 4114, '09065394514': 4115, 'datebox1282essexcm61xn': 4116, 'bay': 4117, 'flew': 4118, 'anna': 4119, 'nagar': 4120, 'starshine': 4121, 'sips': 4122, 'cappuccino': 4123, 'tim': 4124, 'bollox': 4125, 'tol': 4126, 'clarification': 4127, '2u2': 4128, 'wuld': 4129, 'everyboy': 4130, 'xxxxxxxx': 4131, 'ofcourse': 4132, 'brum': 4133, 'torrents': 4134, 'particularly': 4135, 'slowing': 4136, 'apologetic': 4137, 'fallen': 4138, 'actin': 4139, 'spoilt': 4140, 'badly': 4141, 'temple': 4142, 'weåõve': 4143, 'mint': 4144, 'hype': 4145, 'studio': 4146, 'bedrm': 4147, 'young': 4148, 'dawns': 4149, 'refreshed': 4150, 'howda': 4151, 'mathe': 4152, 'samachara': 4153, 'iåõd': 4154, 'configure': 4155, 'perpetual': 4156, 'dd': 4157, 'rounds': 4158, 'payasam': 4159, 'rinu': 4160, 'closes': 4161, '54': 4162, 'resubmit': 4163, 'expiry': 4164, 'horse': 4165, 'rice': 4166, 'lighters': 4167, 'receipts\\x89ûówell': 4168, 'what\\x89û÷s': 4169, 'bunkers': 4170, '1172': 4171, 'removal': 4172, '08708034412': 4173, 'pride': 4174, 'kid': 4175, 'grownup': 4176, '09058095201': 4177, 'mobs': 4178, 'title': 4179, 'breathe1': 4180, 'titles': 4181, 'crazyin': 4182, 'sleepingwith': 4183, 'finest': 4184, 'ymca': 4185, 'pobox365o4w45wq': 4186, '300p': 4187, 'stagwood': 4188, 'winterstone': 4189, 'victors': 4190, 'mittelschmertz': 4191, 'paracetamol': 4192, 'manageable': 4193, 'cedar': 4194, 'lancaster': 4195, 'neway': 4196, 'couldnåõt': 4197, '08717898035': 4198, 'mentor': 4199, 'percent': 4200, 'sonathaya': 4201, 'soladha': 4202, 'srs': 4203, 'crucial': 4204, \"someone's\": 4205, 'sabarish': 4206, '83118': 4207, 'colin': 4208, 'farrell': 4209, 'swat': 4210, 'med': 4211, 'mre': 4212, 'jackson': 4213, 'coveragd': 4214, 'vasai': 4215, \"4'o\": 4216, 'broth': 4217, 'ramen': 4218, 'tightly': 4219, 'sindu': 4220, 'shell': 4221, 'unconsciously': 4222, 'unhappy': 4223, '08712103738': 4224, 'i\\x89ûªm': 4225, 'isn\\x89ûªt': 4226, 'thinked': 4227, 'swan': 4228, 'rimac': 4229, 'inshah': 4230, '08719839835': 4231, 'mgs': 4232, '89123': 4233, 'weirdo': 4234, 'hotmail': 4235, 'burial': 4236, 'ashwini': 4237, '24m': 4238, 'jontin': 4239, '09066362220': 4240, 'supports': 4241, 'srt': 4242, 'ps3': 4243, 'hf8': 4244, 'prestige': 4245, 'imin': 4246, 'dontmatter': 4247, 'urgoin': 4248, 'outl8r': 4249, 'formatting': 4250, 'punish': 4251, 'okday': 4252, 'checkmate': 4253, 'chess': 4254, 'persian': 4255, 'phrase': 4256, 'shah': 4257, 'maat': 4258, 'pleasured': 4259, 'videos': 4260, 'shsex': 4261, 'netun': 4262, 'fgkslpopw': 4263, 'fgkslpo': 4264, 'papa': 4265, 'appendix': 4266, 'paypal': 4267, 'voila': 4268, 'pockets': 4269, 'infra': 4270, 'btwn': 4271, 'gaps': 4272, 'funeral': 4273, 'audrey': 4274, '0796xxxxxx': 4275, 'prizeawaiting': 4276, 'olave': 4277, 'mandara': 4278, 'trishul': 4279, 'purple': 4280, 'lyk': 4281, 'yelow': 4282, 'brown': 4283, 'surly': 4284, 'belongs': 4285, 'fated': 4286, 'shoranur': 4287, 'fuelled': 4288, 'concern': 4289, 'prior': 4290, 'grief': 4291, 'board': 4292, 'overheating': 4293, 'reslove': 4294, 'inst': 4295, \"8'o\": 4296, 'tooo': 4297, \"'simple'\": 4298, 'nte': 4299, 'dang': 4300, 'regretted': 4301, 'boltblue': 4302, 'poly3': 4303, 'jamz': 4304, 'toxic': 4305, 'mandy': 4306, 'sullivan': 4307, 'hotmix': 4308, 'fm': 4309, '09041940223': 4310, 'transferred': 4311, 'real1': 4312, 'pushbutton': 4313, 'dontcha': 4314, 'babygoodbye': 4315, 'golddigger': 4316, 'webeburnin': 4317, 'shitstorm': 4318, 'attributed': 4319, 'easily': 4320, 'lengths': 4321, 'behalf': 4322, 'stunning': 4323, 'chase': 4324, 'crossing': 4325, \"anybody's\": 4326, 'tactful': 4327, 'lightly': 4328, 'checkboxes': 4329, 'gprs': 4330, 'leo': 4331, '515': 4332, 'classes': 4333, 'sparkling': 4334, 'breaks': 4335, '45': 4336, '0121': 4337, '2025050': 4338, 'shortbreaks': 4339, 'org': 4340, 'univ': 4341, 'dileep': 4342, 'muchand': 4343, 'venugopal': 4344, 'mentioned': 4345, 'openings': 4346, 'upcharge': 4347, 'yalru': 4348, 'astne': 4349, 'innu': 4350, 'mundhe': 4351, 'halla': 4352, 'ke': 4353, 'bilo': 4354, 'edhae': 4355, 'ovr': 4356, 'vargu': 4357, 'ami': 4358, 'parchi': 4359, 'kicchu': 4360, 'kaaj': 4361, 'korte': 4362, 'iccha': 4363, 'korche': 4364, 'tul': 4365, 'hangin': 4366, 'marandratha': 4367, 'teju': 4368, 'ilol': 4369, 'personally': 4370, 'wuldnt': 4371, 'haiyoh': 4372, 'million': 4373, 'invitation': 4374, 'cali': 4375, \"bloke's\": 4376, 'weddin': 4377, 'sozi': 4378, 'culdnt': 4379, 'talkbut': 4380, 'wannatell': 4381, 'wenwecan': 4382, 'dudette': 4383, 'neshanth': 4384, '1pm': 4385, '09066368470': 4386, 'allo': 4387, 'braved': 4388, 'triumphed': 4389, 'b\\x89û÷ham': 4390, 'jolly': 4391, 'natwest': 4392, 'ammae': 4393, 'steering': 4394, 'flavour': 4395, 'disturbance': 4396, 'dlf': 4397, 'premarica': 4398, 'lodge': 4399, 'ths': 4400, 'ias': 4401, 'velusamy': 4402, \"sir's\": 4403, 'facilities': 4404, 'otside': 4405, 'absolutly': 4406, 'convenience': 4407, \"mine's\": 4408, 'totes': 4409, 'melody': 4410, 'heehee': 4411, 'chic': 4412, 'declare': 4413, 'tootsie': 4414, 'gep': 4415, 'å£750': 4416, '087187272008': 4417, 'now1': 4418, 'defer': 4419, 'admission': 4420, 'swashbuckling': 4421, 'optin': 4422, 'bbc': 4423, 'charts': 4424, 'elephant': 4425, 'shove': 4426, 'um': 4427, 'questioned': 4428, 'gardener': 4429, 'vegetables': 4430, 'neighbour': 4431, 'buffy': 4432, 'qlynnbv': 4433, 'help08700621170150p': 4434, 'huiming': 4435, '09071517866': 4436, '150ppmpobox10183bhamb64xe': 4437, 'musical': 4438, 'brighten': 4439, 'lodging': 4440, 'grandmas': 4441, 'hungover': 4442, 'smsing': 4443, 'spageddies': 4444, 'win150ppmx3age16': 4445, 'jod': 4446, 'keris': 4447, 'smidgin': 4448, '15pm': 4449, 'edison': 4450, 'rightly': 4451, 'viva': 4452, 'gm': 4453, 'chuckin': 4454, 'trainners': 4455, 'carryin': 4456, 'bac': 4457, 'upping': 4458, 'grams': 4459, 'soooo': 4460, 'provider': 4461, 'tming': 4462, 'block': 4463, 'armenia': 4464, 'swann': 4465, 'burgundy': 4466, 'captaining': 4467, 'claims': 4468, '09050005321': 4469, 'dismay': 4470, 'shorts': 4471, 'webadres': 4472, 'geting': 4473, '09061744553': 4474, 'polyh': 4475, 'maintain': 4476, 'cr': 4477, 'entertain': 4478, 'funk': 4479, 'tones2u': 4480, 'cousin': 4481, 'payback': 4482, 'kvb': 4483, '449050000301': 4484, '09050000301': 4485, 'lf56': 4486, 'memory': 4487, \"something's\": 4488, 'nowhere': 4489, 'ikno': 4490, 'doesdiscount': 4491, 'shitinnit': 4492, 'deserve': 4493, 'asthma': 4494, 'attack': 4495, 'u4': 4496, 'knickers': 4497, '01223585236': 4498, 'nikiyu4': 4499, \"idea's\": 4500, 'anyplaces': 4501, '60': 4502, '400thousad': 4503, 'evaluation': 4504, '07734396839': 4505, 'ibh': 4506, 'nokia6600': 4507, 'lifting': 4508, 'treats': 4509, 'pert': 4510, 'head\\x89û': 4511, 'infact': 4512, '09050000878': 4513, 'ovulate': 4514, '3wks': 4515, 'poking': 4516, 'mising': 4517, 'passion': 4518, '09099726481': 4519, 'dena': 4520, '09061743386': 4521, 'swhrt': 4522, 'cheat': 4523, 'fatty': 4524, 'jb': 4525, 'noncomittal': 4526, 'rstm': 4527, 'sw7': 4528, '3ss': 4529, 'slp': 4530, 'muah': 4531, '7cfca1a': 4532, 'amk': 4533, 'jacuzzi': 4534, 'worc': 4535, 'foregate': 4536, 'shrub': 4537, '07753741225': 4538, '08715203677': 4539, '42478': 4540, 'objection': 4541, 'vijaykanth': 4542, 'drunken': 4543, \"'maangalyam\": 4544, 'alaipayuthe': 4545, 'crap': 4546, 'boggy': 4547, 'biatch': 4548, 'danger': 4549, 'peeps': 4550, 'comment': 4551, \"l'm\": 4552, 'hvae': 4553, '09061701444': 4554, 'acl03530150pm': 4555, 'marvel': 4556, 'ultimate': 4557, '83338': 4558, '8ball': 4559, \"friend's\": 4560, 'babies': 4561, 'hmph': 4562, 'baller': 4563, 'konw': 4564, 'waht': 4565, 'rael': 4566, 'gving': 4567, 'exmpel': 4568, 'jsut': 4569, 'ese': 4570, 'evrey': 4571, 'splleing': 4572, 'wrnog': 4573, 'sitll': 4574, 'raed': 4575, 'wihtuot': 4576, 'ayn': 4577, 'mitsake': 4578, 'dedicated': 4579, 'dedicate': 4580, 'satanic': 4581, 'imposter': 4582, 'destiny': 4583, 'nike': 4584, 'petey': 4585, 'noiåõm': 4586, 'js': 4587, 'cocksuckers': 4588, 'ipads': 4589, 'worthless': 4590, 'novelty': 4591, 'holby': 4592, '4qf2': 4593, 'hillsborough': 4594, 'lavender': 4595, 'steamboat': 4596, 'restrict': 4597, 'hppnss': 4598, 'sorrow': 4599, 'goodfriend': 4600, 'rules': 4601, 'responsibility': 4602, 'bend': 4603, 'thia': 4604, 'inlude': 4605, 'previews': 4606, 'profile': 4607, 'bpo': 4608, 'posh': 4609, 'chaps': 4610, 'trial': 4611, 'prods': 4612, 'champneys': 4613, 'dob': 4614, '08701213186': 4615, 'returns': 4616, 'lingo': 4617, '448712404000': 4618, '08712404000': 4619, 'ducking': 4620, 'chinchillas': 4621, 'tamilnadu': 4622, 'perf': 4623, 'qet': 4624, '07801543489': 4625, 'latests': 4626, 'llc': 4627, 'ny': 4628, 'usa': 4629, 'msgrcvd18': 4630, 'shaking': 4631, 'dance': 4632, 'onum': 4633, 'ela': 4634, 'taste': 4635, 'stories': 4636, \"table's\": 4637, 'occupied': 4638, '8800': 4639, 'psp': 4640, 'manual': 4641, 'reset': 4642, 'troubleshooting': 4643, 'proze': 4644, 'norcorp': 4645, 'misbehaved': 4646, 'hooch': 4647, 'toaday': 4648, 'splat': 4649, 'grazed': 4650, 'knees': 4651, 'uv': 4652, 'causes': 4653, 'mutations': 4654, 'sunscreen': 4655, 'thesedays': 4656, '930': 4657, 'gam': 4658, 'vill': 4659, 'orc': 4660, 'sane': 4661, 'helping': 4662, '08712101358': 4663, 'seekers': 4664, 'dismissial': 4665, 'non': 4666, 'childporn': 4667, 'diddy': 4668, 'neighbor': 4669, 'toothpaste': 4670, 'erutupalam': 4671, 'thandiyachu': 4672, 'amrita': 4673, 'accidant': 4674, 'tookplace': 4675, 'ghodbandar': 4676, 'slovely': 4677, 'timi': 4678, 'dessert': 4679, 'u\\x89ûªve': 4680, 'instant': 4681, '08715203028': 4682, '9th': 4683, 'ideal': 4684, 'path': 4685, 'appear': 4686, 'paths': 4687, 'owns': 4688, 'predicte': 4689, 'surname': 4690, 'clue': 4691, 'begins': 4692, 'emotion': 4693, 'prayrs': 4694, 'othrwise': 4695, 'slaaaaave': 4696, 'summon': 4697, 'woul': 4698, 'curfew': 4699, 'gibe': 4700, 'getsleep': 4701, 'studdying': 4702, '1mega': 4703, 'pixels': 4704, '3optical': 4705, '5digital': 4706, 'dooms': 4707, 'feathery': 4708, 'bowa': 4709, '88800': 4710, '89034': 4711, '08718711108': 4712, 'printed': 4713, 'upstairs': 4714, 'auntie': 4715, 'huai': 4716, 'peach': 4717, 'tasts': 4718, 'shanghai': 4719, '21st': 4720, 'cya': 4721, 'hme': 4722, 'oga': 4723, 'level': 4724, 'buzy': 4725, 'sth': 4726, 'specs': 4727, 'px3748': 4728, 'asia': 4729, 'greatest': 4730, 'courage': 4731, 'bear': 4732, 'defeat': 4733, 'tonights': 4734, '12mths': 4735, '400mins': 4736, 'j5q': 4737, '146tf150p': 4738, \"'need'\": 4739, \"'comfort'\": 4740, \"'luxury'\": 4741, 'sold': 4742, \"g's\": 4743, 'ammo': 4744, 'ak': 4745, 'judgemental': 4746, 'fridays': 4747, 'flying': 4748, 'monkeys': 4749, 'certainly': 4750, 'caveboy': 4751, '08707500020': 4752, 'spirit': 4753, 'hasbro': 4754, 'jump': 4755, 'hoops': 4756, '08714712379': 4757, 'strt': 4758, 'ltdhelpdesk': 4759, '02085076972': 4760, 'lark': 4761, 'wan2': 4762, 'westlife': 4763, 'm8': 4764, 'unbreakable': 4765, 'untamed': 4766, 'unkempt': 4767, '83049': 4768, 'å£75': 4769, 'homeowners': 4770, 'previously': 4771, '1956669': 4772, 'vco': 4773, 'view': 4774, 'gays': 4775, 'balloon': 4776, 'uncountable': 4777, 'walsall': 4778, 'tue': 4779, 'terry': 4780, 'engalnd': 4781, 'mia': 4782, 'elliot': 4783, 'kissing': 4784, 'breaking': 4785, 'cstore': 4786, 'sittin': 4787, 'wind': 4788, 'drops': 4789, '0721072': 4790, 'rp176781': 4791, 'regalportfolio': 4792, '08717205546': 4793, 'shocking': 4794, 'sundayish': 4795, 'neft': 4796, 'beneficiary': 4797, '6times': 4798, 'cts': 4799, 'employee': 4800, 'annie': 4801, 'meatballs': 4802, 'free2day': 4803, \"george's\": 4804, '89080': 4805, '0870241182716': 4806, 'whore': 4807, 'unbelievable': 4808, 'noice': 4809, 'devouring': 4810, 'epi': 4811, '5k': 4812, '09064011000': 4813, 'cr01327bt': 4814, 'fixedline': 4815, 'thirtyeight': 4816, 'progress': 4817, 'arestaurant': 4818, 'squid': 4819, 'dosomething': 4820, 'trained': 4821, 'advisors': 4822, 'dialling': 4823, '402': 4824, 'popped': 4825, 'loo': 4826, 'ed': 4827, 'coincidence': 4828, 'genuine': 4829, '100percent': 4830, 'janx': 4831, 'dads': 4832, 'court': 4833, 'dumb': 4834, 'åè10': 4835, 'evey': 4836, 'gailxx': 4837, 'chloe': 4838, 'smashed': 4839, 'bothering': 4840, 'raping': 4841, 'dudes': 4842, 'poker': 4843, 'stressfull': 4844, 'adds': 4845, 'cudnt': 4846, 'drove': 4847, 'ctla': 4848, 'ente': 4849, 'ishtamayoo': 4850, 'bakrid': 4851, 'drivby': 4852, '0quit': 4853, 'edrunk': 4854, 'iff': 4855, 'pthis': 4856, 'senrd': 4857, 'dnot': 4858, 'dancce': 4859, 'drum': 4860, 'basq': 4861, 'ihave': 4862, '2nhite': 4863, 'ros': 4864, 'xxxxxxx': 4865, 'smoked': 4866, 'compliments': 4867, 'pours': 4868, 'smash': 4869, 'religiously': 4870, 'watts': 4871, 'diesel': 4872, 'brainy': 4873, 'wrkin': 4874, 'mmmmm': 4875, 'hlday': 4876, 'camp': 4877, 'amrca': 4878, 'serena': 4879, 'browsin': 4880, 'compulsory': 4881, 'astrology': 4882, 'gastroenteritis': 4883, 'replace': 4884, 'reduce': 4885, 'limiting': 4886, 'illness': 4887, 'bleak': 4888, 'filled': 4889, 'mylife': 4890, 'rt': 4891, 'pro': 4892, '08701237397': 4893, 'redeemable': 4894, 'luckily': 4895, 'starring': 4896, 'delete': 4897, 'tag': 4898, 'laundry': 4899, 'underwear': 4900, 'bras': 4901, 'strewn': 4902, 'pillows': 4903, 'lingerie': 4904, 'bridal': 4905, 'petticoatdreams': 4906, 'weddingfriend': 4907, \"valentine's\": 4908, '69101': 4909, 'rtf': 4910, 'sphosting': 4911, 'dentist': 4912, 'connect': 4913, '09094646899': 4914, 'vu': 4915, 'bcm1896wc1n3xx': 4916, 'mapquest': 4917, 'dogwood': 4918, 'dull': 4919, '2bold': 4920, 'worrying': 4921, 'quizzes': 4922, 'jelly': 4923, 'screwd': 4924, 'qjkgighjjgcbl': 4925, 'gloucesterroad': 4926, 'uup': 4927, 'dub': 4928, 'je': 4929, 'bot': 4930, 'notes': 4931, 'involved': 4932, '07742676969': 4933, '08719180248': 4934, 'bomb': 4935, 'skye': 4936, 'stressed': 4937, 'simpsons': 4938, 'band': 4939, 'storming': 4940, 'phne': 4941, 'wt': 4942, 'margaret': 4943, 'girlfrnd': 4944, 'grahmbell': 4945, 'invnted': 4946, 'telphone': 4947, '4get': 4948, 'wasnt': 4949, 'wither': 4950, '23f': 4951, '23g': 4952, 'appy': 4953, 'fizz': 4954, 'contains': 4955, 'signin': 4956, \"1's\": 4957, 'inever': 4958, 'barred': 4959, 'twat': 4960, 'dungerees': 4961, 'decking': 4962, 'punch': 4963, 'virgins': 4964, 'sexual': 4965, 'theirs': 4966, '69911': 4967, 'werethe': 4968, 'monkeespeople': 4969, 'monkeyaround': 4970, 'howdy': 4971, 'swimsuit': 4972, 'identification': 4973, 'timin': 4974, 'disappointment': 4975, \"party's\": 4976, 'contribute': 4977, 'greatly': 4978, 'citylink': 4979, 'obedient': 4980, 'note': 4981, 'exposed': 4982, 'vomiting': 4983, 'sian': 4984, 'printing': 4985, 'handing': 4986, 'dust': 4987, 'mth': 4988, 'kit': 4989, 'strip': 4990, '1013': 4991, 'ig11': 4992, 'oja': 4993, 'initiate': 4994, 'dependents': 4995, 'mornin': 4996, 'thanku': 4997, 'yoyyooo': 4998, 'permissions': 4999, 'mac': 5000, 'sporadically': 5001, 'miwa': 5002, 'weaknesses': 5003, \"knee's\": 5004, 'exposes': 5005, 'pulls': 5006, 'wicked': 5007, 'chapel': 5008, 'frontierville': 5009, 'bowls': 5010, 'adventuring': 5011, 'watched': 5012, 'prin': 5013, 'bits': 5014, 'timings': 5015, '09066368753': 5016, '97n7qp': 5017, 'squishy': 5018, 'mwahs': 5019, 'unconvinced': 5020, 'elaborate': 5021, 'willpower': 5022, 'badrith': 5023, 'filthyguys': 5024, '4msgs': 5025, '09095350301': 5026, 'erotic': 5027, 'ecstacy': 5028, 'lakhs': 5029, 'fridge': 5030, '0870737910216yrs': 5031, 'playng': 5032, 'intrude': 5033, 'evr': 5034, 'adewale': 5035, 'egbon': 5036, 'disappeared': 5037, '447801259231': 5038, '09058094597': 5039, 'hdd': 5040, 'casing': 5041, 'apologize': 5042, 'admit': 5043, \"riley's\": 5044, 'faith': 5045, 'misundrstud': 5046, 'tiime': 5047, 'tears': 5048, 'disagreeable': 5049, 'learned': 5050, 'eldest': 5051, 'hire': 5052, 'hitman': 5053, 'arm': 5054, 'stuffs': 5055, 'andre': 5056, \"virgil's\": 5057, '83435': 5058, 'remembrs': 5059, 'forgets': 5060, 'everytime': 5061, '2channel': 5062, 'leadership': 5063, 'skills': 5064, 'psychic': 5065, 'spun': 5066, 'wrld': 5067, 'teams': 5068, 'chechi': 5069, 'phony': 5070, '3100': 5071, 'proper': 5072, 'tongued': 5073, 'wrks': 5074, 'swell': 5075, 'ball': 5076, 'spin': 5077, 'bmw': 5078, 'urgently': 5079, 'shortage': 5080, 'source': 5081, 'arng': 5082, 'amt': 5083, 'canteen': 5084, 'panther': 5085, 'sugababes': 5086, 'zebra': 5087, 'animation': 5088, 'badass': 5089, 'hoody': 5090, 'repairs': 5091, 'followin': 5092, 'go2sri': 5093, 'lanka': 5094, 'bridgwater': 5095, 'banter': 5096, 'arrived': 5097, 'celebrations': 5098, 'toledo': 5099, 'tscs08714740323': 5100, '1winawk': 5101, '50perweeksub': 5102, '08715203685': 5103, '4xx26': 5104, '13': 5105, 'quiet': 5106, 'beth': 5107, 'aunts': 5108, 'charlie': 5109, 'torture': 5110, 'superior': 5111, 'ours': 5112, 'waheed': 5113, 'conform': 5114, 'improved': 5115, 'hearts': 5116, '077xxx': 5117, '09066362206': 5118, 'å£600': 5119, 'landmark': 5120, 'bob': 5121, 'barry': 5122, '83738': 5123, 'literally': 5124, 'nowadays': 5125, 'notixiquating': 5126, 'laxinorficated': 5127, 'bambling': 5128, 'entropication': 5129, 'oblisingately': 5130, 'opted': 5131, 'masteriastering': 5132, 'amplikater': 5133, 'fidalfication': 5134, 'champlaxigating': 5135, 'atrocious': 5136, 'wotz': 5137, 'junna': 5138, '08712402972': 5139, 'propsd': 5140, 'gv': 5141, 'lv': 5142, 'lttrs': 5143, 'threw': 5144, 'aproach': 5145, 'dt': 5146, 'truck': 5147, 'speeding': 5148, 'wn': 5149, 'ran': 5150, \"'hw\": 5151, 'instantly': 5152, 'shouted': 5153, 'thy': 5154, 'lived': 5155, 'happily': 5156, '2gthr': 5157, 'evrydy': 5158, 'ingredients': 5159, 'crowd': 5160, 'lined': 5161, 'mostly': 5162, 'broadband': 5163, 'successfully': 5164, 'installation': 5165, 'forum': 5166, 'buyers': 5167, 'lunchtime': 5168, 'organise': 5169, 'pooja': 5170, 'sweatter': 5171, 'ninish': 5172, 'icky': 5173, 'freek': 5174, 'jen': 5175, 'losers': 5176, 'x2': 5177, 'folks': 5178, 'joys': 5179, 'lifeis': 5180, 'daywith': 5181, 'somewheresomeone': 5182, 'tosend': 5183, 'greeting': 5184, 'posting': 5185, 'supplies': 5186, 'wahala': 5187, 'kills': 5188, 'recieve': 5189, 'conditions': 5190, 'teletext': 5191, 'iron': 5192, 'hopeing': 5193, 'wasn\\x89û÷t': 5194, 'sisters': 5195, 'missionary': 5196, 'gravel': 5197, '69888': 5198, 'synced': 5199, 'shangela': 5200, 'guessed': 5201, 'nelson': 5202, \"bb's\": 5203, 'neighbors': 5204, 'yuou': 5205, 'spot': 5206, 'disconnected': 5207, 'fowler': 5208, '08715203694': 5209, 'image': 5210, \"tyler's\": 5211, 'occurs': 5212, 'minus': 5213, 'paragraphs': 5214, 'performed': 5215, 'priest': 5216, 'strips': 5217, 'postal': 5218, 'okies': 5219, 'borderline': 5220, 'frequently': 5221, 'needa': 5222, 'rayan': 5223, 'macleran': 5224, 'satsgettin': 5225, '47per': 5226, 'shore': 5227, 'fox': 5228, 'frndsship': 5229, 'dwn': 5230, 'cl': 5231, 'scenery': 5232, 'impressively': 5233, 'sensible': 5234, 'reaction': 5235, 'waaaat': 5236, 'lololo': 5237, 'thankyou': 5238, 'star': 5239, '09066364349': 5240, 'box434sk38wp150ppm18': 5241, 'forgiven': 5242, 'poet': 5243, 'imagination': 5244, 'talents': 5245, '1stchoice': 5246, '08707808226': 5247, 'gobi': 5248, '820554ad0a1705572711': 5249, 'trueåác': 5250, 'ringtoneåá': 5251, 'missy': 5252, 'w4': 5253, '5wq': 5254, 'adsense': 5255, 'approved': 5256, 'resizing': 5257, 'å£79': 5258, '08704439680ts': 5259, \"hi'\": 5260, 'fring': 5261, 'ktv': 5262, 'elvis': 5263, 'presleys': 5264, 'stoners': 5265, 'mas': 5266, 'loses': 5267, 'filling': 5268, 'shouting': 5269, 'sized': 5270, '3750': 5271, '09066364589': 5272, 'palm': 5273, 'wondarfull': 5274, 'wating': 5275, 'wewa': 5276, '130': 5277, 'iriver': 5278, '255': 5279, '128': 5280, 'lays': 5281, 'alian': 5282, 'fixes': 5283, 'spelling': 5284, \"station's\": 5285, '08715205273': 5286, 'poo': 5287, '20m12aq': 5288, '\\x89ûï': 5289, 'fiting': 5290, 'load': 5291, 'mj': 5292, 'lifted': 5293, 'hopes': 5294, 'approaches': 5295, '945': 5296, 'christmassy': 5297, 'specialisation': 5298, 'labor': 5299, 'shakara': 5300, 'beggar': 5301, 'sg': 5302, 'phyhcmk': 5303, 'teaching': 5304, 'pc1323': 5305, 'aeronautics': 5306, 'professors': 5307, 'calld': 5308, 'aeroplane': 5309, 'ws': 5310, 'hurried': 5311, 'tensed': 5312, 'strongly': 5313, 'creativity': 5314, 'stifled': 5315, 'soc': 5316, 'jack': 5317, 'helpful': 5318, 'pretend': 5319, 'hypotheticalhuagauahahuagahyuhagga': 5320, 'dabooks': 5321, 'fuuuuck': 5322, 'chk': 5323, 'ms': 5324, 'dict': 5325, 'monster': 5326, 'arranging': 5327, 'cartons': 5328, 'shelves': 5329, '07815296484': 5330, '41782': 5331, 'xclusive': 5332, 'clubsaisai': 5333, 'soiree': 5334, 'speciale': 5335, 'zouk': 5336, 'roses': 5337, '07946746291': 5338, '07880867867': 5339, 'varaya': 5340, 'elaya': 5341, 'wall': 5342, 'europe': 5343, '10th': 5344, '09050000555': 5345, 'ba128nnfwfly150ppm': 5346, 'helloooo': 5347, 'welcomes': 5348, 'leading': 5349, '151': 5350, 'pause': 5351, 'limit': 5352, 'grace': 5353, 'boundaries': 5354, 'endless': 5355, 'inconvenient': 5356, 'plum': 5357, 'smacks': 5358, 'fishrman': 5359, 'sack': 5360, 'strtd': 5361, 'throwin': 5362, '1stone': 5363, \"mrng''\": 5364, 'sleepwell': 5365, 'nigro': 5366, 'furniture': 5367, 'lock': 5368, 'locks': 5369, 'jenne': 5370, 'showered': 5371, \"er'ything\": 5372, '09061209465': 5373, 'suprman': 5374, 'matrix3': 5375, 'starwars3': 5376, 'steve': 5377, '6230': 5378, 'pobox114': 5379, '14tcr': 5380, 'ams': 5381, 'ultimately': 5382, 'tor': 5383, 'motive': 5384, 'tui': 5385, 'achieve': 5386, 'korli': 5387, 'british': 5388, 'hotels': 5389, '02072069400': 5390, 'bx': 5391, '526': 5392, 'sw73ss': 5393, 'blowing': 5394, 'sheffield': 5395, 'categories': 5396, 'ethnicity': 5397, 'census': 5398, 'transcribing': 5399, 'steyn': 5400, 'wicket': 5401, 'heading': 5402, 'prediction': 5403, 'solved': 5404, 'opened': 5405, 'oclock': 5406, 'bash': 5407, 'tex': 5408, 'mecause': 5409, 'werebored': 5410, 'okden': 5411, 'uin': 5412, 'soundåõs': 5413, 'likeyour': 5414, 'gr8fun': 5415, 'updat': 5416, 'countinlots': 5417, 'loveme': 5418, 'fifty': 5419, 'shitload': 5420, 'uploaded': 5421, 'cutest': 5422, 'prometazine': 5423, 'syrup': 5424, '5mls': 5425, 'feed': 5426, 'dual': 5427, 'showr': 5428, 'environment': 5429, 'terrific': 5430, 'les': 5431, 'rudi': 5432, 'snoring': 5433, 'ink': 5434, 'headin': 5435, 'sexychat': 5436, 'photoshop': 5437, 'waqt': 5438, 'pehle': 5439, 'naseeb': 5440, 'zyada': 5441, 'kisi': 5442, 'ko': 5443, 'kuch': 5444, 'milta': 5445, 'hum': 5446, 'sochte': 5447, 'ham': 5448, 'jeetey': 5449, 'potential': 5450, 'challenge': 5451, 'hahaha': 5452, 'brain': 5453, 'faded': 5454, 'glory': 5455, 'ralphs': 5456, 'owl': 5457, 'payments': 5458, 'fedex': 5459, 'banneduk': 5460, '087104711148': 5461, 'wesleys': 5462, 'ooh': 5463, '4got': 5464, 'moseley': 5465, 'weds': 5466, 'enjoying': 5467, '09065174042': 5468, '07821230901': 5469, 'shiny': 5470, 'warming': 5471, '09066364311': 5472, 'jaklin': 5473, 'gut': 5474, 'wrenching': 5475, 'restock': 5476, 'mandan': 5477, 'dialogue': 5478, 'reltnship': 5479, \"dealer's\": 5480, 'sentence': 5481, 'educational': 5482, 'costume': 5483, 'jaykwon': 5484, 'thuglyfe': 5485, 'falconerf': 5486, 'quarter': 5487, 'amla': 5488, 'vday': 5489, 'parachute': 5490, 'applausestore': 5491, 'monthlysubscription': 5492, 'max6': 5493, 'csc': 5494, 'entertaining': 5495, 'hugh': 5496, 'laurie': 5497, 'wendy': 5498, 'checkup': 5499, 'pap': 5500, 'smear': 5501, \"cali's\": 5502, 'complexities': 5503, 'freely': 5504, 'taxes': 5505, 'outrageous': 5506, \"i'ma\": 5507, 'maths': 5508, 'chapter': 5509, 'changing': 5510, 'diapers': 5511, 'owed': 5512, 'studyn': 5513, 'specify': 5514, 'domain': 5515, 'nusstu': 5516, 'plural': 5517, 'nottingham': 5518, '63miles': 5519, '40mph': 5520, 'oral': 5521, 'pounded': 5522, 'dentists': 5523, 'rajitha': 5524, 'raj': 5525, 'ranju': 5526, 'hitter': 5527, 'yavnt': 5528, 'entrepreneurs': 5529, '2006': 5530, 'fifa': 5531, 'shag': 5532, 'sextextuk': 5533, 'xxuk': 5534, '69876': 5535, 'absence': 5536, \"åòit's\": 5537, 'flowers': 5538, '505060': 5539, 'hurting': 5540, 'meaningful': 5541, 'compromised': 5542, 'awkward': 5543, \"shade's\": 5544, 'buyer': 5545, 'dehydrated': 5546, 'september': 5547, 'seperated': 5548, '\\x8eö´\\x89ó': 5549, '\\x8bû¬ud': 5550, 'aust': 5551, 'bk': 5552, 'outs': 5553, 'pookie': 5554, '69855': 5555, 'stopbcm': 5556, 'sf': 5557, 'biola': 5558, '09063458130': 5559, 'polyph': 5560, 'lacking': 5561, 'particular': 5562, \"dramastorm's\": 5563, 'applebees': 5564, 'mirror': 5565, 'youre': 5566, '09058097189': 5567, 'ls15hb': 5568, '09077818151': 5569, 'calls1': 5570, '50ppm': 5571, '30s': 5572, 'santacalling': 5573, '087016248': 5574, 'sleeps': 5575, 'significant': 5576, 'dock': 5577, 'rolled': 5578, 'newscaster': 5579, 'dabbles': 5580, 'flute': 5581, 'wheel': 5582, 'thin': 5583, 'arguments': 5584, 'fed': 5585, 'himso': 5586, 'mobsi': 5587, '391784': 5588, 'purity': 5589, 'musthu': 5590, 'steam': 5591, 'daytime': 5592, 'busty': 5593, '09099726429': 5594, 'janinexx': 5595, 'rv': 5596, 'rvx': 5597, \"shit's\": 5598, 'veggie': 5599, 'needing': 5600, 'textand': 5601, '08002988890': 5602, 'fifth': 5603, 'woozles': 5604, 'weasels': 5605, 'sc': 5606, 'specialise': 5607, 'wad': 5608, 'machi': 5609, 'nri': 5610, 'command': 5611, 'chief': 5612, 'motivate': 5613, 'darkness': 5614, 'shining': 5615, 'certificate': 5616, 'publish': 5617, 'cherthala': 5618, 'bfore': 5619, 'tmorow': 5620, 'engaged': 5621, 'unsubscribed': 5622, 'hunks': 5623, 'gotbabes': 5624, 'subscriptions': 5625, '2005': 5626, 'hhahhaahahah': 5627, 'nig': 5628, 'leonardo': 5629, 'vitamin': 5630, 'senor': 5631, 'blessed': 5632, 'spelled': 5633, 'caps': 5634, 'yelling': 5635, 'bullshit': 5636, 'overtime': 5637, 'nigpun': 5638, 'fones': 5639, 'wild': 5640, 'stop2stop': 5641, 'hep': 5642, 'immunisation': 5643, 'bookedthe': 5644, 'hut': 5645, 'asa': 5646, 'mouth': 5647, '2mro': 5648, '087018728737': 5649, 'toppoly': 5650, 'tune': 5651, 'ciao': 5652, 'gods': 5653, 'theoretically': 5654, 'kitty': 5655, 'shaved': 5656, 'natural': 5657, 'signing': 5658, 'somewhr': 5659, 'crushes': 5660, 'billy': 5661, '09061743811': 5662, '326': 5663, 'salmon': 5664, 'versus': 5665, 'dom': 5666, 'jabo': 5667, '08718726978': 5668, '850': 5669, '650': 5670, 'backwards': 5671, 'cheesy': 5672, 'frosty': 5673, 'slob': 5674, 'wright': 5675, '08006344447': 5676, 'format': 5677, 'disc': 5678, 'wonders': 5679, '7th': 5680, '6th': 5681, '5th': 5682, 'personality': 5683, '3rd': 5684, 'tlk': 5685, 'slippery': 5686, 'meetins': 5687, 'cumin': 5688, '09099726395': 5689, 'banned': 5690, 'fffff': 5691, \"xin's\": 5692, 'slots': 5693, 'euro2004': 5694, 'kickoff': 5695, '83222': 5696, 'nannys': 5697, 'display': 5698, 'footie': 5699, 'blow': 5700, 'phil': 5701, 'neville': 5702, 'repeat': 5703, 'sang': 5704, \"'uptown\": 5705, \"girl'\": 5706, \"80's\": 5707, \"derek's\": 5708, 'watever': 5709, 'built': 5710, 'iz': 5711, 'lonlines': 5712, 'lotz': 5713, 'memories': 5714, 'cried': 5715, 'kane': 5716, 'shud': 5717, '09090204448': 5718, 'minded': 5719, 'aå£1': 5720, 'minapn': 5721, 'ls278bb': 5722, \"ron's\": 5723, 'macs': 5724, 'bruv': 5725, 'svc': 5726, '69988': 5727, 'lit': 5728, 'fire': 5729, 'entirely': 5730, 'rearrange': 5731, 'dormitory': 5732, 'astronomer': 5733, 'starer': 5734, 'election': 5735, 'recount': 5736, 'hitler': 5737, 'eleven': 5738, 'subtoitles': 5739, 'sculpture': 5740, 'lovin': 5741, 'tessy': 5742, 'favor': 5743, 'shijas': 5744, 'degrees': 5745, 'ayo': 5746, 'travelled': 5747, 'wiskey': 5748, 'brandy': 5749, 'rum': 5750, 'gin': 5751, 'scotch': 5752, 'shampain': 5753, 'kudi': 5754, 'yarasu': 5755, 'dhina': 5756, 'vaazhthukkal': 5757, 'whens': 5758, 'sos': 5759, 'attending': 5760, 'ukp': 5761, '09061790125': 5762, 'maps': 5763, \"audrey's\": 5764, 'hogolo': 5765, 'gold': 5766, 'kodstini': 5767, 'necklace': 5768, 'madstini': 5769, 'hogli': 5770, 'mutai': 5771, 'eerulli': 5772, 'kodthini': 5773, 'jos': 5774, 'pubs': 5775, 'frankie': 5776, 'bennys': 5777, 'smoothly': 5778, 'challenging': 5779, '5226': 5780, 'hava': 5781, '1131': 5782, 'stubborn': 5783, 'sucker': 5784, 'hospitals': 5785, 'suckers': 5786, 'attended': 5787, 'spoil': 5788, \"yetty's\": 5789, 'gopalettan': 5790, 'participate': 5791, 'ups': 5792, '3days': 5793, 'usps': 5794, 'bribe': 5795, 'nipost': 5796, '3pound': 5797, 'nearer': 5798, 'jackpot': 5799, '81010': 5800, 'dbuk': 5801, 'lccltd': 5802, '4403ldnw1a7rw18': 5803, 'das': 5804, 'iknow': 5805, 'wellda': 5806, 'peril': 5807, 'studentfinancial': 5808, 'inperialmusic': 5809, 'listening2the': 5810, 'byåóleafcutter': 5811, 'johnåó': 5812, 'insects': 5813, 'molested': 5814, 'plumbing': 5815, 'remixed': 5816, 'evil': 5817, 'acid': 5818, 'yeesh': 5819, 'weirdy': 5820, 'brownies': 5821, 'someday': 5822, 'text82228': 5823, 'logos': 5824, 'blanked': 5825, 'cc100p': 5826, 'jerry': 5827, 'cartoon': 5828, 'irritates': 5829, 'fails': 5830, 'goin2bed': 5831, 'only1more': 5832, '80155': 5833, 'swap': 5834, 'chatter': 5835, 'chat80155': 5836, 'rcd': 5837, 'someplace': 5838, '08718723815': 5839, 'chillin': 5840, '08718727870150ppm': 5841, 'positions': 5842, 'kama': 5843, 'sutra': 5844, 'unmits': 5845, 'tip': 5846, 'hides': 5847, 'secrets': 5848, 'n8': 5849, 'vat': 5850, 'subs16': 5851, '1win150ppmx3': 5852, '09050001295': 5853, 'a21': 5854, 'bike': 5855, 'rounder': 5856, 'required': 5857, 'mus': 5858, 'owe': 5859, 'rocking': 5860, 'ashes': 5861, '08717895698': 5862, 'mobstorequiz10ppm': 5863, 'gayle': 5864, '07090201529': 5865, 'restrictions': 5866, 'buddys': 5867, 'bari': 5868, 'hudgi': 5869, 'yorge': 5870, 'pataistha': 5871, 'ertini': 5872, 'slacking': 5873, 'beach': 5874, 'expected': 5875, 'invention': 5876, \"wherre's\": 5877, 'å£125': 5878, 'freeentry': 5879, 'xt': 5880, 'calm': 5881, 'downon': 5882, 'theacusations': 5883, 'itxt': 5884, 'iwana': 5885, 'wotu': 5886, 'thew': 5887, 'haventcn': 5888, 'nething': 5889, 'varunnathu': 5890, 'edukkukayee': 5891, 'raksha': 5892, 'ollu': 5893, 'pure': 5894, 'hearted': 5895, 'enemies': 5896, 'smiley': 5897, 'drpd': 5898, 'deeraj': 5899, 'deepak': 5900, 'downs': 5901, 'fletcher': 5902, 'xam': 5903, 'hall': 5904, 'hesitation': 5905, 'intha': 5906, 'ponnungale': 5907, 'ipaditan': 5908, 'wasted': 5909, 'chiong': 5910, 'burden': 5911, '8000930705': 5912, 'portege': 5913, 'm100': 5914, 'twinks': 5915, 'scallies': 5916, 'skins': 5917, 'jocks': 5918, \"weekend's\": 5919, '08712466669': 5920, 'port': 5921, 'sitter': 5922, 'kaitlyn': 5923, \"'wnevr\": 5924, 'fal': 5925, 'fals': 5926, 'yen': 5927, 'madodu': 5928, 'nav': 5929, 'pretsorginta': 5930, 'nammanna': 5931, 'pretsovru': 5932, 'alwa': 5933, 'eveb': 5934, 'l8': 5935, 'gon': 5936, 'attraction': 5937, 'breath': 5938, 'sorrows': 5939, 'proove': 5940, 'praises': 5941, 'curry': 5942, 'makiing': 5943, 'sambar': 5944, 'okors': 5945, 'cherish': 5946, 'chickened': 5947, 'woould': 5948, 'crashing': 5949, 'mca': 5950, 'barring': 5951, 'sudden': 5952, 'influx': 5953, 'eye': 5954, '447797706009': 5955, 'careers': 5956, 'sinco': 5957, 'payee': 5958, 'icicibank': 5959, 'beware': 5960, 'frauds': 5961, 'disclose': 5962, 'drastic': 5963, 'parts': 5964, 'olowoyey': 5965, 'argentina': 5966, 'blessing': 5967, 'nigh': 5968, 'andrews': 5969, 'whatsup': 5970, 'idc': 5971, 'weaseling': 5972, 'desparately': 5973, 'tunji': 5974, 'tirunelvai': 5975, 'spice': 5976, 'atleast': 5977, 'shakespeare': 5978, 'tops': 5979, 'consistently': 5980, 'practicum': 5981, 'links': 5982, 'ears': 5983, \"gumby's\": 5984, 'classmates': 5985, 'ceri': 5986, 'rebel': 5987, 'dreamz': 5988, 'buddy': 5989, 'blokes': 5990, 'gamestar': 5991, 'active': 5992, 'å£250k': 5993, 'scoring': 5994, '88088': 5995, 'headstart': 5996, 'rummer': 5997, 'conference': 5998, 'waheeda': 5999, 'ummifying': 6000, 'el': 6001, 'nino': 6002, 'himself': 6003, 'harder': 6004, 'nbme': 6005, 'tattoos': 6006, '09064017295': 6007, 'recorder': 6008, 'canname': 6009, 'australia': 6010, 'mquiz': 6011, 'kalainar': 6012, 'thenampet': 6013, 'related': 6014, 'arul': 6015, 'arr': 6016, 'oscar': 6017, 'reminder': 6018, 'doit': 6019, 'mymoby': 6020, 'wesley': 6021, \"how've\": 6022, 'reverse': 6023, 'cheating': 6024, 'mathematics': 6025, 'rg21': 6026, '4jx': 6027, '27': 6028, '08714714011': 6029, 'apo': 6030, 'honesty': 6031, 'route': 6032, 'throws': 6033, 'brothers': 6034, 'pandy': 6035, 'windows': 6036, 'logoff': 6037, 'msging': 6038, 'abeg': 6039, 'sponsors': 6040, 'event': 6041, 'keyword': 6042, 'tmorrow': 6043, 'accomodate': 6044, 'ana': 6045, 'sathy': 6046, 'rto': 6047, 'ripped': 6048, 'clubmoby': 6049, '08717509990': 6050, 'friendships': 6051, 'grow': 6052, 'subscribers': 6053, 'mary': 6054, 'zhong': 6055, 'qing': 6056, 'act': 6057, '83370': 6058, 'trivia': 6059, '09061790126': 6060, 'lifebook': 6061, 'rejected': 6062, 'worms': 6063, '09058094507': 6064, 'yards': 6065, 'bergkamp': 6066, 'margin': 6067, '78': 6068, 'ortxt': 6069, \"fren's\": 6070, 'unlike': 6071, 'patients': 6072, 'turkeys': 6073, 'iraq': 6074, 'afghanistan': 6075, 'stable': 6076, 'honest': 6077, 'traveling': 6078, 'mel': 6079, 'opps': 6080, \"tt's\": 6081, 'a30': 6082, 'divert': 6083, 'wadebridge': 6084, 'professional': 6085, 'tiger': 6086, 'woods': 6087, 'joanna': 6088, 'cheetos': 6089, 'clash': 6090, 'successful': 6091, 'stuffed': 6092, 'writhing': 6093, 'recovery': 6094, 'cooped': 6095, 'sentiment': 6096, 'rowdy': 6097, 'attitude': 6098, 'attractive': 6099, 'witin': 6100, 'leads': 6101, 'semiobscure': 6102, 'å£5': 6103, '08712402578': 6104, \"it'snot\": 6105, \"child's\": 6106, 'unintentional': 6107, 'nonetheless': 6108, 'emailed': 6109, 'yifeng': 6110, 'settling': 6111, 'happenin': 6112, 'eachother': 6113, 'firmware': 6114, 'thkin': 6115, 'spotty': 6116, 'province': 6117, 'sterling': 6118, 'baaaaaaaabe': 6119, 'lindsay': 6120, 'bars': 6121, 'heron': 6122, 'hottest': 6123, 'accomodations': 6124, 'cave': 6125, 'offered': 6126, 'embarassing': 6127, '08700469649': 6128, 'box420': 6129, '69888nyt': 6130, 't91': 6131, '09057039994': 6132, 'drama': 6133, 'struggling': 6134, 'ego': 6135, \"'if\": 6136, \"invited'\": 6137, 'necessity': 6138, 'reppurcussions': 6139, '81303': 6140, 'trackmarque': 6141, 'vipclub4u': 6142, '1405': 6143, '1680': 6144, '1843': 6145, 'innocent': 6146, 'terror': 6147, 'cruel': 6148, 'decent': 6149, 'joker': 6150, 'stability': 6151, 'tranquility': 6152, 'vibrant': 6153, 'colourful': 6154, 'merely': 6155, 'relationship': 6156, 'wherevr': 6157, 'gudnyt': 6158, 'deepest': 6159, 'darkest': 6160, '09094646631': 6161, 'waliking': 6162, 'cantdo': 6163, 'anythingtomorrow': 6164, 'myparents': 6165, 'aretaking': 6166, 'outfor': 6167, 'katexxx': 6168, 'absolutely': 6169, 'fired': 6170, 'spjanuary': 6171, 'ou': 6172, 'trash': 6173, 'wavering': 6174, 'heal': 6175, 'build': 6176, 'angels': 6177, 'snowball': 6178, 'youåõre': 6179, \"joke's\": 6180, 'university': 6181, 'florida': 6182, 'kickboxing': 6183, 'jp': 6184, 'mofo': 6185, 'dot': 6186, 'pen': 6187, 'biro': 6188, 'belligerent': 6189, 'treasure': 6190, 'useless': 6191, 'converter': 6192, 'prakesh': 6193, 'dobby': 6194, '09066660100': 6195, '2309': 6196, 'cheyyamo': 6197, 'officer': 6198, 'guoyang': 6199, 'ibored': 6200, 'iam': 6201, '4719': 6202, '523': 6203, '07099833605': 6204, '9280114': 6205, 'ouch': 6206, 'risk': 6207, 'alto18': 6208, '44345': 6209, 'gate': 6210, 'acknowledgement': 6211, 'astoundingly': 6212, 'tactless': 6213, 'oath': 6214, 'smiled': 6215, 'å£6': 6216, 'rajas': 6217, 'burrito': 6218, '09058091870': 6219, 'loooooool': 6220, 'couch': 6221, 'rents': 6222, 'nimbomsons': 6223, 'selflessness': 6224, 'hols': 6225, 'hairdressers': 6226, 'beforehand': 6227, '\\rham': 6228, 'retard': 6229, 'gamb': 6230, 'urination': 6231, 'clever': 6232, 'guesses': 6233, 'attach': 6234, 'breeze': 6235, 'fresh': 6236, 'twittering': 6237, 'dusk': 6238, 'puzzles': 6239, 'justify': 6240, 'november': 6241, '09061104276': 6242, 'costå£3': 6243, '75max': 6244, 'garage': 6245, 'bookshelf': 6246, 'crucify': 6247, 'success': 6248, 'decades': 6249, 'goverment': 6250, 'expects': 6251, \"basket's\": 6252, 'conacted': 6253, '09111030116': 6254, 'pobox12n146tf15': 6255, 'shant': 6256, 'jia': 6257, 'gua': 6258, 'faber': 6259, 'ooooooh': 6260, 'yoville': 6261, 'jap': 6262, 'exp': 6263, '30apr': 6264, 'kfc': 6265, 'meals': 6266, 'gravy': 6267, 'dats': 6268, 'dogg': 6269, 'flurries': 6270, 'spaces': 6271, 'embassy': 6272, 'fetching': 6273, 'spiritual': 6274, 'str8': 6275, 'classic': 6276, '200p': 6277, 'aldrine': 6278, 'rtm': 6279, 'n9dx': 6280, 'pickle': 6281, 'crashed': 6282, 'cuddled': 6283, 'uses': 6284, 'passable': 6285, 'phd': 6286, '5years': 6287, 'swoop': 6288, 'tbs': 6289, 'persolvo': 6290, 'forå£38': 6291, 'kath': 6292, 'manchester': 6293, 'gsoh': 6294, 'spam': 6295, 'gigolo': 6296, 'mens': 6297, 'oncall': 6298, 'mjzgroup': 6299, '08714342399': 6300, '50rcvd': 6301, 'beverage': 6302, 'pist': 6303, 'kay': 6304, 'dealer': 6305, 'freedom': 6306, 'lunsford': 6307, \"'an\": 6308, \"quote''\": 6309, '3230': 6310, 'textbook': 6311, 'algorithms': 6312, 'edition': 6313, '09090900040': 6314, 'extreme': 6315, 'sic': 6316, '7mp': 6317, '0870753331018': 6318, 'passes': 6319, '08704439680': 6320, 'knocking': 6321, 'keen': 6322, 'pressies': 6323, '730': 6324, 'chances': 6325, 'csh11': 6326, '6days': 6327, 'tsandcs': 6328, 'lasagna': 6329, 'mei': 6330, 'haven': 6331, 'bao': 6332, 'sugardad': 6333, \"fuck's\": 6334, 'tallahassee': 6335, 'lanre': 6336, \"fakeye's\": 6337, 'eckankar': 6338, 'hooked': 6339, \"weather's\": 6340, 'sliding': 6341, 'every1': 6342, 'ava': 6343, 'goodtime': 6344, 'oli': 6345, 'melnite': 6346, 'ifink': 6347, 'everythin': 6348, 'l8rs': 6349, 'converted': 6350, 'walkabout': 6351, 'rupaul': 6352, 'animal': 6353, 'reminding': 6354, 'destination': 6355, 'mumhas': 6356, 'beendropping': 6357, 'theplace': 6358, 'adress': 6359, 'unintentionally': 6360, 'warning': 6361, 'webpage': 6362, 'base': 6363, 'z': 6364, 'gifts': 6365, 'cliff': 6366, '09053750005': 6367, '310303': 6368, '08718725756': 6369, '140ppm': 6370, 'unnecessarily': 6371, 'affectionate': 6372, 'excited': 6373, '0871277810810': 6374, \"rct'\": 6375, 'thnq': 6376, 'adrian': 6377, 'vatian': 6378, 'brolly': 6379, 'franxx': 6380, 'k718': 6381, '09065069120': 6382, 'ger': 6383, 'toking': 6384, 'syd': 6385, 'ing': 6386, 'cakes': 6387, \"that'd\": 6388, 'scenario': 6389, 'outsider': 6390, 'rip': 6391, 'uterus': 6392, 'barbie': 6393, \"ken's\": 6394, 'arngd': 6395, 'walkin': 6396, 'unfortuntly': 6397, 'bites': 6398, 'frnt': 6399, 'sayin': 6400, 'audiitions': 6401, 'relocate': 6402, 'ore': 6403, 'owo': 6404, 'wa': 6405, 'fro': 6406, 'gurl': 6407, 'appropriate': 6408, 'placed': 6409, 'rubber': 6410, 'triple': 6411, 'echo': 6412, 'squatting': 6413, 'relaxing': 6414, '7am': 6415, '5ish': 6416, 'semi': 6417, 'gmw': 6418, 'connected': 6419, 'studies': 6420, 'anyones': 6421, 'zoom': 6422, 'half8th': 6423, 'continued': 6424, 'president': 6425, '8lb': 6426, '7oz': 6427, 'brilliantly': 6428, 'karnan': 6429, 'thinl': 6430, 'lyrics': 6431, \"textin'\": 6432, 'babyjontet': 6433, 'aunty': 6434, 'prominent': 6435, 'cheek': 6436, 'raglan': 6437, 'edward': 6438, 'cricket': 6439, 'closeby': 6440, 'costumes': 6441, 'yowifes': 6442, 'denying': 6443, 'you\\x89û÷ll': 6444, 'steal': 6445, '07008009200': 6446, '2morrow': 6447, \"x'mas\": 6448, 'risks': 6449, 'hunting': 6450, 'vomitin': 6451, \"world's\": 6452, 'happiest': 6453, 'characters': 6454, 'differences': 6455, 'luvs': 6456, 'allday': 6457, 'ploughing': 6458, 'pile': 6459, 'ironing': 6460, 'chinky': 6461, 'lord': 6462, 'rings': 6463, 'soundtrack': 6464, 'stdtxtrate': 6465, 'starve': 6466, 'alternative': 6467, \"term's\": 6468, '3650': 6469, '09066382422': 6470, '300603': 6471, 'bcm4284': 6472, 'scrumptious': 6473, 'gokila': 6474, '600': 6475, '400': 6476, 'deltomorrow': 6477, '100p': 6478, 'hustle': 6479, 'forth': 6480, 'harlem': 6481, 'continent': 6482, 'indyarocks': 6483, 'phonebook': 6484, 'anal': 6485, 'drunkard': 6486, '645': 6487, 'meaningless': 6488, 'wishin': 6489, 'paragon': 6490, 'responding': 6491, 'lim': 6492, 'equally': 6493, 'uneventful': 6494, 'pesky': 6495, 'cyclists': 6496, 'brison': 6497, 'trips': 6498, 'forwarding': 6499, 'hearin': 6500, 'didnåõt': 6501, 'intend': 6502, 'iwas': 6503, 'marine': 6504, 'itried2tell': 6505, 'urmom': 6506, 'careabout': 6507, 'vivek': 6508, 'kotees': 6509, 'noooooooo': 6510, 'trek': 6511, 'endowed': 6512, 'idew': 6513, 'lul': 6514, 'nurses': 6515, 'shes': 6516, 'obese': 6517, 'oyea': 6518, 'enufcredeit': 6519, 'tocall': 6520, 'ileave': 6521, 'beside': 6522, 'shoul': 6523, 'ffffffffff': 6524, 'outbid': 6525, 'simonwatson5120': 6526, 'shinco': 6527, 'plyr': 6528, 'smsrewards': 6529, 'notifications': 6530, 'bathroom': 6531, 'w8in': 6532, '4utxt': 6533, '82242': 6534, 'hlp': 6535, '08712317606': 6536, 'msg150p': 6537, '2rcv': 6538, 'byatch': 6539, 'whassup': 6540, 'conversations': 6541, 'senses': 6542, 'overemphasise': 6543, 'pai': 6544, 'seh': 6545, '09066358361': 6546, 'y87': 6547, 'digi': 6548, 'fab': 6549, 'coupla': 6550, '62220cncl': 6551, 'stopcs': 6552, '08717890890å£1': 6553, 'complain': 6554, 'bettr': 6555, 'bsnl': 6556, 'offc': 6557, 'hont': 6558, \"dad's\": 6559, 'sh': 6560, 'kanji': 6561, 'mentionned': 6562, 'tiwary': 6563, 'rcb': 6564, 'battle': 6565, 'kochi': 6566, 'jez': 6567, 'iscoming': 6568, 'todo': 6569, 'workand': 6570, 'whilltake': 6571, 'gei': 6572, 'tron': 6573, 'dl': 6574, '9755': 6575, 'compass': 6576, 'soul': 6577, 'gnun': 6578, 'way2sms': 6579, 'sunoco': 6580, 'staring': 6581, 'consent': 6582, 'forms': 6583, 'lay': 6584, 'bimbo': 6585, \"ugo's\": 6586, 'fredericksburg': 6587, 'meat': 6588, 'supreme': 6589, 'complementary': 6590, 'wa14': 6591, '2px': 6592, 'inspection': 6593, 'nursery': 6594, 'didntgive': 6595, 'bellearlier': 6596, 'answerin': 6597, 'reasonable': 6598, 'matric': 6599, 'mountain': 6600, 'deer': 6601, 'chgs': 6602, 'unclaimed': 6603, '09066368327': 6604, 'closingdate04': 6605, 'claimcode': 6606, 'm39m51': 6607, '50pmmorefrommobile2bremoved': 6608, 'mobypobox734ls27yf': 6609, 'muhommad': 6610, 'penny': 6611, 'laready': 6612, 'fwiw': 6613, 'afford': 6614, 'reassuring': 6615, 'computers': 6616, 'appointments': 6617, 'shoving': 6618, 'dolls': 6619, 'patrick': 6620, 'swayze': 6621, 'ryan': 6622, 'allow': 6623, 'sux': 6624, 'raiden': 6625, '0825': 6626, 'vague': 6627, 'accounting': 6628, 'delayed': 6629, 'housing': 6630, 'agency': 6631, 'renting': 6632, 'haircut': 6633, 'breezy': 6634, 'alle': 6635, 'mone': 6636, 'eppolum': 6637, 'allalo': 6638, 'sophas': 6639, 'secondary': 6640, 'applying': 6641, 'ogunrinde': 6642, 'kaila': 6643, 'flow': 6644, 'developed': 6645, 'ovarian': 6646, 'cysts': 6647, 'shrink': 6648, 'spiffing': 6649, 'workage': 6650, 'afternon': 6651, 'interviews': 6652, 'thnx': 6653, \"'hex'\": 6654, 'aids': 6655, 'patent': 6656, 'african': 6657, 'soil': 6658, 'reliant': 6659, 'breathing': 6660, 'japanese': 6661, 'proverb': 6662, 'strike': 6663, '09058094454': 6664, 'accordin': 6665, 'parkin': 6666, 'falling': 6667, 'smeone': 6668, 'velly': 6669, 'heads': 6670, 'sections': 6671, 'clearer': 6672, 'becz': 6673, 'undrstndng': 6674, 'avoids': 6675, 'suffer': 6676, 'ujhhhhhhh': 6677, 'shipped': 6678, 'sandiago': 6679, 'parantella': 6680, 'bridge': 6681, 'lager': 6682, 'fps': 6683, 'weigh': 6684, 'workout': 6685, 'fats': 6686, 'tunde': 6687, 'orh': 6688, \"how're\": 6689, 'throwing': 6690, 'deciding': 6691, 'chik': 6692, \"100's\": 6693, 'filth': 6694, 'saristar': 6695, 'e14': 6696, '9yt': 6697, '08701752560': 6698, '450p': 6699, 'stop2': 6700, 'villa': 6701, '82324': 6702, \"ta's\": 6703, \"ìï'll\": 6704, 'panren': 6705, 'paru': 6706, 'cozy': 6707, 'rajini': 6708, 'tiring': 6709, 'concentrating': 6710, 'earliest': 6711, 'although': 6712, 'baig': 6713, 'watches': 6714, 'noisy': 6715, 'easiest': 6716, 'barcelona': 6717, 'sq825': 6718, 'arrival': 6719, 'eh74rr': 6720, 'typical': 6721, 'heat': 6722, 'applyed': 6723, 'nordstrom': 6724, '08001950382': 6725, '674': 6726, 'randomlly': 6727, 'mys': 6728, 'fundamentals': 6729, 'rushing': 6730, 'forgive': 6731, 'nok': 6732, '87021': 6733, 'excused': 6734, 'prix': 6735, 'hassling': 6736, 'andres': 6737, 'haughaighgtujhyguj': 6738, 'bold2': 6739, 'payment': 6740, 'portal': 6741, 'memorable': 6742, 'boyf': 6743, 'interviw': 6744, 'batsman': 6745, 'multis': 6746, 'raji': 6747, 'nic': 6748, 'checkin': 6749, 'reunion': 6750, 'creep': 6751, 'mila': 6752, 'age23': 6753, 'blonde': 6754, 'mtalk': 6755, '69866': 6756, '30pp': 6757, '5free': 6758, 'increments': 6759, 'help08718728876': 6760, 'whr': 6761, '169': 6762, '6031': 6763, 'stayin': 6764, 'heåõs': 6765, '2getha': 6766, 'flatter': 6767, 'pints': 6768, 'carlin': 6769, 'topped': 6770, 'bubbletext': 6771, 'tgxxrz': 6772, 'rgent': 6773, 'å£1250': 6774, '09071512433': 6775, '050703': 6776, 'callcost': 6777, 'mobilesvary': 6778, 'somerset': 6779, 'matthew': 6780, '09063440451': 6781, 'ppm150': 6782, 'box334': 6783, 'eightish': 6784, 'carpark': 6785, 'loxahatchee': 6786, 'burning': 6787, 'pleassssssseeeeee': 6788, 'sportsx': 6789, 'helens': 6790, 'princes': 6791, 'chad': 6792, 'gymnastics': 6793, 'christians': 6794, 'responsibilities': 6795, 'intention': 6796, 'visitors': 6797, 'smsservices': 6798, 'yourinclusive': 6799, 'exorcism': 6800, 'emily': 6801, \"'rencontre'\": 6802, 'mountains': 6803, 'symptoms': 6804, 'tooth': 6805, 'or2optout': 6806, 'hv9d': 6807, '2stoptx': 6808, 'wasnåõt': 6809, 'spouse': 6810, 'pmt': 6811, '4give': 6812, 'shldxxxx': 6813, 'gsex': 6814, '2667': 6815, 'wc1n': 6816, '3xx': 6817, 'shrek': 6818, 'secured': 6819, 'unsecured': 6820, '195': 6821, '6669': 6822, '08719181513': 6823, 'txtstar': 6824, 'brisk': 6825, 'walks': 6826, '89105': 6827, 'obey': 6828, 'bunch': 6829, 'lotto': 6830, 'concerned': 6831, \"parents'\": 6832, 'snowboarding': 6833, 'befor': 6834, 'pocy': 6835, 'lambda': 6836, 'nosh': 6837, 'gong': 6838, 'kaypoh': 6839, 'name1': 6840, 'name2': 6841, 'mobno': 6842, 'adam': 6843, '07123456789': 6844, 'txtno': 6845, 'ads': 6846, 'dearer': 6847, 'dem': 6848, 'permission': 6849, 'perform': 6850, 'safely': 6851, '67441233': 6852, 'irene': 6853, 'ere': 6854, 'bus8': 6855, '22': 6856, '65': 6857, '61': 6858, '66': 6859, '382': 6860, 'cres': 6861, '6ph': 6862, '5wkg': 6863, 'ì¬n': 6864, 'phone750': 6865, 'hypertension': 6866, 'surrender': 6867, 'como': 6868, 'listened2the': 6869, 'plaid': 6870, 'air1': 6871, 'hilarious': 6872, 'boughtåóbraindanceåóa': 6873, 'ofstuff': 6874, 'aphexåõs': 6875, 'abel': 6876, 'coulda': 6877, 'mesages': 6878, 'apeshit': 6879, 'simulate': 6880, 'readiness': 6881, '0906346330': 6882, '47': 6883, 'po19': 6884, '2ez': 6885, 'compensation': 6886, 'predicting': 6887, 'accumulation': 6888, 'shola': 6889, 'sagamu': 6890, 'lautech': 6891, 'vital': 6892, 'completes': 6893, 'education': 6894, 'zealand': 6895, 'resend': 6896, 'stalking': 6897, 'becausethey': 6898, '09058098002': 6899, 'pobox1': 6900, 'w14rg': 6901, 'packing': 6902, 'ridden': 6903, 'jd': 6904, 'accounts': 6905, 'footy': 6906, 'stadium': 6907, 'large': 6908, 'coca': 6909, 'cola': 6910, 'respectful': 6911, \"partner's\": 6912, 'method': 6913, 'chez': 6914, 'jules': 6915, 'rr': 6916, 'hourish': 6917, 'finalise': 6918, 'several': 6919, 'forgiveness': 6920, 'r836': 6921, '09065069154': 6922, 'thet': 6923, 'skinny': 6924, 'casting': 6925, 'headset': 6926, 'adp': 6927, 'optimistic': 6928, 'improve': 6929, '330': 6930, '1120': 6931, '1205': 6932, 'various': 6933, 'yeovil': 6934, 'motor': 6935, 'max': 6936, 'cutie': 6937, 'hills': 6938, 'ystrday': 6939, 'brownie': 6940, 'rows': 6941, 'sday': 6942, 'everyso': 6943, 'panicks': 6944, 'character': 6945, 'covers': 6946, 'ganesh': 6947, 'abroad': 6948, 'xxsp': 6949, 'stopcost': 6950, '08712400603': 6951, 'mcfly': 6952, 'ab': 6953, 'sara': 6954, 'jorge': 6955, 'instructions': 6956, '0844': 6957, '861': 6958, 'prepayment': 6959, 'telediscount': 6960, 'velachery': 6961, 'smartcall': 6962, '68866': 6963, 'subscriptn3gbp': 6964, '08448714184': 6965, 'landlineonly': 6966, '09064019788': 6967, 'box42wr29c': 6968, 'mallika': 6969, 'sherawat': 6970, 'nange': 6971, 'bakra': 6972, 'kalstiya': 6973, 'possibility': 6974, '2years': 6975, 'strain': 6976, 'warwick': 6977, 'tmw': 6978, 'canceled': 6979, \"havn't\": 6980, 'jog': 6981, 'consensus': 6982, 'predict': 6983, 'sweater': 6984, 'mango': 6985, 'elaborating': 6986, 'safety': 6987, 'aspects': 6988, 'wetherspoons': 6989, '420': 6990, 'virgin': 6991, '09061104283': 6992, '50pm': 6993, 'approx': 6994, 'pattern': 6995, 'emerging': 6996, 'fiend': 6997, 'impede': 6998, 'hesitant': 6999, 'slower': 7000, 'maniac': 7001, 'lapdancer': 7002, 'g2': 7003, '1da': 7004, '150ppmsg': 7005, '09058094583': 7006, 'garden': 7007, 'bulbs': 7008, 'seeds': 7009, 'å£33': 7010, 'scotsman': 7011, 'go2': 7012, 'notxt': 7013, 'teresa': 7014, 'dec': 7015, \"you'ld\": 7016, 'bam': 7017, 'aid': 7018, 'usmle': 7019, 'hallaq': 7020, 'owned': 7021, 'possessive': 7022, 'pract': 7023, 'flung': 7024, 'ambitious': 7025, 'rightio': 7026, '48': 7027, 'wtlp': 7028, 'housewives': 7029, '0871750': 7030, '77': 7031, 'landlines': 7032, 'stink': 7033, 'kavalan': 7034, 'guides': 7035, 'snatch': 7036, 'purse': 7037, 'monkey': 7038, 'asshole': 7039, '3lions': 7040, 'ors': 7041, 'stool': 7042, 'prasad': 7043, '98321561': 7044, 'familiar': 7045, 'prasanth': 7046, 'ettans': 7047, 'youphone': 7048, 'athome': 7049, 'youwanna': 7050, 'enna': 7051, 'kalaachutaarama': 7052, 'corvettes': 7053, 'nevr': 7054, 'unrecognized': 7055, 'somone': 7056, 'valuing': 7057, 'definitly': 7058, 'undrstnd': 7059, 'gained': 7060, 'kg': 7061, 'pressure': 7062, 'limits': 7063, 'onwords': 7064, 'mtnl': 7065, 'mumbai': 7066, 'comprehensive': 7067, 'relieved': 7068, 'westonzoyland': 7069, 'ffffuuuuuuu': 7070, 'famous': 7071, \"'anything'\": 7072, 'unconditionally': 7073, 'temper': 7074, \"'married'\": 7075, 'zac': 7076, 'forced': 7077, 'lolnice': 7078, 'christ': 7079, 'repent': 7080, 'praveesh': 7081, 'delicious': 7082, 'dvg': 7083, 'vinobanagar': 7084, 'åòharry': 7085, 'potter': 7086, 'phoenix': 7087, 'harry': 7088, 'readers': 7089, 'get4an18th': 7090, 'nachos': 7091, '08715203652': 7092, '42810': 7093, 'minimum': 7094, '3miles': 7095, 'cthen': 7096, 'conclusion': 7097, 'references': 7098, 'wikipedia': 7099, 'syria': 7100, 'acted': 7101, 'upon': 7102, 'sooooo': 7103, 'taka': 7104, 'salesman': 7105, 'puzzeles': 7106, 'stalk': 7107, 'profiles': 7108, 'goodmate': 7109, 'asusual': 7110, 'cheered': 7111, 'franyxxxxx': 7112, 'pocay': 7113, 'wocay': 7114, '2morrowxxxx': 7115, '45pm': 7116, 'basketball': 7117, 'outdoors': 7118, 'sorta': 7119, 'blown': 7120, 'ajith': 7121, '116': 7122, 'atten': 7123, 'worlds': 7124, 'discreet': 7125, '83110': 7126, 'neglect': 7127, 'hardly': 7128, 'dartboard': 7129, 'doubles': 7130, 'trebles': 7131, 'motherfucker': 7132, 'stu': 7133, 'truble': 7134, 'evone': 7135, 'hates': 7136, 'strict': 7137, 'asjesus': 7138, 'wrote': 7139, 'dippeditinadew': 7140, 'lovingly': 7141, 'itwhichturnedinto': 7142, 'gifted': 7143, 'tomeandsaid': 7144, 'grave': 7145, 'wtc': 7146, 'weiyi': 7147, 'revealing': 7148, 'gauti': 7149, 'sehwag': 7150, 'odi': 7151, 'okmail': 7152, 'mathews': 7153, 'tait': 7154, 'edwards': 7155, 'anderson': 7156, 'twins': 7157, 'amigos': 7158, 'burn': 7159, 'wrking': 7160, 'stage': 7161, 'macha': 7162, 'mindset': 7163, 'significance': 7164, 'follows': 7165, 'subsequent': 7166, '09050001808': 7167, 'm95': 7168, \"'its\": 7169, 'dial': 7170, 'browser': 7171, 'surf': 7172, 'missunderstding': 7173, \"one's\": 7174, \"it'll\": 7175, 'smarter': 7176, 'shattered': 7177, 'coco': 7178, 'cock': 7179, \"hubby's\": 7180, '89938': 7181, 'strings': 7182, '50ea': 7183, 'otbox': 7184, '731': 7185, 'la1': 7186, '7ws': 7187, 'accenture': 7188, 'greece': 7189, \"unicef's\": 7190, 'asian': 7191, 'tsunami': 7192, 'disaster': 7193, 'fund': 7194, '864233': 7195, 'frog': 7196, 'mad1': 7197, 'mad2': 7198, \"taylor's\": 7199, 'mina': 7200, \"nobody's\": 7201, '8077': 7202, 'machines': 7203, 'wildlife': 7204, 'want2come': 7205, 'that2worzels': 7206, 'wizzle': 7207, 'baaaaabe': 7208, 'misss': 7209, 'youuuuu': 7210, 'we\\x89û÷ll': 7211, 'wishlist': 7212, 'section': 7213, 'nitro': 7214, 'korean': 7215, \"leona's\": 7216, 'hasnt': 7217, 'dose': 7218, 'tablet': 7219, '08719181259': 7220, 'can\\x89û÷t': 7221, '7634': 7222, '7684': 7223, 'parties': 7224, 'clip': 7225, '35p': 7226, 'mmsto': 7227, '32323': 7228, 'plate': 7229, 'leftovers': 7230, 'tke': 7231, 'sacked': 7232, 'celebrate': 7233, 'fondly': 7234, 'ceiling': 7235, 'showers': 7236, 'possessiveness': 7237, 'poured': 7238, 'golden': 7239, 'ignorant': 7240, 'freaky': 7241, 'granite': 7242, 'explosive': 7243, 'nasdaq': 7244, 'cdgt': 7245, '08712400200': 7246, 'withdraw': 7247, 'anyhow': 7248, 'dreading': 7249, 'thou': 7250, 'netflix': 7251, '1hr': 7252, 'sooo': 7253, 'involve': 7254, 'imposed': 7255, '30th': 7256, 'areyouunique': 7257, 'jam': 7258, 'hannaford': 7259, 'wheat': 7260, 'chex': 7261, 'bognor': 7262, 'splendid': 7263, 'deduct': 7264, 'le': 7265, '61200': 7266, 'packs': 7267, 'itcould': 7268, 'tix': 7269, 'solihull': 7270, 'skateboarding': 7271, 'thrown': 7272, 'winds': 7273, 'bandages': 7274, 'situations': 7275, 'loosing': 7276, 'loyal': 7277, 'customers': 7278, '09066380611': 7279, 'xafter': 7280, 'cst': 7281, 'chg': 7282, 'steak': 7283, 'hero': 7284, 'apt': 7285, '9061100010': 7286, 'wire3': 7287, '1st4terms': 7288, 'mobcudb': 7289, \"weren't\": 7290, 'disastrous': 7291, 'flippin': 7292, 'elama': 7293, 'mudyadhu': 7294, \"sms'd\": 7295, 'surgical': 7296, 'emergency': 7297, 'unfolds': 7298, 'patty': 7299, 'haul': 7300, 'sonetimes': 7301, 'rough': 7302, 'brdget': 7303, 'jones': 7304, 'shb': 7305, 'marking': 7306, 'evaporated': 7307, 'stealing': 7308, \"employer's\": 7309, 'factory': 7310, 'install': 7311, 'browse': 7312, 'artists': 7313, 'lastest': 7314, 'stereophonics': 7315, 'marley': 7316, 'dizzee': 7317, 'racal': 7318, 'libertines': 7319, 'strokes': 7320, 'nookii': 7321, 'bookmark': 7322, 'lists': 7323, 'detail': 7324, 'signal': 7325, 'neither': 7326, 'unusual': 7327, 'misplaced': 7328, 'associate': 7329, 'aluable': 7330, 'ffectionate': 7331, 'oveable': 7332, 'ternal': 7333, 'oble': 7334, 'ruthful': 7335, 'ntimate': 7336, 'atural': 7337, 'namous': 7338, 'hon': 7339, 'doinat': 7340, 'increase': 7341, '3000': 7342, 'dao': 7343, 'careful': 7344, '078498': 7345, '08719180219': 7346, 'uncomfortable': 7347, 'rdy': 7348, '08714712394': 7349, '30pm': 7350, 'thout': 7351, 'irritation': 7352, '50s': 7353, 'alot': 7354, '49557': 7355, 'receipts': 7356, 'pendent': 7357, 'intrepid': 7358, 'duo': 7359, 'submitting': 7360, 'wining': 7361, '946': 7362, '0871277810710p': 7363, 'srsly': 7364, 'yi': 7365, 'radiator': 7366, 'tok': 7367, 'recorded': 7368, 'stereo': 7369, 'mi': 7370, 'unknown': 7371, 'thasa': 7372, 'messed': 7373, 'doke': 7374, 'dressed': 7375, 'laying': 7376, '08718730555': 7377, 'imp': 7378, 'hittng': 7379, 'reflex': 7380, 'fans': 7381, '0870141701216': 7382, '120p': 7383, 'ringing': 7384, 'houseful': 7385, 'brats': 7386, 'pulling': 7387, 'inpersonation': 7388, 'flea': 7389, 'reminded': 7390, 'chick': 7391, 'boobs': 7392, '1b6a5ecef91ff9': 7393, '37819': 7394, 'true18': 7395, '0430': 7396, 'jul': 7397, 'evenings': 7398, 'brin': 7399, 'sheet': 7400, 'casualty': 7401, 'stuff42moro': 7402, 'includes': 7403, 'cheque': 7404, 'ay': 7405, 'cloud': 7406, 'river': 7407, '083': 7408, '6089': 7409, 'isaiah': 7410, 'canåõt': 7411, 'isnåõt': 7412, 'shite': 7413, 'kip': 7414, 'smokin': 7415, 'threats': 7416, 'sales': 7417, 'shifad': 7418, 'raised': 7419, 'complaint': 7420, 'twenty': 7421, 'durham': 7422, 'reserved': 7423, 'seat': 7424, 'art': 7425, 'borrow': 7426, 'x29': 7427, '09065989180': 7428, '08719899230': 7429, 'dhanush': 7430, 'rocks': 7431, 'passport': 7432, '08718738034': 7433, 'seing': 7434, 'asssssholeeee': 7435, \"account's\": 7436, 'gandhipuram': 7437, 'grooved': 7438, 'ccna': 7439, 'julianaland': 7440, 'oblivious': 7441, '09061701851': 7442, 'k61': 7443, '12hours': 7444, 'sd': 7445, '83021': 7446, 'fellow': 7447, 'grasp': 7448, '08719181503': 7449, 'painful': 7450, 'recognises': 7451, 'nauseous': 7452, 'dieting': 7453, 'deny': 7454, 'problematic': 7455, 'nos': 7456, 'alter': 7457, 'drugdealer': 7458, 'massages': 7459, 'formally': 7460, 'screen': 7461, 'tomorro': 7462, 'taught': 7463, 'becaus': 7464, 'verifying': 7465, 'prabu': 7466, 'chachi': 7467, 'pl': 7468, 'tiz': 7469, 'kanagu': 7470, 'loud': 7471, 'spontaneously': 7472, 'goodevening': 7473, 'wisdom': 7474, 'mention': 7475, 'served': 7476, '32000': 7477, 'legitimat': 7478, 'efreefone': 7479, 'cough': 7480, 'silly': 7481, 'isn\\x89û÷t': 7482, 'cereals': 7483, 'gari': 7484, 'algarve': 7485, 'clothes': 7486, \"zaher's\": 7487, 'hiphop': 7488, 'interfued': 7489, 'seeking': 7490, 'underdtand': 7491, 'shadow': 7492, 'spring': 7493, '07808': 7494, 'xxxxxx': 7495, '08719899217': 7496, '08448350055': 7497, 'planettalkinstant': 7498, 'pocked': 7499, 'naal': 7500, 'eruku': 7501, 'taj': 7502, 'mahal': 7503, 'lesser': 7504, 'known': 7505, 'facts': 7506, \"shahjahan's\": 7507, 'wifes': 7508, 'shahjahan': 7509, 'arises': 7510, 'hari': 7511, 'adi': 7512, 'entey': 7513, 'nattil': 7514, 'kittum': 7515, 'tall': 7516, 'gonnamissu': 7517, 'buttheres': 7518, 'aboutas': 7519, 'merememberin': 7520, 'asthere': 7521, 'ofsi': 7522, 'breakin': 7523, 'yaxx': 7524, 'finishd': 7525, 'wlcome': 7526, 'lion': 7527, 'spys': 7528, 'computational': 7529, 'push': 7530, 'honestly': 7531, 'promptly': 7532, 'burnt': 7533, 'companion': 7534, 'chef': 7535, 'listener': 7536, 'organizer': 7537, 'sympathetic': 7538, 'athletic': 7539, 'courageous': 7540, 'determined': 7541, 'dependable': 7542, 'psychologist': 7543, 'pest': 7544, 'exterminator': 7545, 'psychiatrist': 7546, 'healer': 7547, 'stylist': 7548, 'driver': 7549, 'aaniye': 7550, 'pudunga': 7551, 'venaam': 7552, 'leanne': 7553, 'que': 7554, 'pases': 7555, 'buen': 7556, 'tiempo': 7557, 'rewarding': 7558, '08714712388': 7559, 'hellogorgeous': 7560, 'lst': 7561, 'nitw': 7562, 'texd': 7563, 'hopeu': 7564, '4ward': 7565, 'jaz': 7566, 'bhaji': 7567, 'cricketer': 7568, 'sigh': 7569, 'starving': 7570, 'crammed': 7571, 'deficient': 7572, 'pei': 7573, 'warned': 7574, 'sprint': 7575, 'axis': 7576, 'greatness': 7577, 'heavily': 7578, 'gpu': 7579, 'correctly': 7580, 'arty': 7581, 'collages': 7582, 'tryin': 7583, 'nick': 7584, 'types': 7585, '08718730666': 7586, 'punto': 7587, 'woulda': 7588, 'å£1million': 7589, 'ppt150x3': 7590, 'box403': 7591, 'w1t1jy': 7592, 'juswoke': 7593, 'boatin': 7594, 'docks': 7595, 'spinout': 7596, 'watchin': 7597, 'chastity': 7598, 'device': 7599, 'beatings': 7600, 'fires': 7601, 'upgrdcentre': 7602, '9153': 7603, 'girlie': 7604, 'sarasota': 7605, 'bull': 7606, 'floating': 7607, 'cumming': 7608, 'adjustable': 7609, 'cooperative': 7610, 'allows': 7611, 'units': 7612, 'accent': 7613, '4years': 7614, 'dental': 7615, 'nmde': 7616, 'tai': 7617, 'feng': 7618, 'reservations': 7619, '09050000928': 7620, 'grumble': 7621, 'å£1000call': 7622, '09071512432': 7623, '300603t': 7624, 'callcost150ppmmobilesvary': 7625, 'nìâte': 7626, 'turned': 7627, 'data': 7628, 'analysis': 7629, 'grateful': 7630, 'happier': 7631, 'highest': 7632, 'å£54': 7633, 'maximum': 7634, 'å£71': 7635, 'pt2': 7636, 'saibaba': 7637, 'colany': 7638, 'depression': 7639, 'beneath': 7640, 'pale': 7641, 'weighed': 7642, 'woohoo': 7643, '4the': 7644, 'payed': 7645, 'suganya': 7646, 'multimedia': 7647, 'draws': 7648, '09061701939': 7649, 's89': 7650, 'ecstasy': 7651, 'msgrcvd': 7652, 'customercare': 7653, 'props': 7654, 'maaaan': 7655, '07808726822': 7656, '9758': 7657, 'hiding': 7658, 'honeymoon': 7659, 'outfit': 7660, 'panasonic': 7661, 'bluetoothhdset': 7662, 'doublemins': 7663, 'doubletxt': 7664, 'lambu': 7665, 'ji': 7666, 'batchlor': 7667, 'stitch': 7668, 'trouser': 7669, \"anything's\": 7670, 'soz': 7671, 'imat': 7672, 'mums': 7673, 'ft': 7674, 'combination': 7675, 'priority': 7676, 'amused': 7677, 'reffering': 7678, 'getiing': 7679, 'nighters': 7680, 'persevered': 7681, 'tahan': 7682, 'anot': 7683, 'lo': 7684, 'guessin': 7685, 'uawake': 7686, 'feellikw': 7687, 'justfound': 7688, 'aletter': 7689, 'thatmum': 7690, 'gotmarried': 7691, '4thnov': 7692, 'ourbacks': 7693, 'fuckinnice': 7694, 'dear1': 7695, 'best1': 7696, 'clos1': 7697, 'lvblefrnd': 7698, 'jstfrnd': 7699, 'cutefrnd': 7700, 'lifpartnr': 7701, 'swtheart': 7702, 'bstfrnd': 7703, 'popping': 7704, 'ibuprofens': 7705, 'mag': 7706, '24th': 7707, 'returning': 7708, 'dramatic': 7709, 'leg': 7710, 'musta': 7711, 'overdid': 7712, 'jon': 7713, 'spain': 7714, 'sum': 7715, 'dinero': 7716, 'åôrents': 7717, '000pes': 7718, 'å£48': 7719, 'breakfast': 7720, 'hamper': 7721, '61610': 7722, '08712400602450p': 7723, 'provided': 7724, 'tones2you': 7725, 'db': 7726, 'bhaskar': 7727, '09096102316': 7728, '07090298926': 7729, '9307622': 7730, 'asus': 7731, 'reformat': 7732, 'tau': 7733, 'piah': 7734, 'hanks': 7735, 'lotsly': 7736, 'hui': 7737, 'xin': 7738, 'lib': 7739, 'sorts': 7740, 'fightng': 7741, 'dificult': 7742, 'sticky': 7743, 'fucks': 7744, 'sometme': 7745, 'pobox202': 7746, 'nr31': 7747, '7zs': 7748, '450pw': 7749, 'faggot': 7750, 'tarot': 7751, '85555': 7752, \"there'll\": 7753, 'shindig': 7754, 'assumed': 7755, 'breadstick': 7756, 'invaders': 7757, 'orig': 7758, 'console': 7759, 'scratches': 7760, 'resubbing': 7761, 'newquay': 7762, '1im': 7763, 'talkin': 7764, 'limited': 7765, 'gail': 7766, 'l8tr': 7767, 'yaxxx': 7768, 'bcaz': 7769, 'lipo': 7770, 'humanities': 7771, 'grown': 7772, 'nationwide': 7773, 'newport': 7774, '07973788240': 7775, '08715203649': 7776, 'mc': 7777, 'avalarr': 7778, 'hollalater': 7779, 'parking': 7780, 'bawling': 7781, 'failure': 7782, 'failing': 7783, 'cashed': 7784, 'announced': 7785, 'blog': 7786, 'soryda': 7787, 'sory': 7788, 'inner': 7789, 'tigress': 7790, 'ebay': 7791, '123': 7792, '09050002311': 7793, 'b4280703': 7794, '08718727868': 7795, 'documents': 7796, 'submitted': 7797, 'stapati': 7798, 'ditto': 7799, '07808247860': 7800, '08719899229': 7801, '40411': 7802, '09061702893': 7803, 'khelate': 7804, 'kintu': 7805, 'opponenter': 7806, 'dhorte': 7807, 'lage': 7808, \"tm'ing\": 7809, 'laughs': 7810, 'adding': 7811, 'zeros': 7812, 'savings': 7813, 'hos': 7814, 'heroes': 7815, 'tips': 7816, 'genes': 7817, 'begun': 7818, 'registration': 7819, 'permanent': 7820, 'residency': 7821}\n",
      "\n",
      "단어 집합의 크기: 7822\n",
      "\n",
      "각 단어에 대한 등장 빈도수:  odict_items([('sorry', 101), ('i', 1832), (\"can't\", 47), ('help', 44), ('you', 1644), ('on', 404), ('this', 258), ('am', 171), ('in', 664), ('bus', 22), ('the', 1003), ('way', 75), ('to', 1679), ('calicut', 2), ('thanks', 65), ('again', 55), ('for', 525), ('your', 519), ('reply', 105), ('today', 108), ('when', 221), ('is', 643), ('ur', 256), ('visa', 1), ('coming', 41), ('and', 754), ('r', 113), ('u', 859), ('still', 125), ('buying', 5), ('gucci', 1), ('bags', 2), ('my', 551), ('sister', 13), ('things', 31), ('are', 383), ('not', 336), ('easy', 20), ('uncle', 12), ('john', 7), ('also', 48), ('has', 79), ('his', 50), ('own', 10), ('bills', 2), ('so', 353), ('really', 71), ('need', 142), ('think', 93), ('about', 126), ('how', 235), ('make', 79), ('money', 52), ('later', 84), ('sha', 4), ('liked', 6), ('new', 100), ('house', 33), ('hello', 45), ('darlin', 14), ('ive', 9), ('finished', 17), ('college', 14), ('now', 360), ('txt', 119), ('me', 614), ('finish', 39), ('if', 297), ('can', 326), ('love', 159), ('kate', 8), ('xxx', 23), ('please', 107), ('call', 403), ('08712402779', 1), ('immediately', 8), ('as', 133), ('there', 152), ('an', 70), ('urgent', 54), ('message', 60), ('waiting', 40), ('know', 201), ('girls', 13), ('always', 41), ('safe', 10), ('selfish', 2), ('got', 182), ('it', 463), ('pa', 23), ('thank', 20), ('good', 178), ('night', 92), ('lol', 59), ('have', 431), ('made', 18), ('plans', 6), ('years', 21), ('didnt', 21), ('get', 304), ('full', 17), ('msg', 76), ('sometext', 1), ('missing', 18), ('send', 135), ('congrats', 12), (\"that's\", 45), ('great', 89), ('wanted', 24), ('tell', 110), ('score', 3), ('cos', 61), ('might', 30), ('relax', 5), ('but', 352), ('its', 164), ('motivating', 1), ('sharing', 1), ('yes', 74), ('posted', 6), ('a', 1056), ('couple', 12), ('of', 443), ('pics', 16), ('fb', 5), (\"there's\", 27), ('snow', 12), ('outside', 14), ('too', 87), (\"i'm\", 309), ('just', 277), ('waking', 5), ('up', 248), ('stuff', 35), ('will', 288), ('do', 302), ('yeah', 71), ('should', 81), ('use', 40), ('gt', 235), ('atm', 1), ('register', 2), ('sure', 58), ('anyway', 20), ('let', 59), ('be', 297), ('ready', 35), ('yup', 31), ('havent', 20), ('been', 90), ('before', 50), ('want', 158), ('go', 223), ('yoga', 6), ('book', 21), ('aiyar', 3), ('dun', 46), ('disturb', 9), ('liao', 31), ('thk', 42), ('lots', 12), ('2', 373), ('aft', 13), ('cupboard', 1), ('come', 165), ('what', 209), ('hook', 5), ('means', 20), ('right', 70), ('no', 263), ('was', 169), ('busy', 20), ('length', 1), ('e', 76), ('same', 38), ('top', 15), ('shorter', 2), ('n', 104), ('fringe', 2), ('going', 138), ('lazy', 8), ('wan', 42), ('distract', 2), ('resume', 2), ('awesome', 13), ('text', 155), (\"you're\", 42), ('restocked', 1), ('ok', 207), ('lor', 138), ('or', 312), ('look', 25), ('4', 236), ('promotion', 1), ('number', 73), ('8714714', 1), ('awarded', 27), ('city', 3), ('break', 13), ('could', 47), ('win', 45), ('å£200', 7), ('summer', 5), ('shopping', 30), ('spree', 6), ('every', 58), ('wk', 33), ('store', 10), ('88039', 4), ('skilgme', 4), ('tscs087147403231winawk', 3), ('age16', 8), ('å£1', 26), ('50perwksub', 3), ('loans', 2), ('any', 113), ('purpose', 2), ('even', 47), ('bad', 23), ('credit', 9), ('tenants', 2), ('welcome', 10), ('noworriesloans', 1), ('com', 49), ('08717111821', 1), ('only', 154), ('yesterday', 17), ('true', 19), ('usual', 4), (\"guy's\", 1), ('out', 207), ('town', 26), (\"there're\", 2), ('definitely', 6), ('people', 30), ('around', 52), ('colours', 2), ('one', 134), ('colour', 18), ('quite', 27), ('light', 9), ('other', 41), ('darker', 1), ('actually', 22), ('done', 42), (\"she's\", 12), ('styling', 1), ('hair', 20), ('tagged', 1), ('friends', 37), ('that', 397), ('seemed', 3), ('count', 1), ('alright', 23), ('thinkin', 7), ('haha', 40), ('mon', 7), ('okie', 12), ('best', 38), ('cheap', 7), ('gd', 15), ('food', 17), ('la', 5), ('ex', 9), ('oso', 19), ('depends', 7), ('whether', 1), ('wana', 10), ('eat', 27), ('western', 1), ('chinese', 4), ('den', 29), ('which', 44), ('prefer', 3), ('lovely', 11), ('smell', 1), (\"ain't\", 4), ('tobacco', 1), ('he', 155), ('remains', 2), ('bro', 1), ('amongst', 1), ('bros', 2), ('winner', 8), ('specially', 6), ('selected', 17), ('receive', 23), ('å£1000', 22), ('cash', 58), ('å£2000', 16), ('award', 21), ('speak', 23), ('live', 27), ('operator', 9), ('claim', 76), ('087147123779am', 1), ('7pm', 4), ('cost', 23), ('10p', 16), ('huh', 20), ('early', 30), ('then', 188), ('ì', 102), ('having', 31), ('dinner', 29), ('izzit', 5), ('unlimited', 13), ('08712402902', 1), ('wonder', 9), ('online', 20), ('had', 83), ('gone', 12), ('net', 19), ('cafe', 4), ('did', 89), ('phone', 89), ('recharged', 1), ('were', 47), ('boytoy', 14), ('piggy', 1), ('awake', 4), ('bet', 4), (\"u're\", 6), ('sleeping', 13), ('lunch', 33), ('cal', 5), ('sir', 26), ('meeting', 26), ('pansy', 1), (\"you've\", 12), ('living', 4), ('jungle', 1), ('two', 19), ('driving', 19), ('more', 84), ('worried', 10), ('won', 47), ('1', 84), ('000', 23), ('prize', 70), ('call09050000327', 2), ('dont', 110), ('show', 21), ('yourself', 18), ('far', 14), ('put', 22), ('pictures', 4), ('facebook', 8), ('hiya', 9), ('hows', 11), ('sunny', 3), ('africa', 1), ('hope', 87), ('avin', 1), ('time', 171), ('give', 70), ('big', 27), ('old', 17), ('silver', 1), ('back', 126), ('kiss', 24), ('from', 210), ('din', 5), ('c', 75), ('cut', 11), ('vikky', 5), ('lt', 234), ('at', 303), ('truro', 1), ('hospital', 6), ('ext', 1), ('here', 91), ('by', 118), ('side', 10), ('monday', 9), ('nxt', 6), ('week', 85), ('vl', 7), ('completing', 1), ('both', 18), ('shoot', 4), ('loads', 7), ('miss', 55), ('baby', 25), ('4eva', 2), ('ringtone', 23), ('order', 19), ('reference', 7), ('x49', 2), ('mobile', 97), ('charged', 11), ('50', 35), ('tone', 37), ('arrive', 7), ('customer', 37), ('services', 15), ('09065989182', 2), ('feeling', 16), ('pls', 84), ('fill', 3), ('abiola', 11), (\"i've\", 53), ('joined', 5), ('league', 1), ('keep', 52), ('touch', 14), ('mean', 17), ('deal', 7), ('friend', 40), ('all', 191), ('times', 19), ('personal', 3), ('pic', 12), ('re', 20), ('ambrith', 1), ('madurai', 1), ('met', 8), ('arun', 1), ('dha', 1), ('marrge', 1), ('remembr', 2), ('training', 8), ('per', 42), ('request', 5), (\"'melle\", 1), ('melle', 1), ('oru', 2), ('minnaminunginte', 1), ('nurungu', 1), ('vettam', 1), (\"'\", 6), ('set', 11), ('callertune', 4), ('callers', 2), ('press', 6), ('9', 21), ('copy', 4), ('bahamas', 2), ('callfreefone', 1), ('08081560665', 1), ('either', 11), ('cruise', 1), ('ofå£2000', 1), ('18', 35), ('opt', 10), ('x', 43), ('07786200117', 1), ('congratulations', 12), ('å£500', 13), ('cd', 5), ('gift', 19), ('vouchers', 11), ('free', 198), ('entry', 15), ('our', 108), ('å£100', 16), ('weekly', 15), ('draw', 33), ('music', 13), ('87066', 8), ('tncs', 5), ('www', 68), ('ldew', 6), ('com1win150ppmx3age16', 3), ('v', 45), ('romantic', 5), ('85233', 1), ('real', 30), ('sry', 2), ('talk', 37), ('with', 274), ('parents', 9), ('sec', 4), ('cancelled', 2), ('well', 82), ('sounds', 12), ('important', 21), ('understand', 9), ('ring', 16), ('fone', 10), ('88066', 3), ('lost', 9), ('å£12', 1), ('private', 14), ('2003', 11), ('account', 28), ('statement', 13), ('shows', 30), ('800', 12), ('un', 12), ('redeemed', 11), ('s', 46), ('m', 27), ('points', 16), ('08718738002', 1), ('identifier', 14), ('code', 26), ('48922', 1), ('expires', 14), ('21', 5), ('11', 14), ('04', 10), ('stranger', 3), ('choose', 13), ('long', 37), ('world', 20), ('stands', 1), ('friendship', 10), ('never', 33), ('ends', 6), ('lets', 14), ('forever', 9), ('gud', 37), ('nitz', 1), ('nothing', 25), ('getting', 42), ('msgs', 13), ('dis', 19), ('name', 35), ('wit', 13), ('different', 6), (\"no's\", 1), ('str', 2), ('down', 44), ('ard', 19), ('3', 62), ('smth', 13), ('already', 75), ('they', 94), ('released', 3), ('another', 28), ('italian', 3), ('cosign', 1), ('option', 2), ('checking', 7), ('happening', 6), ('area', 8), ('thursday', 4), ('thing', 48), (\"we'll\", 17), ('work', 67), ('11mths', 7), ('update', 18), ('oranges', 2), ('latest', 27), ('camera', 23), ('mobiles', 8), ('weekend', 24), ('calls', 16), ('upd8', 2), ('freefone', 3), ('08000839402', 10), ('2stoptxt', 2), ('us', 49), ('connection', 4), ('itself', 9), ('decimal', 13), ('refund', 1), ('bill', 6), ('cool', 35), ('head', 17), ('hey', 97), ('hun', 5), ('onbus', 1), ('goin', 19), ('meet', 69), ('him', 94), ('wants', 15), ('2go', 2), ('4a', 2), ('meal', 4), ('donyt', 1), ('feel', 44), ('like', 189), ('cuz', 7), ('last', 58), ('home', 131), ('hes', 2), ('sweet', 22), ('latelyxxx', 1), ('wat', 77), ('doing', 69), ('aight', 28), ('textbuddy', 2), ('chat', 45), ('horny', 5), ('guys', 28), ('25p', 7), ('search', 11), ('postcode', 2), ('gaytextbuddy', 2), ('89693', 2), ('handsome', 1), ('finding', 1), ('job', 34), ('being', 30), ('working', 21), ('towards', 5), ('mummy', 2), (\"where's\", 5), ('does', 23), ('watch', 27), ('infernal', 3), ('affairs', 2), ('lar', 33), ('jus', 28), ('reached', 7), ('bathe', 9), ('first', 49), ('sis', 14), ('using', 7), ('she', 108), ('finishes', 3), ('k', 124), ('goodo', 1), ('we', 266), ('must', 22), ('friday', 11), ('egg', 3), ('potato', 2), ('ratio', 1), ('tortilla', 1), ('needed', 2), ('juz', 22), ('remembered', 3), ('gotta', 10), ('dog', 6), ('attracts', 1), ('brothas', 3), ('wet', 5), ('trip', 18), ('nigeria', 7), ('wish', 39), ('happiness', 8), ('very', 53), ('soon', 43), ('company', 14), ('share', 4), ('moments', 3), ('bluray', 1), ('player', 13), ('charge', 17), ('morning', 50), ('see', 120), ('tomorrow', 60), ('super', 5), ('da', 117), ('nalla', 2), ('timing', 4), ('reason', 11), (\"we've\", 4), ('spoken', 4), ('year', 36), ('anyways', 3), ('exam', 11), ('hack', 1), ('backdoor', 1), ('into', 26), ('121', 2), ('rooms', 2), ('fraction', 1), ('neo69', 1), ('09050280520', 1), ('subscribe', 1), ('pm', 12), ('dps', 1), ('bcm', 1), ('box', 26), ('8027', 1), ('ldn', 6), ('wc1n3xx', 3), ('person', 29), (\"who's\", 5), ('sms', 36), ('survey', 1), ('exhausted', 3), ('train', 7), ('much', 89), ('wine', 5), ('pie', 4), ('sleep', 47), ('nt', 15), ('yet', 36), ('chikku', 20), ('simple', 6), ('habba', 1), ('hw', 6), ('abt', 23), ('normally', 3), ('drink', 16), ('water', 8), ('daily', 4), ('aah', 2), ('cuddle', 3), ('would', 65), ('lush', 2), (\"i'd\", 11), ('tea', 6), ('soup', 2), ('kind', 13), ('fumbling', 1), ('hi', 107), (\"harish's\", 1), ('rent', 7), ('transfred', 1), ('acnt', 1), ('pass', 10), ('silently', 2), ('say', 73), ('thinking', 16), ('making', 22), ('least', 8), ('moment', 8), ('swt', 5), ('drms', 2), ('shesil', 3), ('y', 36), ('said', 57), (\"it's\", 70), ('dat', 30), ('gals', 5), ('kicks', 2), ('off', 48), (\"i'll\", 110), ('day', 152), ('almost', 10), ('wif', 20), ('tot', 20), ('take', 104), ('nap', 3), ('her', 101), ('picking', 8), ('date', 15), ('sunday', 9), ('saw', 19), ('unni', 1), ('dear', 78), ('recharge', 1), ('rakhesh', 5), ('airport', 5), ('road', 7), ('630', 2), ('oredi', 14), ('lot', 26), ('pple', 5), ('why', 64), ('computer', 10), ('fried', 1), ('essential', 3), ('part', 19), (\"don't\", 110), ('spares', 1), ('because', 28), ('fucking', 13), ('idiot', 4), ('roommates', 2), ('looovvve', 1), ('leaving', 13), ('running', 3), ('7', 29), ('ip', 1), ('address', 16), ('test', 17), ('considering', 3), (\"isn't\", 9), ('minecraft', 1), ('server', 1), ('thanx', 29), ('puttin', 1), ('problems', 4), ('most', 20), ('stupid', 8), ('suggestion', 1), ('lands', 1), ('problem', 31), ('helps', 1), ('forgt', 1), ('previous', 3), ('hot', 19), ('fantasies', 4), ('08707509020', 4), ('20p', 7), ('min', 51), ('ntt', 7), ('ltd', 14), ('po', 22), ('1327', 5), ('croydon', 5), ('cr9', 5), ('5wb', 5), ('0870', 5), ('few', 31), ('may', 30), ('pub', 13), ('waitin', 4), ('ìï', 48), ('sch', 21), ('sad', 13), ('story', 10), ('man', 32), (\"b'day\", 4), ('wife', 15), (\"did'nt\", 2), ('forgot', 22), ('kids', 7), ('went', 39), ('colleagues', 4), ('entered', 7), ('cabin', 2), (\"''\", 9), ('happy', 61), ('boss', 5), ('felt', 9), ('special', 25), ('askd', 6), ('after', 67), ('invited', 7), ('apartment', 2), ('mind', 25), ('bedroom', 4), ('minute', 12), (\"''ok''\", 2), ('sed', 2), ('sexy', 19), ('mood', 4), ('came', 20), ('5', 36), ('minuts', 2), ('latr', 2), ('wid', 10), ('cake', 4), ('kidz', 2), ('screaming', 4), ('surprise', 8), ('sofa', 7), ('naked', 3), ('someone', 48), ('toyota', 1), ('camry', 1), ('mr', 9), (\"olayiwola's\", 1), ('mileage', 1), ('clean', 7), ('sell', 10), ('raise', 3), ('dough', 2), ('landing', 1), ('holla', 6), ('some', 97), ('walk', 15), ('rofl', 3), ('betta', 1), ('invest', 2), ('anti', 3), ('aging', 1), ('products', 1), ('oh', 98), ('god', 18), ('taken', 4), ('teeth', 2), ('paining', 1), ('check', 28), ('corect', 1), ('speling', 1), ('sarcasm', 2), ('loyalty', 4), ('offer', 23), ('nokia6650', 1), ('å£10', 7), ('txtauction', 3), ('word', 28), ('start', 24), ('81151', 2), ('yours', 15), ('4t', 2), ('ctxt', 1), ('tc', 7), ('150p', 48), ('mtmsg', 1), ('tee', 2), ('hee', 12), ('lecture', 3), ('cheery', 1), ('bye', 4), ('studying', 7), ('b', 64), ('service', 35), ('announcement', 5), ('premier', 2), ('kent', 2), ('vale', 2), ('wait', 50), ('ar', 8), ('elsewhere', 3), ('car', 29), (\"dat's\", 2), ('bored', 15), ('tv', 20), ('cant', 43), ('theatre', 4), ('wherever', 4), ('where', 79), ('fujitsu', 2), ('ibm', 1), ('hp', 1), ('toshiba', 2), ('model', 5), ('skyped', 2), ('kz', 2), ('sura', 5), ('pleasure', 4), ('given', 2), ('ultimatum', 2), ('countin', 2), ('aburo', 2), ('enjoy', 31), ('er', 2), ('didn\\x89û÷t', 2), ('plan', 26), ('\\x89ûò', 8), ('limping', 1), ('slowly', 5), ('followed', 3), ('aa', 1), ('exhaust', 1), ('hanging', 4), ('chillaxin', 1), ('point', 10), ('guess', 28), ('designation', 1), ('software', 3), ('developer', 1), ('chennai', 10), ('nobody', 6), ('names', 2), ('their', 10), ('penis', 2), (\"doesn't\", 13), ('add', 6), ('09066649731from', 1), ('landline', 23), ('complimentary', 8), ('ibiza', 4), ('holiday', 29), ('await', 13), ('collection', 17), ('sae', 15), ('t', 48), ('cs', 31), ('434', 5), ('sk3', 3), ('8wp', 3), ('150ppm', 25), ('moby', 3), ('quiz', 7), ('high', 7), ('street', 9), ('who', 70), ('duchess', 2), ('cornwall', 3), ('82277', 5), ('unsub', 4), ('stop', 115), ('008704050406', 2), ('sp', 6), ('arrow', 1), ('testing', 2), ('card', 11), ('dunno', 26), ('network', 22), ('bathing', 3), ('cleaning', 4), ('room', 26), ('men', 8), ('alone', 16), ('nokia', 43), ('3510i', 4), ('deliveredtomorrow', 3), ('300', 4), ('minutes', 25), ('100', 11), ('texts', 24), ('camcorder', 11), ('08000930705', 12), ('im', 64), ('stil', 1), ('fucked', 1), ('nite', 18), ('tobed', 1), ('430', 1), ('pathaya', 1), ('enketa', 1), ('maraikara', 1), (\"pa'\", 1), ('try', 37), ('fact', 8), ('gosh', 1), ('pain', 20), ('spose', 1), ('better', 32), ('figures', 2), ('found', 12), ('piece', 1), (\"priscilla's\", 2), ('bowl', 2), ('ho', 5), ('these', 19), ('type', 9), ('words', 15), ('anything', 63), ('else', 20), ('salad', 1), ('desert', 2), ('something', 60), ('many', 42), ('beers', 1), ('shall', 28), ('missed', 19), ('44', 1), ('7732584351', 1), ('orange', 24), ('upgrade', 2), ('0207', 3), ('153', 2), ('9996', 1), ('14thmarch', 1), (\"c's\", 12), ('apply', 24), ('availa', 1), ('ignoring', 1), ('able', 23), ('fixed', 5), ('bluff', 1), ('leh', 25), ('yay', 3), ('gonna', 40), ('cheers', 7), ('everything', 27), ('school', 22), ('valentine', 8), ('happened', 14), ('interview', 3), ('squeeeeeze', 1), ('christmas', 8), ('hug', 3), ('lik', 2), ('frndshp', 1), ('cute', 6), ('6', 31), ('luvd', 1), ('lucky', 13), ('none', 6), ('hate', 5), ('envy', 1), ('everyone', 13), (\"see's\", 1), ('life', 64), ('donno', 2), ('scorable', 1), ('knw', 13), (\"couldn't\", 5), ('dying', 1), ('probably', 25), ('late', 45), ('freemsg', 13), ('mini', 2), ('digital', 4), ('snap', 1), ('collect', 21), ('quizclub', 1), ('80122300p', 1), ('rwm', 1), ('ph', 1), ('08704050406', 1), ('bugis', 6), ('near', 7), ('month', 25), ('chocolate', 2), ('weed', 8), ('alcohol', 3), ('supose', 1), ('worry', 22), ('film', 8), ('mate', 10), ('babysit', 1), ('xx', 16), ('rest', 9), ('250', 3), ('messages', 15), ('84025', 1), ('web2mobile', 1), ('mates', 9), ('etc', 8), ('join', 20), ('txt250', 1), ('50p', 6), ('box139', 1), ('la32wu', 1), ('16', 33), ('remove', 5), ('txtx', 1), ('approve', 1), ('panalam', 1), ('posts', 1), ('told', 45), ('gautham', 3), ('ah', 30), ('yah', 1), ('cancel', 6), ('decision', 3), ('decide', 6), ('simpler', 1), ('less', 9), ('magical', 1), ('buy', 55), ('maggi', 1), ('mee', 1), ('disturbing', 2), ('rob', 1), ('mack', 1), ('gf', 1), ('theater', 1), ('england', 8), ('macedonia', 1), ('goals', 2), ('team', 6), ('news', 12), ('national', 16), ('87077', 7), ('eg', 8), ('wales', 3), ('scotland', 2), ('4txt', 2), ('ì¼1', 1), ('20', 8), ('poboxox36504w45wq', 1), ('ask', 72), ('mistake', 7), ('gr8', 11), ('handle', 3), ('victoria', 1), ('island', 1), ('traffic', 2), ('plus', 15), (\"when's\", 2), ('album', 3), ('due', 2), ('yo', 34), ('postponed', 1), ('stocked', 1), ('logging', 1), ('geoenvironmental', 1), ('implications', 1), ('cold', 7), ('east', 1), ('coast', 2), ('hmmm', 12), ('players', 4), ('becomes', 2), ('habit', 2), ('amp', 45), ('finally', 12), ('follow', 2), (\"wasn't\", 8), ('available', 12), ('washob', 1), ('nobbing', 1), ('nickey', 1), ('platt', 1), ('instead', 3), ('isnt', 5), ('ya', 47), ('dry', 3), ('spell', 2), ('season', 4), ('over', 52), ('sense', 7), ('foot', 2), (\"haven't\", 16), ('forgotten', 2), ('bucks', 7), ('recpt', 1), ('ordered', 2), ('processed', 2), ('informed', 5), ('wanna', 31), ('pose', 1), ('comb', 1), ('dryer', 1), ('used', 11), ('ones', 9), ('babe', 58), ('youi', 1), ('bring', 20), (\"he'll\", 5), ('match', 8), ('voucher', 14), ('holder', 6), ('weeks', 9), ('pc', 8), ('http', 19), ('tlp', 3), ('co', 37), ('uk', 47), ('reward', 7), ('ts', 8), ('information', 9), ('user', 7), ('0789xxxxxxx', 1), ('2find', 2), ('log', 10), ('onto', 5), ('urawinner', 5), ('fantastic', 8), ('awaiting', 6), ('errors', 1), ('difficulties', 2), ('correction', 1), ('care', 49), ('dude', 16), ('fuck', 22), (\"he's\", 25), ('apparently', 3), ('bffs', 1), ('carly', 1), ('quick', 5), ('cruisin', 1), ('girl', 24), ('hour', 20), ('thats', 29), ('jenny', 2), ('uncles', 2), ('atlanta', 2), ('semester', 9), ('th', 9), ('gower', 1), ('ill', 35), ('åômorrow', 1), ('åð', 3), ('random', 3), ('mu', 12), ('seconds', 2), ('officially', 2), ('philosophical', 1), ('hole', 1), ('saved', 3), ('bed', 26), ('nightnight', 1), ('youdoing', 1), ('sar', 2), ('cell', 6), ('thts', 5), ('physics', 1), ('abbey', 1), ('newspapers', 1), ('di', 2), ('yijue', 5), (\"we're\", 18), ('esaplanade', 1), ('tonight', 49), ('87131', 4), ('poly', 17), ('0845', 1), ('2814032', 1), ('1st', 25), ('tones', 14), ('3xå£150pw', 1), ('eå£nd', 1), ('nope', 14), ('replied', 5), ('referin', 1), (\"mei's\", 1), ('treat', 13), ('somebody', 8), ('shld', 3), ('rich', 3), ('frm', 8), ('tmr', 21), ('onwards', 2), ('saturday', 11), ('difficult', 7), ('representative', 5), ('freephone', 4), ('0808', 1), ('145', 1), ('4742', 1), ('between', 15), ('9am', 1), ('11pm', 1), ('guaranteed', 40), ('å£5000', 11), ('inclusive', 4), ('credits', 7), ('gotto', 1), ('comuk', 7), ('login', 6), ('3qxj9', 3), ('unsubscribe', 13), ('extra', 9), ('08702840625', 3), ('220cm2', 1), ('9ae', 3), ('church', 1), ('registered', 6), ('subscriber', 4), ('yr', 12), ('receipt', 5), ('correct', 9), ('ans', 10), ('next', 51), ('olympics', 1), ('80062', 5), ('kaiez', 2), ('tuition', 5), ('gee', 6), ('second', 14), ('beta', 1), ('yan', 4), ('jiu', 4), ('takes', 13), ('away', 22), ('worries', 5), ('sick', 8), ('needy', 1), ('pouts', 2), ('stomps', 2), ('feet', 3), ('slave', 6), ('bank', 11), ('aiyah', 4), ('rain', 5), ('drizzling', 1), ('run', 18), ('ac', 8), ('blind', 2), ('4u', 5), ('rodds1', 1), ('aberdeen', 1), ('united', 1), ('kingdom', 1), ('img', 1), ('w', 14), ('icmb3cktz8r7', 1), ('dates', 2), ('hide', 1), ('carlos', 13), (\"phone's\", 1), ('vibrate', 1), ('acting', 1), ('hear', 28), ('26th', 2), ('july', 3), ('nice', 41), ('dearly', 2), ('i\\x89û÷ve', 1), ('salt', 1), ('rub', 2), ('open', 14), ('wounds', 1), ('paper', 6), ('ended', 3), ('ago', 10), ('copied', 1), ('haf', 21), ('study', 9), ('hardcore', 3), ('porn', 4), ('direct', 9), ('69200', 1), ('access', 7), ('24', 4), ('hrs', 6), ('chrgd', 1), ('2exit', 1), ('dizzamn', 1), ('suitemates', 1), ('response', 3), ('d', 50), ('powerful', 1), ('weapon', 1), ('occupy', 1), ('place', 42), ('others', 8), (\"'heart'\", 1), ('propose', 2), ('sptv', 2), ('jersey', 1), ('devils', 1), ('detroit', 2), ('red', 9), ('wings', 1), ('play', 22), ('ice', 8), ('hockey', 1), ('incorrect', 1), ('end', 36), ('beerage', 1), ('btw', 4), ('regarding', 2), ('anyone', 12), ('4th', 3), ('guy', 18), ('commit', 1), ('rhythm', 2), ('establish', 1), ('body', 5), ('learn', 4), ('meets', 2), ('smiling', 11), ('smile', 33), ('beautiful', 16), ('belly', 5), ('laugh', 9), ('tomo', 16), ('milk', 3), ('ree', 1), ('comp', 9), ('chance', 26), ('ipod', 8), ('pod', 3), ('80182', 2), ('std', 6), ('rate', 21), ('08452810073', 2), ('details', 18), ('willing', 5), ('pay', 26), ('pump', 1), ('petrol', 3), ('dump', 1), ('heap', 1), ('mom', 8), ('decided', 11), ('lowes', 1), ('boring', 5), ('justbeen', 1), ('overa', 1), ('since', 18), ('broke', 5), ('brains', 1), ('mush', 1), ('reception', 1), ('single', 6), ('line', 32), ('meaning', 3), ('luton', 1), ('0125698789', 1), ('h', 2), ('corporation', 1), ('st', 11), ('gap', 3), ('\\x89û', 11), (\"fr'ndship\", 1), ('needle', 1), ('clock', 4), ('though', 21), ('evn', 2), ('itz', 1), ('4few', 1), ('bt', 20), ('alwys', 2), ('stay', 21), ('conected', 1), ('9t', 2), ('saying', 15), ('explicitly', 1), ('nora', 1), ('bother', 6), ('no1', 5), ('mob', 14), ('8007', 13), ('txting', 8), ('getzed', 5), ('pobox', 7), ('36504', 4), ('w45wq', 3), ('norm150p', 3), ('maid', 3), ('murderer', 3), ('coz', 10), ('murdered', 3), ('january', 5), ('public', 2), ('govt', 2), ('instituitions', 2), ('closed', 4), ('including', 4), ('post', 9), ('office', 22), (\"today's\", 5), ('contents', 3), ('page', 7), ('little', 20), ('child', 3), ('afraid', 2), ('dark', 3), ('become', 5), ('teenager', 1), ('completed', 2), ('degree', 1), ('joining', 2), ('finance', 2), ('famamus', 1), ('suffering', 1), ('fever', 4), ('dysentry', 1), ('ni8', 8), ('goes', 23), ('woke', 7), ('dropped', 4), ('stairs', 1), ('seems', 6), ('phews', 1), ('shit', 26), ('surprised', 4), ('spent', 6), ('evening', 20), ('french', 1), ('fooled', 1), ('bit', 34), (\"didn't\", 33), ('collected', 2), ('simply', 5), ('password', 4), ('mix', 1), ('85069', 1), ('verify', 2), ('usher', 1), ('britney', 1), ('fml', 3), ('ish', 5), ('hang', 2), ('maybe', 27), ('westshore', 1), ('hyde', 2), ('park', 11), ('village', 5), ('spook', 2), ('halloween', 1), ('logo', 3), ('eerie', 1), ('zed', 5), ('08701417012150p', 1), ('yellow', 1), ('travel', 4), ('rite', 16), ('dad', 22), ('confirm', 10), ('club', 13), ('subs', 2), ('expired', 1), ('sub', 6), ('monoc', 1), ('monos', 1), ('polyc', 1), ('polys', 7), ('stream', 1), ('0871212025016', 1), ('nothin', 1), ('comes', 10), ('hanger', 1), ('laptop', 8), ('heavy', 5), ('tick', 3), ('ee', 2), ('na', 9), ('poortiyagi', 1), ('odalebeku', 1), ('hanumanji', 1), ('hanuman', 1), ('bajarangabali', 1), ('maruti', 1), ('pavanaputra', 1), ('sankatmochan', 1), ('ramaduth', 1), ('mahaveer', 1), ('janarige', 1), ('ivatte', 1), ('kalisidare', 1), ('olage', 1), ('ondu', 1), ('keluviri', 1), ('maretare', 1), ('inde', 1), ('dodda', 1), ('problum', 1), ('nalli', 1), ('siguviri', 1), ('idu', 1), ('matra', 1), ('neglet', 1), ('stretch', 2), ('pussy', 4), ('changed', 5), ('25', 5), ('club4mobiles', 1), ('content', 12), ('87070', 1), ('club4', 1), ('box1146', 1), ('mk45', 1), ('2wt', 1), ('nah', 9), ('iphone', 1), ('congratulation', 1), ('spend', 9), ('vewy', 2), ('lubly', 1), ('ding', 2), ('fassyole', 1), ('blacko', 1), ('londn', 1), ('changes', 3), ('report', 5), ('gym', 9), ('freezing', 1), ('craving', 1), ('dint', 4), ('angry', 8), ('abi', 4), ('senthil', 2), ('hsbc', 2), ('valentines', 6), ('partner', 4), ('lifetime', 3), ('83600', 3), ('rcvd', 6), ('custcare', 8), ('08718720201', 5), ('princess', 22), ('deleted', 3), ('website', 5), ('blogging', 1), ('magicalsongs', 1), ('blogspot', 1), ('lousy', 2), ('kept', 4), ('hours', 14), ('cat', 3), ('calling', 15), ('onam', 1), ('sirji', 1), ('fine', 36), ('insurance', 7), ('qatar', 2), ('insha', 1), ('allah', 2), ('tata', 1), ('aig', 1), ('tissco', 1), ('tayseer', 1), ('enuff', 3), ('space', 4), ('mb', 2), ('style', 5), ('garments', 1), ('shirts', 1), ('wear', 4), ('them', 62), ('nudist', 1), ('themed', 1), ('course', 9), ('elaine', 2), ('hit', 12), ('grab', 1), ('cultures', 1), ('module', 2), ('cancer', 5), ('throat', 2), ('hurts', 6), ('answering', 4), ('everyones', 1), ('babysitting', 1), ('erm', 2), ('woodland', 1), ('avenue', 1), ('somewhere', 9), ('parish', 1), ('magazine', 1), ('telephone', 2), ('trouble', 6), ('ijust', 1), ('talked', 1), ('mum', 14), ('skint', 1), ('fancied', 1), ('bevies', 1), ('waz', 1), ('gona', 3), ('othrs', 1), ('spoon', 1), ('jst', 3), ('bin', 5), ('watchng', 1), ('planet', 2), ('earth', 4), ('comfey', 1), ('hav', 19), (\"aunty's\", 1), ('tel', 11), ('sent', 51), ('affidavit', 1), ('says', 21), ('twiggs', 1), ('division', 1), ('g', 18), ('courtroom', 1), ('double', 15), ('nvm', 4), ('hella', 3), ('knows', 9), ('questions', 8), ('glad', 8), ('weekdays', 1), ('price', 18), ('haiz', 2), ('nails', 1), ('muz', 10), ('until', 19), ('drivin', 4), ('tddnewsletter', 1), ('emc1', 1), ('games', 13), ('thedailydraw', 1), ('helen', 2), ('dozens', 1), ('prizeswith', 1), ('ve', 2), ('wisheds', 1), ('rock', 8), (\"you'd\", 6), ('reboot', 2), ('ym', 3), ('photo', 6), ('grins', 11), ('alex', 6), ('hmm', 12), ('mayb', 8), ('bag', 6), ('goigng', 1), ('small', 7), ('except', 6), ('perfume', 1), ('lyricalladie', 1), ('f', 4), ('inviting', 3), ('910', 2), ('hmmross', 1), ('frnd', 12), ('62468', 3), ('monthly', 3), ('amount', 5), ('terrible', 3), ('till', 14), ('6months', 2), ('finishing', 3), ('paying', 7), ('pleasant', 1), ('checked', 3), ('balance', 6), ('statements', 1), ('acc', 5), ('morn', 2), ('cannot', 3), ('mistakes', 2), ('once', 24), ('close', 12), ('brother', 15), ('alert', 4), ('10k', 2), ('150', 8), ('09064018838', 1), ('cro1327', 1), ('vary', 3), ('watching', 24), ('movie', 19), ('xy', 6), ('shop', 15), (\"all's\", 1), ('09058094455', 1), ('land', 15), ('3030', 7), ('valid', 20), ('12hrs', 16), ('lei', 22), ('lab', 3), ('goggles', 1), ('dnt', 4), ('pieces', 3), ('cloth', 1), ('pack', 4), ('tablets', 2), ('anybody', 1), ('asks', 1), ('p', 6), ('forget', 12), ('crave', 8), ('arabian', 1), ('steed', 1), ('mmmmmm', 2), ('yummy', 2), ('giggle', 1), ('possibly', 1), ('person2die', 1), ('nvq', 1), ('09066350750', 2), ('10', 24), ('ppm', 3), ('took', 14), ('hungry', 13), ('yun', 4), ('bootydelious', 2), ('32', 1), ('squeezed', 1), ('months', 7), ('entitled', 6), ('08002986030', 1), ('todays', 14), ('voda', 4), ('numbers', 8), ('ending', 6), ('7548', 1), ('350', 2), ('08712300220', 4), ('quoting', 4), ('4041', 1), ('standard', 5), ('rates', 8), ('app', 5), ('goodmorning', 8), ('2hrs', 1), ('teach', 5), ('ship', 2), ('cars', 5), ('pick', 47), ('8th', 5), ('missin', 3), ('jess', 4), ('hurry', 7), ('favorite', 2), ('oyster', 1), ('sashimi', 1), ('stomach', 2), ('rumbling', 1), ('bird', 1), ('purchases', 1), ('warm', 8), ('bath', 9), ('cup', 4), (\"you'll\", 13), ('magic', 1), ('loose', 2), ('weight', 6), ('northampton', 1), ('xmas', 17), ('radio', 4), ('weird', 2), ('juan', 2), ('fri', 15), ('expect', 4), ('party', 9), ('presents', 1), ('nicky', 1), ('womdarfull', 1), ('actor', 2), ('yar', 12), ('mushy', 1), ('embarrassed', 1), ('horrible', 5), ('bf', 5), ('hundreds', 1), ('handsomes', 1), ('beauties', 1), ('thought', 38), ('aunties', 1), ('february', 3), ('reach', 27), ('sound', 7), ('ll', 24), ('meant', 10), ('apology', 1), ('texting', 6), ('drugs', 8), ('hold', 7), ('strong', 6), ('arms', 4), ('scarcasim', 1), ('becoz', 2), ('jan', 2), ('whn', 2), ('al', 4), ('ofice', 2), ('cn', 2), ('fr', 11), ('duffer', 1), ('booked', 8), ('ticket', 6), ('pongal', 4), (\"dip's\", 1), ('dead', 9), ('respond', 3), ('pee', 1), ('burns', 1), ('tonite', 9), ('indians', 3), ('poor', 6), ('india', 11), ('country', 5), ('swiss', 2), ('directors', 1), ('lac', 1), ('crore', 2), ('indian', 3), ('deposited', 1), ('banks', 2), (\"'taxless'\", 1), ('budget', 5), ('yrs', 6), ('jobs', 2), ('delhi', 1), ('lane', 2), ('roads', 3), ('power', 6), ('suply', 1), ('than', 36), ('social', 5), ('projects', 1), ('citizen', 3), ('imf', 1), ('loan', 6), ('blocked', 1), ('politicians', 2), ('rights', 2), ('against', 6), ('corrupt', 1), ('itna', 1), ('forward', 6), ('karo', 1), ('ki', 1), ('pura', 1), ('padhe', 1), ('that\\x89û÷s', 3), ('apes', 1), ('fight', 2), ('death', 1), ('possible', 4), ('each', 13), ('beyond', 3), ('yetunde', 4), ('returned', 2), ('mid', 4), ('return', 4), ('period', 1), ('8', 17), ('accordingly', 3), ('guai', 1), ('shd', 7), ('seen', 12), ('naughty', 6), ('jogging', 2), ('ride', 5), ('luv', 24), ('wen', 15), ('os', 2), ('called', 24), ('ubandu', 1), ('without', 19), ('installing', 2), ('hard', 11), ('disk', 1), ('files', 3), ('system', 6), ('repair', 2), ('wot', 19), ('drinkin', 2), ('dancin', 1), ('eatin', 6), ('cinema', 5), ('grr', 1), ('taking', 15), ('prescription', 2), ('pharmacy', 1), ('ugh', 10), ('legal', 4), ('advice', 5), ('gary', 3), ('split', 1), ('ptbo', 3), ('goto', 7), ('220', 2), ('cm2', 2), ('generally', 3), ('fun', 24), ('bar', 2), ('iouri', 3), ('gave', 6), ('wylie', 4), (\"ryan's\", 1), ('days', 32), ('resent', 1), ('attempt', 17), ('failed', 1), ('error', 2), ('queries', 1), ('customersqueries', 1), ('netvision', 1), ('tired', 9), ('arguing', 1), ('luck', 8), ('catches', 1), ('track', 5), ('wallet', 1), ('takin', 3), ('linear', 1), ('algebra', 1), ('don', 11), ('mrt', 8), ('whenevr', 3), ('gray', 1), ('listn', 1), ('watevr', 1), ('while', 19), ('promise', 7), ('bangbabes', 1), ('download', 10), ('wap', 10), ('bangb', 1), ('internet', 6), ('menu', 4), ('brother\\x89û÷s', 1), ('scraped', 1), ('barrel', 1), ('shower', 7), ('misfits', 1), ('seventeen', 1), ('pounds', 11), ('seven', 3), ('hundred', 2), ('ml', 1), ('listed', 1), ('catch', 8), ('2marrow', 2), ('wed', 5), ('aha', 8), ('knew', 10), ('murder', 2), ('exactly', 2), ('08715500022', 1), ('rpl', 1), ('cnl', 1), ('unfortunately', 2), ('2nights', 1), ('uve', 1), ('xchat', 4), ('uks', 2), ('wildest', 1), ('86688', 10), ('msgrcvdhg', 3), ('suite342', 8), ('2lands', 8), ('row', 12), ('w1j6hl', 6), ('18yrs', 3), ('plm', 2), ('presnts', 1), ('bcz', 1), ('mis', 2), ('jeevithathile', 1), ('irulinae', 1), ('neekunna', 1), ('prakasamanu', 1), ('sneham', 1), ('prakasam', 1), ('ennal', 1), ('prabha', 3), (\"'that\", 1), ('mns', 1), (\"is'love'\", 1), ('following', 6), ('link', 10), ('dining', 2), ('experiencehttp', 1), ('vouch4me', 1), ('etlp', 1), ('asp', 2), ('zoe', 2), ('shitin', 1), ('myself', 9), ('il', 9), ('defo', 1), ('hardest', 1), ('cum', 9), ('2morow', 3), ('millions', 1), ('lekdog', 1), ('confuses', 1), ('doesn\\x89û÷t', 1), ('ma', 4), ('fan', 2), ('madam', 3), ('sorting', 2), ('narcotics', 1), ('situation', 6), ('mark', 7), ('fat', 6), ('fingers', 4), ('buttons', 1), ('rats', 1), ('ever', 29), ('vote', 5), ('themes', 1), ('guild', 1), ('bristol', 2), ('flight', 2), ('daddy', 8), ('shu', 2), ('looking', 23), ('singapore', 1), ('siva', 2), ('tats', 1), ('movies', 5), ('father', 7), ('happen', 19), ('de', 17), ('clear', 3), ('dvd', 6), ('copies', 1), ('left', 23), ('swing', 10), ('wonderful', 11), ('urgh', 1), ('coach', 1), ('smells', 1), ('chip', 1), ('especially', 5), ('duvet', 1), ('predictive', 1), ('project', 10), ('railway', 2), ('fortune', 1), ('loves', 6), ('moves', 2), ('however', 7), ('6hrs', 4), ('doctor', 6), ('wow', 11), ('healthy', 1), ('rd', 5), ('alibi', 1), ('cutting', 1), ('whole', 13), ('jay', 10), ('snickering', 1), ('tells', 3), ('totally', 3), ('chords', 1), ('requirements', 1), ('campus', 4), ('neva', 16), ('handed', 3), ('mega', 1), ('asda', 1), ('counts', 1), ('celebration', 2), (\"ashley's\", 1), ('lmao', 5), ('billed', 3), ('shortcode', 1), ('83332', 1), ('08081263000', 1), ('charges', 4), ('refunded', 1), ('moan', 5), ('scream', 4), ('sells', 2), ('mids', 2), ('south', 5), ('tampa', 7), ('evo', 1), ('flash', 3), ('jealous', 3), ('sat', 27), ('eyes', 7), ('philosophy', 3), ('gibbs', 1), ('unsold', 3), ('mike', 1), ('hussey', 1), ('lara', 1), ('singles', 3), ('chart', 2), ('quality', 4), ('claire', 3), ('havin', 3), ('borin', 2), ('2nite', 6), ('09099725823', 1), ('callså£1', 4), ('minmoremobsemspobox45po139wa', 2), ('poorly', 1), ('punishment', 1), ('face', 28), ('worst', 2), ('brb', 1), ('kill', 1), ('mah', 8), ('interested', 7), ('ahhhh', 1), ('woken', 2), ('dream', 6), ('tho', 14), ('comedy', 3), ('knock', 2), ('whose', 1), ('80082', 3), ('enter', 8), ('å£250', 11), ('choice', 4), ('tkls', 1), ('stoptxtstopå£1', 1), ('reserve', 1), ('eve', 11), ('thirunelvali', 1), ('tirunelvali', 2), ('through', 10), ('tackle', 1), ('0776xxxxxxx', 2), (\"u've\", 4), ('final', 10), ('contact', 47), ('cha', 4), ('quiteamuzing', 1), ('thatåõscool', 1), ('hen', 1), ('tickets', 9), ('sale', 7), ('during', 7), ('10am', 5), ('8pm', 1), ('thurs', 5), (\"they're\", 7), ('selling', 2), ('fast', 9), ('printer', 1), ('groovy', 1), ('groovying', 1), ('practising', 1), ('curtsey', 1), ('thatåõs', 4), ('gota', 1), ('leave', 42), ('responce', 1), ('happend', 2), ('ha', 14), ('nan', 3), ('yalrigu', 1), ('heltini', 1), ('iyo', 1), ('kothi', 2), ('shared', 1), ('uttered', 1), ('trusting', 1), ('plz', 17), ('those', 21), ('letter', 3), ('sing', 4), ('hu', 1), ('find', 56), ('female', 3), ('preferably', 1), ('smart', 1), ('navigate', 1), ('choosing', 1), ('require', 1), ('guidance', 1), ('doubt', 2), (\"finn's\", 1), ('moving', 2), ('flat', 4), ('arrange', 5), ('lamp', 1), ('caroline', 2), ('cps', 1), ('causing', 2), ('outages', 1), ('conserve', 1), ('energy', 5), ('kilos', 1), ('white', 3), ('fudge', 1), ('oreos', 1), ('stores', 2), ('2day', 8), ('6pm', 3), ('walmart', 3), ('id', 15), ('james', 3), ('farting', 1), ('drive', 16), ('chit', 1), ('logon', 1), ('8883', 1), ('cm', 1), ('4217', 1), ('london', 4), ('w1a', 1), ('6zf', 1), ('118p', 1), ('derek', 3), ('taylor', 2), ('mouse', 1), ('desk', 1), ('vodafone', 2), ('0089', 1), ('four', 3), ('digits', 1), ('received', 3), ('å£350', 7), ('matches', 5), ('09063442151', 1), ('step', 4), ('foward', 1), ('fall', 4), ('ruin', 2), ('icic', 1), ('lect', 8), ('mths', 3), ('video', 28), ('phones', 6), ('mins', 36), ('necesity', 1), ('imagine', 5), ('urself', 8), ('witout', 1), (\"hw'd\", 1), ('colleg', 1), (\"wat'll\", 1), ('wth', 1), ('functions', 1), ('thnk', 3), ('events', 1), (\"espe'll\", 1), ('cared', 2), ('irritated', 1), ('4wrd', 1), ('loving', 15), ('frnds', 10), ('wthout', 1), ('whom', 3), ('takecare', 1), ('sayy', 1), ('okay', 17), ('drop', 12), ('cards', 1), ('12', 7), ('wun', 7), ('impressed', 1), ('funs', 1), ('secretly', 1), ('fancies', 1), ('09065394514', 1), ('datebox1282essexcm61xn', 1), ('rays', 2), ('leaves', 4), ('blue', 7), ('bay', 1), ('mrng', 6), ('diet', 2), ('flew', 1), ('window', 2), ('asked', 21), ('anna', 1), ('nagar', 1), ('afternoon', 19), ('starshine', 1), (\"how's\", 17), ('ache', 4), ('sips', 1), ('cappuccino', 1), ('teasing', 5), ('imma', 7), ('cause', 14), ('sary', 2), ('tim', 1), ('bollox', 1), ('hurt', 19), ('tol', 1), ('somethin', 4), (\"did't\", 5), ('clarification', 1), ('j', 5), ('centre', 2), ('damn', 5), ('mp3', 7), ('doesnt', 6), ('catching', 3), ('2u2', 1), ('wuld', 1), ('mite', 4), ('donåõt', 4), ('crazy', 10), ('everyboy', 1), ('needs', 15), ('lady', 5), ('xxxxxxxx', 1), ('ofcourse', 1), ('upload', 2), ('songs', 3), ('brum', 1), ('putting', 5), ('keeping', 4), ('boye', 3), ('guide', 5), ('torrents', 1), ('particularly', 1), ('slowing', 1), ('started', 18), ('honey', 7), ('moon', 4), ('apologetic', 1), ('fallen', 1), ('actin', 1), ('spoilt', 1), ('caught', 3), (\"won't\", 15), ('badly', 1), ('bec', 2), ('temple', 1), ('aiyo', 6), ('weåõve', 1), ('2geva', 2), ('mint', 1), ('xxxx', 2), ('hype', 1), ('plaza', 2), ('700', 2), ('studio', 1), ('bedrm', 1), ('900', 2), ('role', 4), ('giving', 5), ('miracle', 3), ('looked', 4), ('young', 1), ('sunshine', 4), ('dawns', 1), ('refreshed', 1), ('alive', 3), ('breathe', 2), ('air', 5), ('howda', 1), ('mathe', 1), ('en', 2), ('samachara', 1), ('torch', 7), ('bold', 6), ('together', 12), ('mmm', 4), ('roast', 3), ('iåõd', 1), ('drinks', 3), ('collecting', 3), ('configure', 1), ('settings', 2), ('perpetual', 1), ('dd', 1), ('chasing', 2), ('750', 13), ('anytime', 13), ('half', 30), ('rental', 9), ('delivery', 15), ('attend', 3), ('rounds', 1), ('arrested', 3), ('possession', 2), ('talking', 12), ('pix', 5), ('birthday', 22), ('payasam', 1), ('rinu', 1), ('brings', 5), ('mine', 12), ('prob', 12), ('email', 9), ('noe', 17), ('4d', 2), ('closes', 1), ('7ish', 2), ('wont', 24), ('sitting', 7), ('package', 3), ('term', 3), ('54', 1), ('resubmit', 1), ('expiry', 1), ('themob', 5), ('info', 10), ('horse', 1), ('racing', 2), ('earlier', 13), ('ate', 4), ('chicken', 3), ('rice', 1), ('cardiff', 3), ('uni', 5), ('lighters', 1), ('don\\x89û÷t', 5), ('receipts\\x89ûówell', 1), ('what\\x89û÷s', 1), ('consider', 2), ('walls', 3), ('bunkers', 1), ('peaceful', 2), ('enough', 23), ('matter', 6), ('lemme', 6), ('basically', 4), ('unique', 4), ('1172', 1), ('removal', 1), ('87239', 3), ('08708034412', 1), ('pride', 1), (\"shouldn't\", 4), ('kid', 1), ('supposed', 8), ('grownup', 1), ('future', 6), ('planned', 5), ('result', 3), ('present', 7), ('whats', 13), ('bonus', 17), ('caller', 13), ('09058095201', 1), ('burger', 3), ('move', 8), ('killing', 2), ('wrong', 9), ('answer', 13), ('assume', 3), ('mobs', 1), ('2u', 2), ('rply', 6), ('title', 1), ('breathe1', 1), ('titles', 1), ('crazyin', 1), ('sleepingwith', 1), ('finest', 1), ('ymca', 1), ('pobox365o4w45wq', 1), ('300p', 1), ('amy', 2), ('ure', 3), ('intelligent', 4), ('woman', 5), ('walked', 2), ('moms', 3), ('stagwood', 1), ('winterstone', 1), ('victors', 1), ('hill', 4), ('ages', 4), ('abj', 2), ('likely', 3), ('mittelschmertz', 1), ('google', 4), ('paracetamol', 1), ('issues', 3), ('california', 2), ('manageable', 1), ('wats', 6), ('cedar', 1), ('key', 3), ('likes', 3), ('dislikes', 3), ('lou', 2), ('lancaster', 1), ('bak', 6), ('neway', 1), ('couldnåõt', 1), ('båõday', 2), ('å£150', 4), ('worth', 11), ('discount', 6), ('85023', 3), ('savamob', 5), ('member', 4), ('offers', 6), ('08717898035', 1), ('å£3', 10), ('00', 5), ('sen', 3), ('cbe', 4), ('believe', 17), ('taunton', 3), ('tacos', 2), ('mentor', 1), ('percent', 1), ('sonathaya', 1), ('soladha', 1), ('srs', 1), ('mail', 23), ('planning', 7), ('crucial', 1), ('sometimes', 7), ('makes', 16), (\"someone's\", 1), ('noon', 5), ('hand', 7), ('sabarish', 1), ('persons', 2), ('heard', 9), ('warner', 3), ('83118', 1), ('colin', 1), ('farrell', 1), ('swat', 1), ('wkend', 4), ('med', 1), ('popcorn', 2), ('kiosk', 2), ('sony', 6), ('mre', 1), ('painting', 2), ('jackson', 1), ('rec', 2), ('center', 3), ('group', 4), ('coveragd', 1), ('urgnt', 3), ('vasai', 1), (\"4'o\", 1), ('broth', 1), ('ramen', 1), ('unless', 8), ('currently', 8), ('500', 12), ('maximize', 3), ('cc', 3), ('114', 2), ('14', 2), ('tcr', 2), ('w1', 3), ('holding', 4), ('tightly', 1), ('library', 8), ('sindu', 1), ('birla', 2), ('soft', 2), ('shell', 1), ('unconsciously', 1), ('avoiding', 2), ('unhappy', 1), ('å£2', 12), ('08712103738', 1), ('letters', 3), ('i\\x89ûªm', 1), ('expecting', 4), ('isn\\x89ûªt', 1), ('thinked', 1), ('class', 35), ('doin', 10), ('swan', 1), ('usf', 9), ('rimac', 1), ('pray', 7), ('inshah', 1), ('08719839835', 1), ('mgs', 1), ('89123', 1), ('weirdo', 1), ('msn', 2), ('hotmail', 1), ('enjoyed', 3), ('burial', 1), ('mojibiola', 2), ('ashwini', 1), ('avoid', 2), ('age', 12), ('gender', 2), ('begin', 3), ('24m', 1), ('yep', 8), ('jontin', 1), ('02', 8), ('06', 7), ('03', 12), ('2nd', 22), ('09066362220', 1), ('asap', 10), ('box97n7qp', 3), ('supports', 1), ('ass', 10), ('srt', 1), ('ps3', 1), ('usb', 2), ('1000', 2), ('txts', 7), ('tariffs', 4), ('motorola', 7), ('sonyericsson', 3), ('bluetooth', 5), ('mobileupd8', 9), ('call2optout', 6), ('hf8', 1), ('oops', 7), ('eight', 3), ('station', 5), ('prestige', 1), ('imin', 1), ('dontmatter', 1), ('urgoin', 1), ('outl8r', 1), ('formatting', 1), ('punish', 1), ('eta', 2), ('30', 12), ('okday', 1), ('brah', 2), ('exams', 5), ('checkmate', 1), ('chess', 1), ('persian', 1), ('phrase', 1), ('shah', 1), ('maat', 1), ('king', 7), ('boo', 3), ('prepare', 4), ('pleasured', 1), ('videos', 1), ('shsex', 1), ('netun', 1), ('fgkslpopw', 1), ('fgkslpo', 1), ('kidding', 2), ('papa', 1), ('appendix', 1), ('range', 2), ('impossible', 2), ('chill', 2), ('tons', 2), ('coins', 4), ('thru', 3), ('paypal', 1), ('voila', 1), ('pockets', 1), ('infra', 1), ('slow', 9), ('omw', 6), ('castor', 2), ('created', 3), ('btwn', 1), ('sum1', 2), ('vry', 3), ('gaps', 1), ('hands', 3), ('legs', 3), ('door', 7), ('funeral', 1), ('audrey', 1), ('0796xxxxxx', 1), ('prizeawaiting', 1), ('olave', 1), ('mandara', 1), ('kano', 5), ('trishul', 1), ('contacts', 2), ('purple', 1), ('realy', 6), ('pink', 2), ('lyk', 1), ('green', 5), ('yelow', 1), ('wnt', 3), ('bck', 2), ('black', 4), ('brown', 1), ('nw', 4), ('giv', 3), ('color', 2), ('slept', 6), ('yest', 7), ('wake', 20), ('surly', 1), ('review', 3), ('masters', 4), ('bb', 7), ('belongs', 1), ('family', 14), ('fated', 1), ('shoranur', 1), ('incident', 2), ('fuelled', 1), ('concern', 1), ('prior', 1), ('grief', 1), ('chain', 3), ('violence', 2), ('women', 2), ('board', 1), ('issue', 3), ('overheating', 1), ('reslove', 1), ('inst', 1), ('pending', 3), (\"8'o\", 1), ('laughing', 3), ('winning', 2), ('tooo', 1), (\"'simple'\", 1), ('nte', 1), ('dang', 1), ('o', 10), ('cheaper', 5), ('telling', 14), ('hoped', 2), ('regretted', 1), ('vava', 3), ('playing', 3), ('umma', 7), ('shame', 4), ('cld', 2), ('boltblue', 1), ('mono', 3), ('poly3', 1), ('slide', 2), ('jamz', 1), ('toxic', 1), ('scold', 2), ('mandy', 1), ('sullivan', 1), ('hotmix', 1), ('fm', 1), ('chosen', 2), ('easter', 2), ('09041940223', 1), ('29', 3), ('05', 5), ('transferred', 1), (\"wat's\", 4), ('real1', 1), ('pushbutton', 1), ('dontcha', 1), ('babygoodbye', 1), ('golddigger', 1), ('webeburnin', 1), ('reaching', 6), ('stops', 2), ('smoke', 15), ('shitstorm', 1), ('attributed', 1), ('game', 14), ('rs', 10), ('necessary', 2), ('secret', 8), ('recognise', 2), ('thesis', 2), ('skip', 3), ('front', 2), ('pull', 2), ('funny', 6), ('distance', 2), ('wishing', 7), ('moji', 4), ('speechless', 2), ('easily', 1), ('lengths', 1), ('behalf', 1), ('stunning', 1), ('meh', 8), ('chase', 1), ('crossing', 1), (\"anybody's\", 1), ('tactful', 1), ('lead', 5), ('lightly', 1), ('custom', 2), ('checkboxes', 1), ('69669', 2), ('polyphonic', 4), ('ringtones', 9), ('normal', 9), ('gprs', 1), ('leo', 1), ('mall', 3), ('515', 1), ('billion', 2), ('classes', 1), ('sparkling', 1), ('breaks', 1), ('45', 1), ('0121', 1), ('2025050', 1), ('visit', 10), ('shortbreaks', 1), ('org', 1), ('kappa', 2), ('orchard', 8), ('univ', 1), ('placement', 2), ('dileep', 1), ('muchand', 1), ('support', 9), ('remember', 24), ('venugopal', 1), ('mentioned', 1), ('goodnight', 6), ('fix', 3), ('lions', 2), ('lionm', 2), ('lionp', 2), ('original', 4), ('3gbp', 3), ('openings', 1), (\"'til\", 3), ('thanksgiving', 3), ('upcharge', 1), ('yalru', 1), ('lyfu', 2), ('astne', 1), ('innu', 1), ('mundhe', 1), ('lyf', 2), ('ali', 2), ('halla', 1), ('ke', 1), ('bilo', 1), ('marriage', 4), ('program', 2), ('edhae', 1), ('ovr', 1), ('vargu', 1), ('meow', 2), ('question', 14), ('oi', 2), ('ami', 1), ('parchi', 1), ('kicchu', 1), ('kaaj', 1), ('korte', 1), ('iccha', 1), ('korche', 1), ('ta', 5), ('tul', 1), ('hangin', 1), ('makin', 2), ('pobox84', 4), ('m263uz', 2), ('print', 2), ('marandratha', 1), ('teju', 1), ('9ja', 2), ('ilol', 1), ('personally', 1), ('wuldnt', 1), ('haiyoh', 1), ('hamster', 2), ('million', 1), ('hotel', 6), ('invitation', 1), ('apologise', 3), ('cali', 1), ('english', 4), (\"bloke's\", 1), ('weddin', 1), ('callin', 3), ('sozi', 1), ('culdnt', 1), ('talkbut', 1), ('wannatell', 1), ('wenwecan', 1), ('properly', 2), ('dudette', 1), ('confirmed', 3), ('oni', 4), ('neshanth', 1), ('1pm', 1), ('valued', 6), ('pleased', 4), ('advise', 2), ('recent', 2), ('å£1500', 2), ('09066368470', 1), ('allo', 1), ('braved', 1), ('buses', 2), ('trains', 2), ('triumphed', 1), ('we\\x89û÷re', 3), ('b\\x89û÷ham', 1), ('jolly', 1), ('sort', 9), ('natwest', 1), ('ammae', 1), ('turns', 6), ('sit', 2), ('steering', 1), ('flavour', 1), ('regret', 3), ('disturbance', 1), ('dlf', 1), ('premarica', 1), ('kindly', 3), ('rgds', 2), ('kerala', 4), ('change', 17), ('field', 2), ('quickly', 3), ('administrator', 2), ('case', 10), ('lodge', 1), (\"joy's\", 4), ('ths', 1), ('iq', 2), ('tis', 3), ('ias', 1), ('velusamy', 1), (\"sir's\", 1), ('birth', 3), ('facilities', 1), ('otside', 1), ('tht', 6), ('absolutly', 1), ('appreciate', 7), ('sacrifice', 2), ('process', 4), ('convenience', 1), (\"mine's\", 1), ('lookin', 6), ('totes', 1), ('mmmm', 2), ('lick', 3), ('diff', 3), ('fuckin', 3), ('boy', 20), ('melody', 1), ('heehee', 1), ('chic', 1), ('common', 4), ('declare', 1), ('aftr', 5), ('hoping', 6), ('licks', 2), ('tootsie', 1), ('pop', 2), ('gep', 1), ('march', 10), ('cashbin', 2), ('biggest', 2), ('tried', 17), ('å£750', 1), ('pound', 5), ('087187272008', 1), ('now1', 1), ('defer', 1), ('admission', 1), ('til', 17), ('lido', 2), ('530', 4), ('okey', 3), ('dokey', 2), ('swashbuckling', 1), ('optin', 1), ('bbc', 1), ('charts', 1), ('size', 2), ('elephant', 1), ('shove', 1), ('um', 1), ('solve', 2), ('police', 3), ('questioned', 1), ('cook', 2), ('cooking', 2), ('gardener', 1), ('vegetables', 1), ('children', 5), ('neighbour', 1), ('brilliant', 2), ('buffy', 1), ('satisfy', 2), ('randy', 2), ('qlynnbv', 1), ('help08700621170150p', 1), ('waited', 2), ('huiming', 1), ('num', 5), ('lk', 2), ('tt', 3), ('cine', 6), ('yogasana', 4), ('photos', 4), ('useful', 2), ('bitch', 3), ('09071517866', 1), ('150ppmpobox10183bhamb64xe', 1), ('dreams', 14), ('stars', 2), ('musical', 1), ('effects', 2), ('gorgeous', 4), ('brighten', 1), ('kb', 6), ('lessons', 9), ('lodging', 1), ('grandmas', 1), ('hungover', 1), ('excuses', 2), ('beauty', 2), ('pimples', 2), ('smsing', 1), ('along', 4), ('inside', 5), ('spageddies', 1), ('win150ppmx3age16', 1), ('official', 4), ('flag', 5), ('yer', 2), ('84199', 2), ('eng', 3), ('box39822', 2), ('w111wx', 2), ('alrite', 5), ('jod', 1), ('revision', 2), ('keris', 1), ('smidgin', 1), ('15pm', 1), ('seriously', 2), ('exact', 2), ('edison', 1), ('rightly', 1), ('fool', 2), ('wise', 2), ('viva', 1), ('gm', 1), ('chuckin', 1), ('trainners', 1), ('save', 7), ('carryin', 1), ('bac', 1), ('hr', 6), ('b4', 11), ('upping', 1), ('grams', 1), ('soooo', 1), ('omg', 7), ('provider', 1), ('tming', 1), ('gas', 13), ('block', 1), ('armenia', 1), ('swann', 1), ('howard', 2), ('ron', 3), ('burgundy', 1), ('captaining', 1), ('boat', 2), ('claims', 1), ('09050005321', 1), ('dismay', 1), ('whenever', 8), ('wearing', 3), ('shorts', 1), ('webadres', 1), ('geting', 1), ('salary', 4), ('slip', 2), ('3g', 4), ('videophones', 2), ('09061744553', 1), ('videochat', 2), ('java', 2), ('dload', 2), ('polyh', 1), ('noline', 2), ('rentl', 2), ('bx420', 2), ('ip4', 3), ('5we', 3), ('150pm', 3), ('lift', 4), ('sight', 2), ('remain', 2), ('maintain', 1), ('cr', 1), ('entertain', 1), ('sending', 9), ('practical', 2), ('june', 3), ('funk', 1), ('tones2u', 1), ('cousin', 1), ('hg', 5), ('5p', 3), ('alfie', 3), (\"moon's\", 3), ('song', 9), ('m8s', 3), ('charity', 9), ('nokias', 3), ('08701417012', 3), ('profit', 4), ('asking', 9), ('slippers', 3), ('payback', 1), ('kvb', 1), ('449050000301', 1), ('09050000301', 1), ('rude', 2), ('read', 12), ('answered', 2), ('linerental', 2), ('lf56', 1), ('admirer', 5), ('reveal', 6), ('thinks', 9), ('09058094565', 2), ('fish', 2), ('memory', 1), (\"something's\", 1), ('silent', 3), ('mode', 6), ('nowhere', 1), ('ikno', 1), ('doesdiscount', 1), ('shitinnit', 1), ('ge', 3), ('jokin', 2), (\"roommate's\", 2), ('stock', 3), ('bout', 13), ('truth', 9), ('heart', 26), ('itåõs', 2), ('deserve', 1), ('tight', 2), ('asthma', 1), ('attack', 1), ('u4', 1), ('knickers', 1), ('beg', 2), ('01223585236', 1), ('nikiyu4', 1), ('action', 3), ('80608', 2), (\"t's\", 6), ('movietrivia', 2), ('08712405022', 2), ('1x150p', 4), ('sun', 16), ('oooh', 2), ('plenty', 5), (\"idea's\", 1), ('anyplaces', 1), ('ow', 2), ('dey', 5), ('paid', 7), ('60', 1), ('400thousad', 1), ('evaluation', 1), ('07734396839', 1), ('ibh', 1), ('nokia6600', 1), ('lifting', 1), ('argue', 2), ('treats', 1), ('remind', 5), ('obviously', 4), ('eggs', 3), ('pert', 1), ('head\\x89û', 1), ('infact', 1), ('seeing', 7), ('contacted', 3), ('dating', 10), ('09050000878', 1), ('pobox45w2tg150p', 2), ('bought', 4), ('ovulate', 1), ('3wks', 1), ('fret', 2), ('past', 6), ('history', 2), ('poking', 1), ('everyday', 2), ('canada', 2), ('fees', 3), ('mising', 1), ('2morro', 2), ('passion', 1), ('09099726481', 1), ('dena', 1), ('minmobsmorelkpobox177hp51fl', 3), ('picked', 4), ('09061743386', 1), ('swhrt', 1), ('raining', 6), ('cheat', 1), ('fatty', 1), ('understanding', 2), ('trying', 32), ('lag', 2), ('skype', 4), ('business', 3), ('guessing', 2), ('flaked', 2), ('jb', 1), ('clearly', 2), ('fault', 6), ('ten', 9), ('noncomittal', 1), ('rstm', 1), ('sw7', 1), ('3ss', 1), ('agree', 2), ('ipad', 2), ('macho', 2), ('slp', 1), ('muah', 1), ('items', 2), ('7cfca1a', 1), ('amk', 1), ('coffee', 6), ('tear', 4), ('falls', 2), ('bslvyl', 6), ('swimming', 2), ('pool', 2), ('jacuzzi', 1), ('picture', 3), ('violated', 2), ('mm', 8), ('write', 7), ('worc', 1), ('foregate', 1), ('shrub', 1), ('morphine', 2), ('07753741225', 1), ('08715203677', 1), ('42478', 1), ('objection', 1), ('captain', 2), ('vijaykanth', 1), ('drunken', 1), ('langport', 2), ('darren', 11), ('def', 3), (\"'maangalyam\", 1), ('alaipayuthe', 1), ('appt', 4), ('listen', 13), ('twice', 4), ('ad', 4), ('crap', 1), ('boggy', 1), ('biatch', 1), ('ave', 4), ('adult', 4), ('experience', 3), ('danger', 1), ('peeps', 1), ('comment', 1), ('searching', 3), (\"l'm\", 1), ('goodnoon', 2), ('hvae', 1), ('å£900', 4), ('09061701444', 1), ('acl03530150pm', 1), ('marvel', 1), ('ultimate', 1), ('spider', 2), ('å£4', 3), ('83338', 1), ('8ball', 1), ('wallpaper', 3), ('boyfriend', 2), ('si', 2), (\"friend's\", 1), ('practicing', 2), ('babies', 1), ('hmph', 1), ('baller', 1), ('serving', 2), ('konw', 1), ('waht', 1), ('rael', 1), ('gving', 1), ('yuo', 2), ('exmpel', 1), ('jsut', 1), ('ese', 1), ('tihs', 2), ('evrey', 1), ('splleing', 1), ('wrnog', 1), ('sitll', 1), ('raed', 1), ('wihtuot', 1), ('ayn', 1), ('mitsake', 1), ('dedicated', 1), ('dedicate', 1), ('valuable', 2), ('satanic', 1), ('imposter', 1), ('destiny', 1), ('aunt', 2), ('nike', 1), ('petey', 1), ('noiåõm', 1), ('avent', 3), ('nit', 2), ('js', 1), ('cocksuckers', 1), ('ipads', 1), ('worthless', 1), ('garbage', 2), ('novelty', 1), ('wanting', 4), ('holby', 1), ('4qf2', 1), ('hillsborough', 1), ('bishan', 2), ('lavender', 1), ('shuhui', 7), ('suntec', 3), ('steamboat', 1), ('restrict', 1), ('eating', 6), ('anythin', 2), ('hppnss', 1), ('sorrow', 1), ('wil', 11), ('forevr', 2), ('goodfriend', 1), ('whatever', 13), ('rules', 1), ('showing', 2), ('responsibility', 1), ('bend', 1), ('rule', 3), ('thia', 1), ('argument', 3), ('inlude', 1), ('previews', 1), ('profile', 1), ('bpo', 1), ('posh', 1), ('birds', 3), ('chaps', 1), ('trial', 1), ('prods', 1), ('champneys', 1), ('dob', 1), ('jamster', 2), ('88888', 2), ('08701213186', 1), ('returns', 1), ('lingo', 1), ('forwarded', 6), ('448712404000', 1), ('08712404000', 1), ('telugu', 2), ('nyt', 7), ('ducking', 1), ('chinchillas', 1), ('tamilnadu', 1), ('tough', 6), ('five', 5), ('08002888812', 2), ('yahoo', 7), ('boys', 6), ('perf', 1), ('qet', 1), ('07801543489', 1), ('latests', 1), ('40gb', 5), ('83355', 5), ('llc', 1), ('ny', 1), ('usa', 1), ('mt', 3), ('msgrcvd18', 1), ('gent', 2), ('weekends', 6), ('09064012160', 2), ('k52', 3), ('shaking', 1), ('booty', 2), ('dance', 1), ('floor', 2), ('onum', 1), ('ela', 1), ('taste', 1), ('filthy', 2), ('stories', 1), (\"table's\", 1), ('occupied', 1), ('tree', 2), ('tap', 2), ('spile', 2), ('broad', 2), ('canal', 2), ('shirt', 3), ('lose', 10), ('bcoz', 7), ('gr8prizes', 2), ('wkly', 8), ('8800', 1), ('psp', 1), ('80878', 2), ('08715705022', 3), ('manual', 1), ('tech', 2), ('reset', 1), ('troubleshooting', 1), ('å£400', 4), ('proze', 1), ('norcorp', 1), ('mtmsgrcvd18', 4), ('misbehaved', 1), ('slap', 2), ('hooch', 1), ('toaday', 1), ('fell', 2), ('splat', 1), ('grazed', 1), ('knees', 1), ('stayed', 2), ('auction', 14), ('7250i', 2), ('86021', 4), ('w1jhl', 2), ('uv', 1), ('causes', 1), ('mutations', 1), ('sunscreen', 1), ('thesedays', 1), ('930', 1), ('gam', 1), ('outstanding', 2), ('innings', 3), ('vill', 1), ('hop', 5), ('parco', 2), ('nb', 2), ('1030', 2), ('orc', 1), ('hip', 2), ('midnight', 7), ('barely', 4), ('sane', 1), ('fighting', 3), ('constantly', 3), ('helping', 1), ('08712101358', 1), ('joke', 5), ('seekers', 1), ('kallis', 5), ('dismissial', 1), ('non', 1), ('looks', 5), ('ic', 3), ('lotta', 2), ('childporn', 1), ('diddy', 1), ('neighbor', 1), ('toothpaste', 1), ('erutupalam', 1), ('thandiyachu', 1), ('staff', 3), ('amrita', 1), ('accidant', 1), ('tookplace', 1), ('ghodbandar', 1), ('slovely', 1), ('timi', 1), ('clearing', 2), ('completely', 4), ('em', 8), ('round', 5), ('frens', 6), ('greetings', 3), ('joy', 2), ('anthony', 2), ('dessert', 1), ('21870000', 2), ('mailbox', 2), ('messaging', 2), ('09056242159', 2), ('retrieve', 2), ('u\\x89ûªve', 1), ('å£50', 2), ('instant', 1), ('08715203028', 1), ('9th', 1), ('wins', 3), ('optout', 3), ('08718727870', 3), ('ideal', 1), ('path', 1), ('appear', 1), ('paths', 1), ('walking', 4), ('owns', 1), ('property', 2), ('passionate', 4), ('predicte', 1), ('bloody', 4), ('hell', 6), ('surname', 1), ('clue', 1), ('spanish', 2), ('begins', 1), ('evry', 2), ('emotion', 1), (\"dsn't\", 3), ('prayrs', 1), ('othrwise', 1), ('slaaaaave', 1), ('summon', 1), ('anymore', 7), ('woul', 1), ('curfew', 1), ('gibe', 1), ('getsleep', 1), ('studdying', 1), ('ear', 2), ('1mega', 1), ('pixels', 1), ('3optical', 1), ('5digital', 1), ('dooms', 1), ('journey', 4), (\"what's\", 18), ('feathery', 1), ('bowa', 1), ('88800', 1), ('89034', 1), ('premium', 2), ('08718711108', 1), ('printed', 1), ('upstairs', 1), ('auntie', 1), ('huai', 1), ('peach', 1), ('tasts', 1), ('shanghai', 1), ('21st', 1), ('cya', 1), ('networking', 3), ('hme', 1), ('09061790121', 2), ('oga', 1), ('bread', 2), ('level', 1), ('series', 4), ('record', 3), ('sends', 2), ('basic', 4), ('pilates', 5), ('intro', 4), ('competition', 4), ('buzy', 1), ('lesson', 14), ('sth', 1), ('specs', 1), ('membership', 2), ('px3748', 1), ('china', 2), ('asia', 1), ('expensive', 6), ('greatest', 1), ('courage', 1), ('bear', 1), ('defeat', 1), ('losing', 3), ('gn', 2), ('guilty', 2), ('tonights', 1), ('tmrw', 2), ('doors', 3), ('12mths', 1), ('400mins', 1), ('j5q', 1), ('146tf150p', 1), (\"'need'\", 1), (\"'comfort'\", 1), (\"'luxury'\", 1), ('sold', 1), ('onion', 2), ('beer', 4), (\"g's\", 1), ('scrounge', 2), ('ammo', 1), ('ak', 1), (\"wouldn't\", 2), ('judgemental', 1), ('fridays', 1), ('flying', 1), ('monkeys', 1), ('certainly', 1), ('gimme', 3), ('lip', 2), ('caveboy', 1), ('08707500020', 1), ('films', 3), ('theres', 2), ('infront', 2), ('spirit', 1), ('commercial', 2), ('hasbro', 1), ('august', 3), ('jump', 1), ('hoops', 1), ('stress', 3), ('dorm', 2), ('08714712379', 1), ('local', 3), ('strt', 1), ('netcollex', 4), ('ltdhelpdesk', 1), ('02085076972', 1), ('happens', 5), ('vegas', 2), ('stays', 2), ('knackered', 3), ('lark', 1), ('i\\x89û÷m', 2), ('joking', 4), ('fancy', 11), ('lives', 3), ('wah', 2), ('wan2', 1), ('greet', 3), ('westlife', 1), ('m8', 1), ('tour', 4), ('unbreakable', 1), ('untamed', 1), ('unkempt', 1), ('83049', 1), ('å£75', 1), ('homeowners', 1), ('previously', 1), ('refused', 2), ('0800', 9), ('1956669', 1), (\"'help'\", 2), ('december', 4), ('vco', 1), ('08002986906', 3), ('sea', 11), ('view', 1), ('gays', 1), ('bell', 3), ('law', 6), ('balloon', 1), ('uncountable', 1), ('noun', 2), ('dictionary', 2), ('research', 4), ('walsall', 1), ('tue', 1), ('terry', 1), ('engalnd', 1), ('telly', 2), ('mia', 1), ('elliot', 1), ('kissing', 1), ('student', 2), ('books', 3), ('breaking', 1), ('cstore', 1), ('textpod', 2), ('84128', 3), ('08712405020', 3), ('depressed', 2), ('sittin', 1), ('wind', 1), ('drops', 1), ('scary', 3), ('pouch', 2), ('0721072', 1), ('curious', 2), ('battery', 6), ('esplanade', 3), ('childish', 2), ('rp176781', 1), ('further', 2), ('regalportfolio', 1), ('08717205546', 1), ('shocking', 1), ('crash', 2), ('taxi', 2), ('short', 5), ('sundayish', 1), ('neft', 1), ('transaction', 2), ('credited', 3), ('beneficiary', 1), ('6times', 1), ('cts', 1), ('employee', 1), ('gives', 5), ('reasons', 4), ('annie', 1), ('buns', 3), ('adore', 3), ('loverboy', 6), ('meatballs', 1), ('free2day', 1), (\"george's\", 1), ('jordan', 3), ('89080', 1), ('saucy', 2), ('celeb', 2), ('pocketbabe', 2), ('0870241182716', 1), ('whore', 1), ('unbelievable', 1), ('noice', 1), ('tease', 2), ('prey', 2), ('devouring', 1), ('lie', 3), ('epi', 1), ('5k', 1), ('09064011000', 1), ('cr01327bt', 1), ('fixedline', 1), ('flirt', 6), ('sam', 3), ('recd', 3), ('thirtyeight', 1), ('pence', 2), ('usually', 4), ('progress', 1), ('continue', 2), ('arestaurant', 1), ('squid', 1), ('dosomething', 1), ('select', 2), ('o2', 3), ('added', 4), ('benefits', 2), ('trained', 1), ('advisors', 1), ('dialling', 1), ('402', 1), ('popped', 1), ('loo', 1), ('ed', 1), ('lil', 2), ('sport', 6), ('coincidence', 1), ('hmv', 3), ('genuine', 1), ('100percent', 1), ('fran', 3), ('2mrw', 5), ('janx', 1), ('dads', 1), ('bigger', 3), ('die', 7), ('q', 4), ('tomarrow', 2), ('court', 1), ('stand', 7), ('gets', 8), ('dumb', 1), ('realize', 2), ('åè10', 1), ('evey', 1), ('mnth', 3), ('goodnite', 2), ('gailxx', 1), ('chloe', 1), ('smashed', 1), ('visionsms', 2), ('yunny', 2), ('bothering', 1), ('trust', 7), ('answers', 4), ('raping', 1), ('dudes', 1), ('poker', 1), ('stressfull', 1), ('surely', 4), ('adds', 1), ('cudnt', 1), ('drove', 1), ('ctla', 1), ('cochin', 2), ('ente', 1), ('ishtamayoo', 1), ('bakrid', 1), ('file', 3), (\"'ll\", 3), ('drivby', 1), ('0quit', 1), ('edrunk', 1), ('iff', 1), ('pthis', 1), ('senrd', 1), ('dnot', 1), ('dancce', 1), ('drum', 1), ('basq', 1), ('ihave', 1), ('2nhite', 1), ('ros', 1), ('xxxxxxx', 1), ('smoked', 1), ('oic', 2), ('settle', 2), ('compliments', 1), ('pours', 1), ('bday', 3), ('april', 5), ('played', 3), ('smash', 1), ('religiously', 1), ('ahead', 5), ('watts', 1), ('runs', 2), ('blame', 2), ('diesel', 1), ('expressoffer', 2), ('brainy', 1), ('miles', 3), ('smiles', 4), ('difference', 2), ('keeps', 2), ('wrkin', 1), ('mmmmm', 1), ('loved', 10), ('reckon', 2), ('transport', 2), ('hlday', 1), ('mo', 7), ('camp', 1), ('amrca', 1), ('serena', 1), ('browsin', 1), ('compulsory', 1), ('astrology', 1), ('malaria', 3), ('worse', 4), ('gastroenteritis', 1), ('replace', 1), ('loss', 3), ('temp', 2), ('reduce', 1), ('meds', 3), ('vomit', 4), ('self', 4), ('limiting', 1), ('illness', 1), ('prospects', 2), ('bleak', 1), ('filled', 1), ('mylife', 1), ('rt', 1), ('pro', 1), ('ringtoneking', 2), ('08701237397', 1), ('redeemable', 1), ('luckily', 1), ('starring', 1), ('middle', 3), ('merry', 6), ('kisses', 3), ('embarassed', 4), ('delete', 1), ('tag', 1), ('messy', 2), ('wednesday', 6), ('throw', 2), ('laundry', 1), ('underwear', 1), ('bras', 1), ('strewn', 1), ('pillows', 1), ('wedding', 3), ('lingerie', 1), ('bridal', 1), ('petticoatdreams', 1), ('superb', 2), ('selection', 4), ('brought', 4), ('weddingfriend', 1), (\"valentine's\", 1), ('paris', 4), ('inc', 6), ('69101', 1), ('rtf', 1), ('sphosting', 1), ('dentist', 1), (\"hasn't\", 2), ('gently', 2), ('60p', 4), ('connect', 1), ('09094646899', 1), (\"uk's\", 4), ('vu', 1), ('bcm1896wc1n3xx', 1), ('mapquest', 1), ('dogwood', 1), ('pretty', 9), ('dull', 1), ('2bold', 1), ('hrishi', 2), ('worrying', 1), ('quizzes', 1), ('cookies', 2), ('jelly', 1), ('screwd', 1), ('xxxmobilemovieclub', 2), ('click', 6), ('qjkgighjjgcbl', 1), ('gloucesterroad', 1), ('uup', 1), ('marry', 4), ('named', 2), ('dub', 1), ('je', 1), ('buff', 2), ('bot', 1), ('notes', 1), ('rem', 4), ('massive', 2), ('rather', 7), ('involved', 1), ('foreign', 3), ('stamps', 3), ('2004', 6), ('07742676969', 1), ('786', 3), ('unredeemed', 3), ('08719180248', 1), ('45239', 2), ('bomb', 1), ('skye', 1), ('yor', 2), ('tank', 2), ('stressed', 1), ('simpsons', 1), ('2007', 2), ('band', 1), ('died', 3), ('storming', 1), ('phne', 1), ('wt', 1), ('margaret', 1), ('girlfrnd', 1), ('grahmbell', 1), ('invnted', 1), ('telphone', 1), ('moral', 3), ('4get', 1), ('butt', 3), ('wasnt', 1), ('phoned', 2), ('jason', 3), ('wither', 1), ('23f', 1), ('gay', 7), ('23g', 1), ('appy', 1), ('fizz', 1), ('contains', 1), ('boston', 2), ('location', 2), ('nyc', 2), ('signin', 1), (\"1's\", 1), ('inever', 1), ('exciting', 2), ('barred', 1), ('twat', 1), ('dungerees', 1), ('decking', 1), ('punch', 1), (\"1000's\", 2), ('virgins', 1), ('4fil', 2), ('sexual', 1), ('theirs', 1), ('69911', 1), ('werethe', 1), ('monkeespeople', 1), ('monkeyaround', 1), ('howdy', 1), ('schedule', 4), ('swimsuit', 1), ('allowed', 2), ('perhaps', 2), ('identification', 1), ('dare', 3), ('timin', 1), ('total', 4), ('disappointment', 1), ('texted', 3), ('craziest', 2), ('gang', 3), ('grand', 4), ('nature', 3), ('adventure', 2), (\"party's\", 1), ('contribute', 1), ('greatly', 1), ('appreciated', 2), ('citylink', 1), ('faster', 3), ('obedient', 1), ('queen', 4), ('broken', 2), ('note', 1), ('exposed', 1), ('vomiting', 1), ('sian', 1), ('subpoly', 2), ('81618', 2), ('printing', 1), ('handing', 1), ('hm', 2), ('headache', 3), ('dust', 1), ('flies', 2), ('tog', 3), ('mth', 1), ('kit', 1), ('strip', 1), ('1013', 1), ('ig11', 1), ('oja', 1), ('initiate', 1), ('dependents', 1), ('mornin', 1), ('thanku', 1), ('yoyyooo', 1), ('permissions', 1), ('mac', 1), ('earn', 2), ('09066362231', 3), ('07xxxxxxxxx', 3), ('fyi', 5), ('sporadically', 1), ('starting', 8), ('bc', 2), ('miwa', 1), ('jiayin', 2), ('karaoke', 2), ('fair', 3), ('weaknesses', 1), ('pushes', 2), (\"knee's\", 1), ('exposes', 1), ('pulls', 1), ('wicked', 1), ('chapel', 1), ('frontierville', 1), ('renewal', 2), ('bowls', 1), ('adventuring', 1), ('pages', 3), ('geeeee', 2), ('eh', 8), ('watched', 1), ('inconsiderate', 2), ('nag', 2), ('recession', 2), ('hence', 2), ('askin', 5), (\"month's\", 3), ('prin', 1), ('bits', 1), ('sighs', 4), ('timings', 1), ('xuhui', 2), ('8am', 2), ('09066368753', 1), ('97n7qp', 1), ('squishy', 1), ('mwahs', 1), ('stopped', 3), ('cream', 2), ('voice', 7), ('ahmad', 5), ('unconvinced', 1), ('elaborate', 1), ('willpower', 1), ('badrith', 1), ('nasty', 2), ('filthyguys', 1), ('slo', 2), ('4msgs', 1), ('09095350301', 1), ('erotic', 1), ('ecstacy', 1), ('08712460324', 7), ('nat', 3), ('lakhs', 1), ('fridge', 1), ('0870737910216yrs', 1), ('playng', 1), ('intrude', 1), ('feb', 4), (\"u'll\", 6), ('married', 4), ('ignore', 3), ('evr', 1), ('adewale', 1), ('aka', 2), ('egbon', 1), ('disappeared', 1), ('447801259231', 1), ('09058094597', 1), ('hdd', 1), ('casing', 1), ('xavier', 2), ('blood', 6), ('apologize', 1), ('admit', 1), ('excellent', 6), (\"riley's\", 1), ('faith', 1), ('three', 2), ('respect', 4), ('mother', 5), ('mails', 2), ('misundrstud', 1), ('tiime', 1), ('tears', 1), ('wee', 2), ('disagreeable', 1), ('desparate', 2), ('learned', 1), ('fake', 2), ('gravity', 2), ('carefully', 2), ('feels', 6), ('reality', 3), ('fantasy', 3), ('eldest', 1), ('inches', 3), ('hire', 1), ('hitman', 1), ('speaking', 2), ('arm', 1), ('weak', 4), ('shot', 3), ('stuffs', 1), ('handset', 5), ('networks', 2), ('accidentally', 2), ('andre', 1), (\"virgil's\", 1), ('subscribed', 3), ('83435', 1), ('helpline', 2), ('08706091795', 2), ('spending', 2), ('spoiled', 2), ('remembrs', 1), ('forgets', 1), ('everytime', 1), ('jsco', 2), ('2channel', 1), ('leadership', 1), ('skills', 1), ('psychic', 1), ('spun', 1), ('spk', 3), ('wrld', 1), ('teams', 1), ('chechi', 1), ('phony', 1), ('3100', 1), ('serious', 4), ('proper', 1), ('tongued', 1), ('wrks', 1), ('aint', 3), ('swell', 1), ('cashto', 2), ('08000407165', 2), ('getstop', 2), ('88222', 2), ('php', 2), ('ball', 1), ('spin', 1), ('bat', 3), ('market', 2), ('bmw', 1), ('urgently', 1), ('hv', 2), ('shortage', 1), ('lacs', 2), ('source', 1), ('arng', 1), ('amt', 1), ('canteen', 1), ('sweetie', 2), ('across', 7), ('howz', 4), ('textcomp', 3), ('cust', 2), ('panther', 1), ('sugababes', 1), ('zebra', 1), ('animation', 1), ('badass', 1), ('hoody', 1), ('armand', 3), ('epsilon', 2), ('repairs', 1), ('tests', 3), ('ovulation', 2), ('followin', 1), ('9pm', 3), ('sucks', 7), ('go2sri', 1), ('lanka', 1), ('edge', 2), ('bridgwater', 1), ('banter', 1), ('arrived', 1), ('terms', 4), ('sac', 2), ('carry', 3), ('celebrations', 1), ('toledo', 1), ('accept', 4), ('messaged', 2), ('bringing', 2), ('tscs08714740323', 1), ('1winawk', 1), ('50perweeksub', 1), ('08715203685', 1), ('4xx26', 1), ('13', 1), ('quiet', 1), ('beth', 1), ('aunts', 1), ('charlie', 1), ('torture', 1), ('superior', 1), ('department', 2), ('ours', 1), ('waheed', 1), ('fathima', 2), ('conform', 1), ('improved', 1), ('sex', 9), ('dogging', 6), ('hearts', 1), ('cares', 2), ('closer', 4), ('077xxx', 1), ('09066362206', 1), ('lotr', 3), ('å£600', 1), ('complete', 4), ('landmark', 1), ('bob', 1), ('barry', 1), ('ben', 2), ('83738', 1), ('tyler', 5), ('literally', 1), ('dubsack', 2), ('batch', 2), ('nowadays', 1), ('notixiquating', 1), ('laxinorficated', 1), ('opportunity', 4), ('bambling', 1), ('entropication', 1), ('oblisingately', 1), ('opted', 1), ('masteriastering', 1), ('amplikater', 1), ('fidalfication', 1), ('champlaxigating', 1), ('atrocious', 1), ('wotz', 1), ('opinion', 4), ('junna', 1), ('fifteen', 4), ('08712402972', 1), ('gal', 6), ('propsd', 1), ('gv', 1), ('lv', 1), ('lttrs', 1), ('threw', 1), ('thm', 2), ('aproach', 1), ('dt', 1), ('truck', 1), ('speeding', 1), ('wn', 1), ('ran', 1), (\"'hw\", 1), ('boost', 2), ('instantly', 1), ('shouted', 1), ('thy', 1), ('lived', 1), ('happily', 1), ('2gthr', 1), ('drinking', 2), ('evrydy', 1), ('gain', 2), ('demand', 2), ('husband', 2), ('ingredients', 1), ('longer', 6), ('crowd', 1), ('lined', 1), ('mostly', 1), ('creepy', 2), ('directly', 6), ('inform', 2), ('application', 2), ('airtel', 2), ('broadband', 1), ('successfully', 1), ('installation', 1), ('within', 7), ('hint', 3), ('forum', 1), ('list', 5), ('buyers', 1), ('lunchtime', 1), ('organise', 1), ('bbd', 2), ('pooja', 1), ('sweatter', 1), ('ninish', 1), ('icky', 1), ('american', 3), ('freek', 1), ('jen', 1), ('caring', 3), ('losers', 1), ('x2', 1), ('folks', 1), ('community', 2), ('joys', 1), ('lifeis', 1), ('daywith', 1), ('thoughts', 2), ('somewheresomeone', 1), ('tosend', 1), ('greeting', 1), ('posting', 1), ('spare', 2), ('supplies', 1), ('wahala', 1), ('kills', 1), ('recieve', 1), ('24hrs', 2), ('conditions', 1), ('channel', 2), ('teletext', 1), ('pg', 4), ('iron', 1), ('hopeing', 1), ('wasn\\x89û÷t', 1), ('pissed', 4), ('sisters', 1), ('missionary', 1), ('doggy', 3), ('standing', 2), ('laid', 3), ('locations', 2), ('largest', 2), ('gravel', 1), ('69888', 1), ('ec2a', 2), ('31p', 2), ('synced', 1), ('shangela', 1), ('stuck', 3), ('guessed', 1), ('gram', 3), ('nelson', 1), (\"bb's\", 1), ('comin', 9), ('aww', 2), ('neighbors', 1), ('yuou', 1), (\"mom's\", 4), ('spot', 1), ('starts', 6), ('disconnected', 1), ('bruce', 2), ('fowler', 1), ('08715203694', 1), ('40533', 2), ('31', 3), ('image', 1), ('quit', 3), ('gudnite', 2), ('practice', 3), ('otherwise', 4), ('pizza', 7), (\"tyler's\", 1), ('minor', 2), ('crisis', 2), ('sooner', 4), (\"blake's\", 3), ('occurs', 1), ('av', 2), ('minus', 1), ('paragraphs', 1), ('performed', 1), ('priest', 1), ('strips', 1), ('postal', 1), ('okies', 1), ('blah', 3), ('borderline', 1), ('status', 2), ('frequently', 1), ('needa', 1), ('mcat', 2), ('rayan', 1), ('macleran', 1), ('satsgettin', 1), ('47per', 1), ('thangam', 4), ('specific', 2), ('crab', 3), ('shore', 1), ('waves', 2), ('cleared', 2), ('footprints', 3), ('fox', 1), ('frndsship', 1), ('dwn', 1), ('roger', 4), ('cl', 1), ('125gift', 2), ('scenery', 1), ('impressively', 1), ('sensible', 1), ('shock', 2), ('leona', 3), ('reaction', 1), ('waaaat', 1), ('lololo', 1), ('thankyou', 1), ('star', 1), ('09066364349', 1), ('box434sk38wp150ppm18', 1), ('forgiven', 1), ('rose', 5), ('poet', 1), ('imagination', 1), ('frndship', 2), ('mad', 3), ('works', 4), ('buzz', 4), ('talents', 1), ('requests', 3), ('1stchoice', 1), ('08707808226', 1), ('gobi', 1), ('arts', 2), ('tms', 2), ('widelive', 2), ('index', 2), ('wml', 2), ('820554ad0a1705572711', 1), ('trueåác', 1), ('ringtoneåá', 1), ('missy', 1), ('w4', 1), ('5wq', 1), ('norm', 3), ('maga', 2), ('09061213237', 2), ('177', 2), ('m227xy', 2), ('adsense', 1), ('approved', 1), ('resizing', 1), ('nights', 4), ('flights', 4), ('å£79', 1), ('08704439680ts', 1), (\"hi'\", 1), ('fring', 1), ('ktv', 1), ('outta', 4), ('elvis', 1), ('presleys', 1), ('url', 3), ('wondering', 8), ('stoners', 1), ('mas', 1), ('advance', 5), ('toot', 2), ('theory', 2), ('loses', 1), ('kick', 3), ('setting', 2), ('filling', 1), ('shouting', 1), ('sized', 1), ('records', 5), ('indicate', 2), ('3750', 1), ('accident', 3), ('09066364589', 1), ('fetch', 5), ('west', 2), ('palm', 1), ('jazz', 4), ('wondarfull', 1), ('wating', 1), ('08000776320', 2), ('wewa', 1), ('130', 1), ('iriver', 1), ('255', 1), ('128', 1), ('under', 4), ('lays', 1), ('envelope', 2), ('alian', 1), ('fixes', 1), ('spelling', 1), ('figure', 9), (\"station's\", 1), ('08715205273', 1), ('poo', 1), ('09066612661', 3), ('luxury', 2), ('canary', 2), ('islands', 3), ('20m12aq', 1), ('\\x89ûï', 1), ('doc', 2), ('hubby', 2), ('fiting', 1), ('load', 1), ('mj', 1), ('lifted', 1), ('hopes', 1), ('approaches', 1), ('technical', 2), ('flip', 2), ('945', 1), ('darling', 3), ('christmassy', 1), ('specialisation', 1), ('labor', 1), ('shakara', 1), ('beggar', 1), ('contract', 4), ('mnths', 2), ('callback', 2), ('science', 3), ('nus', 2), ('edu', 2), ('sg', 1), ('phyhcmk', 1), ('teaching', 1), ('pc1323', 1), ('height', 2), ('confidence', 3), ('aeronautics', 1), ('professors', 1), ('wer', 3), ('calld', 1), ('aeroplane', 1), ('plane', 3), ('ws', 1), ('students', 3), ('hurried', 1), ('tensed', 1), ('spoke', 3), ('strongly', 1), ('promises', 3), ('creativity', 1), ('stifled', 1), ('asleep', 4), ('soc', 1), ('jack', 1), ('helpful', 1), ('pretend', 1), ('hypotheticalhuagauahahuagahyuhagga', 1), ('wrk', 2), ('meetin', 4), ('wiv', 6), ('dabooks', 1), ('fuuuuck', 1), ('sleepin', 2), ('sup', 5), ('tirupur', 2), ('chk', 1), ('belovd', 2), ('ms', 1), ('dict', 1), ('monster', 1), ('arranging', 1), ('cartons', 1), ('shelves', 1), ('07815296484', 1), ('08718738001', 2), ('41782', 1), ('xclusive', 1), ('clubsaisai', 1), ('28', 4), ('soiree', 1), ('speciale', 1), ('zouk', 1), ('nichols', 2), ('roses', 1), ('ladies', 4), ('07946746291', 1), ('07880867867', 1), ('apps', 3), ('varaya', 1), ('elaya', 1), ('wall', 1), ('actual', 2), ('europe', 1), ('10th', 1), ('sept', 4), ('09050000555', 1), ('ba128nnfwfly150ppm', 1), ('helloooo', 1), ('welcomes', 1), ('version', 4), ('current', 3), ('leading', 1), ('bid', 7), ('151', 1), ('pause', 1), ('08718726270', 2), (\"god's\", 5), ('limit', 1), ('grace', 1), ('measure', 3), ('boundaries', 1), ('endless', 1), ('blessings', 2), ('inconvenient', 1), ('sipix', 2), ('09061221066', 2), ('fromm', 2), ('sweetheart', 2), ('sugar', 3), ('plum', 1), ('smacks', 1), ('fishrman', 1), ('sack', 1), ('ful', 3), ('stones', 2), ('strtd', 1), ('throwin', 1), ('in2', 3), ('atlast', 2), ('1stone', 1), ('diamonds', 2), (\"mrng''\", 1), ('machan', 3), ('screamed', 2), ('sleepwell', 1), ('avatar', 3), ('nigro', 1), ('furniture', 1), ('lock', 1), ('locks', 1), ('jenne', 1), ('showered', 1), (\"er'ything\", 1), ('brand', 5), ('09061209465', 1), ('suprman', 1), ('matrix3', 1), ('starwars3', 1), ('steve', 1), ('6230', 1), ('83383', 2), ('pobox114', 1), ('14tcr', 1), ('ams', 1), ('ultimately', 1), ('tor', 1), ('motive', 1), ('tui', 1), ('achieve', 1), ('korli', 1), ('talks', 2), ('ericsson', 2), ('british', 1), ('hotels', 1), ('02072069400', 1), ('bx', 1), ('526', 1), ('sw73ss', 1), ('blowing', 1), ('2waxsto', 2), ('medical', 5), (\"she'll\", 4), ('deliver', 5), ('major', 2), ('geeee', 3), ('cuddling', 2), ('yck', 2), ('sheffield', 1), ('tom', 3), ('opinions', 2), ('categories', 1), ('ethnicity', 1), ('census', 1), ('transcribing', 1), ('dai', 3), ('downloaded', 2), ('exe', 3), ('steyn', 1), ('wicket', 1), ('heading', 1), ('prediction', 1), ('mystery', 2), ('solved', 1), ('opened', 1), ('oclock', 1), ('bash', 1), ('jolt', 2), ('suzy', 2), ('low', 2), ('7250', 2), ('tex', 1), ('mecause', 1), ('werebored', 1), ('okden', 1), ('hunny', 2), ('uin', 1), ('soundåõs', 1), ('likeyour', 1), ('gr8fun', 1), ('updat', 1), ('countinlots', 1), ('loveme', 1), ('xxxxx', 2), ('fifty', 1), ('addie', 2), ('shitload', 1), ('uploaded', 1), ('drug', 4), ('cutest', 1), ('prometazine', 1), ('syrup', 1), ('5mls', 1), ('feed', 1), ('dual', 1), ('sim', 3), ('showr', 1), ('develop', 2), ('environment', 1), ('terrific', 1), ('les', 1), ('rudi', 1), ('snoring', 1), ('drunk', 2), ('ink', 1), ('necessarily', 2), ('headin', 1), ('sexychat', 1), ('chatting', 3), ('photoshop', 1), ('shut', 2), ('waqt', 1), ('se', 3), ('pehle', 1), ('naseeb', 1), ('zyada', 1), ('kisi', 1), ('ko', 1), ('kuch', 1), ('nahi', 2), ('milta', 1), ('zindgi', 2), ('wo', 2), ('jo', 2), ('hum', 1), ('sochte', 1), ('hai', 5), ('ham', 1), ('jeetey', 1), ('potential', 1), ('talent', 2), ('straight', 6), ('weather', 5), ('challenge', 1), ('08700621170150p', 2), ('hahaha', 1), ('brain', 1), ('faded', 1), ('glory', 1), ('ralphs', 1), ('owl', 1), ('payments', 1), ('fedex', 1), ('banneduk', 1), ('89555', 3), ('textoperator', 3), ('g696ga', 2), ('087104711148', 1), ('wesleys', 1), ('ooh', 1), ('4got', 1), ('dancing', 2), ('moseley', 1), ('weds', 1), ('table', 2), ('enjoying', 1), ('09065174042', 1), ('07821230901', 1), ('shiny', 1), ('warming', 1), ('constant', 2), ('09066364311', 1), ('regards', 2), ('jaklin', 1), ('idk', 2), ('miserable', 2), ('control', 2), ('gut', 1), ('wrenching', 1), ('cramps', 2), ('restock', 1), ('mandan', 1), ('dialogue', 1), ('reltnship', 1), (\"dealer's\", 1), ('impatient', 2), ('explicit', 2), ('secs', 2), ('02073162414', 2), ('costs', 4), ('sentence', 1), ('concentrate', 2), ('educational', 1), ('career', 2), ('farm', 2), ('settled', 3), ('tat', 3), ('costume', 1), ('jaykwon', 1), ('thuglyfe', 1), ('falconerf', 1), ('quarter', 1), ('ground', 3), ('amla', 1), ('durban', 2), ('vday', 1), ('parachute', 1), ('applausestore', 1), ('monthlysubscription', 1), ('max6', 1), ('csc', 1), ('web', 2), ('2stop', 2), ('entertaining', 1), ('hugh', 1), ('laurie', 1), ('stick', 2), ('indeed', 2), ('89545', 2), ('biz', 6), ('2optout', 3), ('087187262701', 2), ('50gbp', 2), ('mtmsg18', 2), ('wendy', 1), ('sometime', 3), ('regular', 2), ('checkup', 1), ('pap', 1), ('smear', 1), (\"cali's\", 1), ('complexities', 1), ('freely', 1), ('taxes', 1), ('outrageous', 1), (\"i'ma\", 1), ('maths', 1), ('chapter', 1), ('changing', 1), ('diapers', 1), ('owed', 1), ('ideas', 3), ('studyn', 1), ('specify', 1), ('domain', 1), ('nusstu', 1), ('wtf', 3), ('appointment', 2), ('plural', 1), ('nottingham', 1), ('63miles', 1), ('40mph', 1), ('receiving', 4), ('oral', 1), ('fave', 3), ('position', 2), ('pounded', 1), ('dentists', 1), ('melt', 2), ('sunlight', 2), ('80086', 2), ('txttowin', 2), ('rajitha', 1), ('raj', 1), ('ranju', 1), ('jacket', 2), ('hitter', 1), ('yavnt', 1), ('entrepreneurs', 1), ('2006', 1), ('fifa', 1), ('held', 2), ('shag', 1), ('sextextuk', 1), ('xxuk', 1), ('69876', 1), ('value', 2), ('realized', 2), ('absence', 1), ('interflora', 2), (\"åòit's\", 1), ('flowers', 1), ('505060', 1), ('hurting', 1), ('meaningful', 1), ('lines', 3), ('compromised', 1), ('awkward', 1), (\"shade's\", 1), ('blackberry', 4), ('buyer', 1), ('dehydrated', 1), ('september', 1), ('express', 2), ('seperated', 1), ('\\x8eö´\\x89ó', 1), ('\\x8bû¬ud', 1), ('effect', 2), ('aust', 1), ('bk', 1), ('apart', 2), ('outs', 1), ('sign', 3), ('pin', 3), ('pookie', 1), ('69855', 1), ('stopbcm', 1), ('sf', 1), ('fit', 2), ('biola', 1), (\"mum's\", 3), ('09063458130', 1), ('polyph', 1), ('dollar', 2), ('lacking', 1), ('particular', 1), (\"dramastorm's\", 1), ('applebees', 1), ('notice', 5), ('mirror', 1), ('youre', 1), ('turning', 2), ('freak', 3), ('09058097189', 1), ('revealed', 2), ('ls15hb', 1), ('santa', 4), ('09077818151', 1), ('calls1', 1), ('50ppm', 1), ('3mins', 3), ('30s', 1), ('santacalling', 1), ('88600', 3), ('087016248', 1), ('nervous', 2), ('flirting', 2), ('bloke', 2), ('sleeps', 1), ('significant', 1), ('scared', 4), ('dock', 1), ('rolled', 1), ('newscaster', 1), ('dabbles', 1), ('flute', 1), ('behind', 7), ('wheel', 1), ('thin', 1), ('arguments', 1), ('fed', 1), ('himso', 1), ('mobsi', 1), ('391784', 1), ('ibhltd', 3), ('ldnw15h', 3), ('purity', 1), ('reading', 7), ('evng', 3), ('musthu', 1), ('steam', 1), ('daytime', 1), ('busty', 1), ('09099726429', 1), ('janinexx', 1), ('ru', 4), ('rv', 1), ('hol', 2), ('havenåõt', 2), ('rvx', 1), (\"shit's\", 1), ('roommate', 2), ('veggie', 1), ('lover', 5), ('needing', 1), ('textand', 1), ('08002988890', 1), ('fifth', 1), ('woozles', 1), ('weasels', 1), ('exeter', 2), ('wkg', 2), ('sc', 1), ('specialise', 1), ('wad', 1), ('favour', 2), ('tension', 2), ('machi', 1), ('nri', 1), ('command', 1), ('chief', 1), ('royal', 2), ('purchase', 3), ('motivate', 1), ('darkness', 1), ('shining', 1), ('excuse', 4), ('birthdate', 2), ('certificate', 1), ('publish', 1), ('wishes', 4), ('cherthala', 1), ('bfore', 1), ('tmorow', 1), ('engaged', 1), ('dr', 2), ('unsubscribed', 1), ('babes', 5), ('hunks', 1), ('gotbabes', 1), ('subscriptions', 1), ('replying', 4), ('80488', 5), ('2005', 1), ('hhahhaahahah', 1), ('nig', 1), ('leonardo', 1), ('vitamin', 1), ('fo', 2), ('senor', 1), (\"everybody's\", 2), ('peace', 2), ('jesus', 2), ('blessed', 1), ('ikea', 2), ('spelled', 1), ('caps', 1), ('yelling', 1), ('among', 2), ('mess', 2), ('bullshit', 1), ('workin', 7), ('overtime', 1), ('nigpun', 1), ('fones', 1), ('wild', 1), ('stop2stop', 1), ('hep', 1), ('immunisation', 1), ('bookedthe', 1), ('hut', 1), (\"cann't\", 3), ('asa', 1), ('mouth', 1), ('2mro', 1), ('087018728737', 1), ('toppoly', 1), ('tune', 1), ('pole', 2), ('reg', 2), ('ciao', 1), ('audition', 2), ('gods', 1), ('theoretically', 1), ('kitty', 1), ('shaved', 1), ('natural', 1), ('whos', 3), ('eek', 2), ('singing', 2), ('542', 3), ('0578', 2), ('dollars', 3), ('signing', 1), ('somewhr', 1), ('perfect', 3), ('crushes', 1), ('billy', 1), ('concert', 3), ('09061743811', 1), ('abta', 2), ('tenerife', 5), ('326', 1), ('cw25wx', 3), ('favourite', 3), ('cooked', 2), ('salmon', 1), ('versus', 1), ('dom', 1), ('jabo', 1), ('08718726978', 1), ('30ish', 2), ('850', 1), ('toa', 2), ('payoh', 2), ('650', 1), ('piss', 2), ('realise', 2), ('backwards', 1), ('cheesy', 1), ('frosty', 1), ('snowman', 2), ('slob', 1), ('convincing', 2), ('wright', 1), ('fly', 2), ('08006344447', 1), ('format', 1), ('disc', 1), ('sumthin', 2), ('wonders', 1), ('7th', 1), ('6th', 1), ('5th', 1), ('personality', 1), ('3rd', 1), ('tlk', 1), ('slippery', 1), ('lucy', 2), ('meetins', 1), ('cumin', 1), ('09099726395', 1), ('nearly', 3), ('banned', 1), ('hostel', 5), ('fffff', 1), ('kadeem', 2), (\"xin's\", 1), ('empty', 6), ('slots', 1), ('euro2004', 1), ('kickoff', 1), ('results', 2), ('euro', 2), ('83222', 1), ('nannys', 1), ('display', 1), ('footie', 1), ('blow', 1), ('phil', 1), ('neville', 1), ('repeat', 1), ('sang', 1), (\"'uptown\", 1), (\"girl'\", 1), (\"80's\", 1), (\"derek's\", 1), ('watever', 1), ('relation', 2), ('built', 1), ('iz', 1), ('lonlines', 1), ('lotz', 1), ('memories', 1), ('cried', 1), ('yeh', 3), ('kane', 1), ('shud', 1), ('pete', 8), ('09090204448', 1), ('minded', 1), ('aå£1', 1), ('minapn', 1), ('ls278bb', 1), (\"ron's\", 1), ('swatch', 2), ('macs', 1), ('prepared', 2), ('bruv', 1), ('rcv', 2), ('svc', 1), ('69988', 1), ('lit', 1), ('fire', 1), ('l8r', 5), ('entirely', 1), ('understood', 3), ('i\\x89û÷ll', 3), ('amazing', 4), ('rearrange', 1), ('dormitory', 1), ('dirty', 4), ('astronomer', 1), ('starer', 1), ('election', 1), ('lies', 2), ('recount', 1), ('hitler', 1), ('eleven', 1), ('twelve', 2), ('subtoitles', 1), ('sculpture', 1), ('lovin', 1), ('activate', 4), ('treated', 2), ('tessy', 1), ('favor', 1), ('convey', 3), ('nimya', 2), ('shijas', 1), ('turn', 3), ('heater', 2), ('degrees', 1), ('ayo', 1), ('travelled', 1), ('wiskey', 1), ('brandy', 1), ('rum', 1), ('gin', 1), ('vodka', 2), ('scotch', 1), ('shampain', 1), ('kudi', 1), ('yarasu', 1), ('dhina', 1), ('vaazhthukkal', 1), ('whens', 1), ('sos', 1), ('attending', 1), ('ukp', 1), ('2000', 2), ('09061790125', 1), ('maps', 1), (\"audrey's\", 1), ('blank', 4), ('grl', 4), ('hogolo', 1), ('gold', 1), ('kodstini', 1), ('agalla', 2), ('necklace', 1), ('madstini', 1), ('hogli', 1), ('mutai', 1), ('eerulli', 1), ('kodthini', 1), ('polo', 2), ('suite', 2), ('373', 2), ('w1j', 2), ('6hl', 2), ('jos', 1), ('pubs', 1), ('frankie', 1), ('bennys', 1), ('cam', 3), ('wipro', 2), ('smoothly', 1), ('challenging', 1), ('5226', 1), ('hava', 1), ('1131', 1), ('stubborn', 1), ('sucker', 1), ('hospitals', 1), ('suckers', 1), ('attended', 1), ('spoil', 1), ('connections', 2), (\"yetty's\", 1), ('gopalettan', 1), ('participate', 1), ('admin', 2), ('ups', 1), ('3days', 1), ('shipping', 3), ('2wks', 2), ('usps', 1), ('bribe', 1), ('nipost', 1), ('3pound', 1), ('nearer', 1), ('jackpot', 1), ('81010', 1), ('dbuk', 1), ('lccltd', 1), ('4403ldnw1a7rw18', 1), ('das', 1), ('iknow', 1), ('wellda', 1), ('peril', 1), ('studentfinancial', 1), ('cheese', 2), ('inperialmusic', 1), ('listening2the', 1), ('weirdest', 2), ('byåóleafcutter', 1), ('johnåó', 1), ('insects', 1), ('molested', 1), ('plumbing', 1), ('remixed', 1), ('evil', 1), ('acid', 1), ('yeesh', 1), ('weirdy', 1), ('brownies', 1), ('someday', 1), ('text82228', 1), ('logos', 1), ('txt82228', 2), ('wifi', 2), ('blanked', 1), ('40', 2), ('cc100p', 1), ('hopefully', 3), ('dave', 3), ('5000', 3), ('09061743806', 2), ('tcs', 3), ('box326', 2), ('quote', 3), ('jerry', 1), ('cartoon', 1), ('irritates', 1), ('fails', 1), ('goin2bed', 1), ('only1more', 1), ('speed', 2), ('speedchat', 2), ('80155', 1), ('swap', 1), ('chatter', 1), ('chat80155', 1), ('pobox36504w45wq', 2), ('rcd', 1), ('someplace', 1), ('08718723815', 1), ('chillin', 1), ('09065171142', 2), ('stopsms', 2), ('08718727870150ppm', 1), ('positions', 1), ('kama', 1), ('sutra', 1), ('unmits', 1), ('tip', 1), ('hides', 1), ('thousands', 2), ('secrets', 1), ('n8', 1), ('vat', 1), ('supply', 2), ('cds', 4), ('subs16', 1), ('1win150ppmx3', 1), ('å£800', 4), ('09050001295', 1), ('a21', 1), ('bike', 1), ('rounder', 1), ('required', 1), ('mus', 1), ('owe', 1), ('smokes', 2), ('begging', 2), ('rocking', 1), ('ashes', 1), ('200', 2), ('08717895698', 1), ('mobstorequiz10ppm', 1), ('smith', 2), ('waste', 3), ('gayle', 1), (\"let's\", 3), ('07090201529', 1), ('restrictions', 1), ('1000s', 3), ('buddys', 1), ('bari', 1), ('hudgi', 1), ('yorge', 1), ('pataistha', 1), ('ertini', 1), ('slacking', 1), ('beach', 1), ('expected', 1), ('invention', 1), (\"wherre's\", 1), ('å£125', 1), ('freeentry', 1), ('xt', 1), ('ey', 2), ('calm', 1), ('downon', 1), ('theacusations', 1), ('itxt', 1), ('iwana', 1), ('wotu', 1), ('thew', 1), ('haventcn', 1), ('up4', 2), ('nething', 1), ('varunnathu', 1), ('edukkukayee', 1), ('raksha', 1), ('ollu', 1), ('pure', 1), ('hearted', 1), ('enemies', 1), ('enemy', 2), ('smiley', 1), ('ranjith', 2), ('drpd', 1), ('deeraj', 1), ('deepak', 1), ('5min', 2), ('bless', 2), ('downs', 1), ('fletcher', 1), ('xam', 1), ('hall', 1), ('manage', 2), ('hesitation', 1), ('intha', 1), ('ponnungale', 1), ('ipaditan', 1), ('wasted', 1), ('chiong', 1), ('docs', 3), ('burden', 1), ('delivered', 2), ('8000930705', 1), ('portege', 1), ('m100', 1), ('twinks', 1), ('bears', 2), ('scallies', 1), ('skins', 1), ('jocks', 1), (\"weekend's\", 1), ('08712466669', 1), ('staying', 7), ('port', 1), ('sitter', 1), ('kaitlyn', 1), (\"'wnevr\", 1), ('fal', 1), ('vth', 2), ('fals', 1), ('yen', 1), ('madodu', 1), ('nav', 1), ('pretsorginta', 1), ('nammanna', 1), ('pretsovru', 1), ('alwa', 1), ('eveb', 1), ('cud', 3), ('ppl', 4), ('l8', 1), ('gon', 1), ('messenger', 2), ('attraction', 1), ('breath', 1), ('cry', 4), ('sorrows', 1), ('proove', 1), ('praises', 1), ('curry', 1), ('makiing', 1), ('sambar', 1), ('okors', 1), ('cherish', 1), ('chickened', 1), ('woould', 1), ('crashing', 1), ('opening', 2), ('mca', 1), ('barring', 1), ('sudden', 1), ('influx', 1), ('eye', 1), ('sore', 3), ('bloomberg', 2), ('447797706009', 1), ('careers', 1), ('sinco', 1), ('payee', 1), ('icicibank', 1), ('urn', 2), ('beware', 1), ('frauds', 1), ('disclose', 1), ('drastic', 1), ('combine', 2), ('parts', 1), ('olowoyey', 1), ('usc', 3), ('argentina', 1), ('secretary', 2), ('blessing', 1), ('nigh', 1), ('andrews', 1), ('whatsup', 1), ('idc', 1), ('weaseling', 1), ('desparately', 1), ('tunji', 1), ('tm', 3), ('shortly', 4), ('engin', 2), ('tirunelvai', 1), ('spice', 1), ('atleast', 1), ('shakespeare', 1), ('tops', 1), ('consistently', 1), ('practicum', 1), ('links', 1), ('ears', 1), ('ttyl', 4), (\"gumby's\", 1), ('classmates', 1), ('ceri', 1), ('rebel', 1), ('dreamz', 1), ('buddy', 1), ('2moro', 3), ('blokes', 1), ('football', 2), ('sky', 4), ('gamestar', 1), ('active', 1), ('å£250k', 1), ('scoring', 1), ('88088', 1), ('headstart', 1), ('desperate', 2), ('rummer', 1), ('conference', 1), ('waheeda', 1), ('ummifying', 1), ('el', 1), ('nino', 1), ('himself', 1), ('harder', 1), ('nbme', 1), ('tattoos', 1), ('09064017295', 1), ('recorder', 1), ('canname', 1), ('capital', 2), ('australia', 1), ('mquiz', 1), ('kalainar', 1), ('thenampet', 1), ('related', 1), ('trade', 2), ('arul', 1), ('salon', 2), ('arr', 1), ('oscar', 1), ('reminder', 1), ('doit', 1), ('mymoby', 1), ('wesley', 1), (\"how've\", 1), ('reverse', 1), ('cheating', 1), ('mathematics', 1), ('rg21', 1), ('4jx', 1), ('27', 1), ('08714714011', 1), ('apo', 1), ('honesty', 1), ('decisions', 2), ('route', 1), ('throws', 1), ('brothers', 1), ('pandy', 1), ('mental', 2), ('windows', 1), ('logoff', 1), ('switch', 2), ('sweets', 2), ('irritating', 3), ('msging', 1), ('abeg', 1), ('sponsors', 1), ('event', 1), ('picsfree1', 2), ('vid', 2), ('keyword', 1), ('tmorrow', 1), ('accomodate', 1), ('seem', 3), ('ana', 1), ('sathy', 1), ('rto', 1), ('surfing', 2), ('ripped', 1), ('clubmoby', 1), ('08717509990', 1), ('six', 2), ('downloads', 3), ('friendships', 1), ('grow', 1), ('subscribers', 1), ('mary', 1), ('jane', 2), ('zhong', 1), ('qing', 1), ('act', 1), ('83370', 1), ('trivia', 1), (\"aren't\", 4), ('09061790126', 1), ('lifebook', 1), ('rejected', 1), ('kinda', 7), ('newest', 2), ('gossip', 3), ('funky', 2), ('82468', 2), ('moved', 2), ('worms', 1), ('09058094507', 1), ('goal', 2), ('arsenal', 3), ('henry', 2), ('liverpool', 2), ('scores', 2), ('yards', 1), ('bergkamp', 1), ('margin', 1), ('78', 1), ('fullonsms', 4), ('ortxt', 1), ('thgt', 2), (\"fren's\", 1), ('rang', 3), ('gentle', 5), ('unlike', 1), ('patients', 1), ('turkeys', 1), ('force', 2), ('iraq', 1), ('afghanistan', 1), ('stable', 1), ('honest', 1), ('traveling', 1), ('mel', 1), ('opps', 1), ('confused', 2), (\"tt's\", 1), ('a30', 1), ('divert', 1), ('via', 7), ('wadebridge', 1), ('professional', 1), ('tiger', 1), ('woods', 1), ('joanna', 1), ('cheetos', 1), ('clash', 1), ('successful', 1), ('stuffed', 1), ('pig', 2), ('bleh', 2), ('writhing', 1), ('recovery', 1), ('cooped', 1), ('expression', 2), ('sentiment', 1), ('rowdy', 1), ('attitude', 1), ('shy', 2), ('attractive', 1), ('lovable', 2), ('witin', 1), ('leads', 1), ('welp', 2), ('semiobscure', 1), ('subscription', 3), ('å£5', 1), ('08712402578', 1), ('flaky', 2), ('parent', 2), (\"it'snot\", 1), (\"child's\", 1), ('unintentional', 1), ('nonetheless', 1), ('emailed', 1), ('yifeng', 1), ('09050003091', 2), ('c52', 2), ('settling', 1), ('happenin', 1), ('ola', 2), ('eachother', 1), ('firmware', 1), ('thkin', 1), ('nd', 2), ('rush', 4), ('argh', 2), ('spotty', 1), ('province', 1), ('sterling', 1), ('places', 2), ('baaaaaaaabe', 1), ('probs', 2), ('costa', 3), ('del', 5), ('sol', 3), ('09050090044', 2), ('toclaim', 2), ('pobox334', 2), ('stockport', 2), ('sk38xh', 3), ('costå£1', 2), ('max10mins', 2), ('lindsay', 1), ('bars', 1), ('heron', 1), ('hottest', 1), ('accomodations', 1), ('cave', 1), ('offered', 1), ('embarassing', 1), ('08700469649', 1), ('box420', 1), ('69888nyt', 1), ('jeans', 2), ('t91', 1), ('gbp', 2), ('09057039994', 1), ('drama', 1), ('struggling', 1), ('strange', 2), ('ego', 1), (\"'if\", 1), (\"invited'\", 1), ('necessity', 1), ('reppurcussions', 1), ('vip', 4), ('pre', 2), ('81303', 1), ('trackmarque', 1), ('vipclub4u', 1), ('smoking', 2), ('1405', 1), ('1680', 1), ('1843', 1), ('innocent', 1), ('terror', 1), ('cruel', 1), ('decent', 1), ('joker', 1), ('stability', 1), ('tranquility', 1), ('vibrant', 1), ('colourful', 1), ('merely', 1), ('relationship', 1), ('wherevr', 1), ('gudnyt', 1), ('deepest', 1), ('darkest', 1), ('09094646631', 1), ('waliking', 1), ('cantdo', 1), ('anythingtomorrow', 1), ('myparents', 1), ('aretaking', 1), ('outfor', 1), ('katexxx', 1), ('absolutely', 1), ('recently', 6), ('paperwork', 2), ('knowing', 3), ('fired', 1), ('spjanuary', 1), ('male', 3), ('08709222922', 2), ('8p', 2), ('peak', 2), ('ou', 1), ('trash', 1), ('wavering', 1), ('coping', 2), ('individual', 2), ('heal', 1), ('build', 1), ('angels', 1), ('snowball', 1), ('fights', 2), ('youåõre', 1), (\"joke's\", 1), ('university', 1), ('florida', 1), ('kickboxing', 1), ('jp', 1), ('mofo', 1), ('dot', 1), ('pen', 1), ('biro', 1), (\"jay's\", 2), ('belligerent', 1), ('treasure', 1), ('useless', 1), ('converter', 1), ('prakesh', 1), ('galileo', 2), ('dobby', 1), ('09066660100', 1), ('2309', 1), ('lately', 2), ('cheyyamo', 1), ('officer', 1), ('guoyang', 1), ('ibored', 1), ('iam', 1), ('08', 2), ('0871', 3), ('4719', 1), ('523', 1), ('box95qu', 3), ('divorce', 2), ('unable', 4), ('07099833605', 1), ('ref', 4), ('9280114', 1), ('ouch', 1), ('risk', 1), ('alto18', 1), ('wave', 2), ('44345', 1), ('gate', 1), ('charles', 2), ('uh', 2), ('acknowledgement', 1), ('astoundingly', 1), ('tactless', 1), ('faggy', 2), ('oath', 1), ('smiled', 1), ('it\\x89û÷s', 3), ('å£6', 1), ('rajas', 1), ('burrito', 1), ('09058091870', 1), ('m26', 2), ('3uz', 2), ('loooooool', 1), ('couch', 1), ('rents', 1), ('nimbomsons', 1), ('selflessness', 1), ('hols', 1), ('hairdressers', 1), ('beforehand', 1), ('\\rham', 1), ('retard', 1), ('86888', 2), ('subscribe6gbp', 2), ('3hrs', 2), ('txtstop', 2), ('gamb', 1), ('urination', 1), ('clever', 1), ('guesses', 1), ('aiya', 3), ('attach', 1), ('breeze', 1), ('bright', 2), ('fresh', 1), ('flower', 2), ('twittering', 1), ('dusk', 1), ('puzzles', 1), ('justify', 1), ('ruining', 2), ('blu', 2), ('november', 1), ('09061104276', 1), ('smsco', 2), ('costå£3', 1), ('75max', 1), ('garage', 1), ('keys', 2), ('bookshelf', 1), ('crucify', 1), ('success', 1), ('decades', 1), ('goverment', 1), ('expects', 1), ('88877', 2), (\"basket's\", 1), ('gettin', 6), ('topic', 2), ('conacted', 1), ('09111030116', 1), ('pobox12n146tf15', 1), ('shant', 1), ('jia', 1), ('ba', 2), ('gua', 1), ('faber', 1), ('dress', 2), ('ooooooh', 1), ('yoville', 1), ('jap', 1), ('exp', 1), ('30apr', 1), ('sleepy', 2), ('kfc', 1), ('tuesday', 5), ('meals', 1), ('gravy', 1), ('dats', 1), ('dogg', 1), ('flurries', 1), ('born', 3), ('spaces', 1), ('embassy', 1), ('fetching', 1), ('spiritual', 1), ('deep', 5), ('str8', 1), ('classic', 1), ('200p', 1), ('aldrine', 1), ('rtm', 1), ('n9dx', 1), ('pickle', 1), ('crashed', 1), ('cuddled', 1), ('uses', 1), ('passable', 1), ('phd', 1), ('5years', 1), ('easier', 3), ('swoop', 1), ('tbs', 1), ('persolvo', 1), ('forå£38', 1), ('kath', 1), ('manchester', 1), ('ques', 2), ('suits', 2), ('auto', 3), ('gsoh', 1), ('spam', 1), ('gigolo', 1), ('fastest', 2), ('growing', 2), ('mens', 1), ('oncall', 1), ('mjzgroup', 1), ('08714342399', 1), ('50rcvd', 1), ('beverage', 1), ('pist', 1), ('kay', 1), ('dealer', 1), ('freedom', 1), ('lunsford', 1), (\"'an\", 1), (\"quote''\", 1), ('3230', 1), ('textbook', 1), ('algorithms', 1), ('edition', 1), ('09090900040', 1), ('extreme', 1), ('privacy', 2), ('sic', 1), ('listening', 2), ('7mp', 1), ('0870753331018', 1), ('lounge', 2), ('passes', 1), ('08704439680', 1), ('booking', 3), ('knocking', 1), ('keen', 1), ('pressies', 1), ('fren', 3), ('730', 1), ('chances', 1), ('csh11', 1), ('87575', 2), ('6days', 1), ('tsandcs', 1), ('hl', 3), ('lasagna', 1), ('mei', 1), ('haven', 1), ('bao', 1), ('sugardad', 1), (\"fuck's\", 1), ('sake', 2), ('tallahassee', 1), ('lanre', 1), (\"fakeye's\", 1), ('eckankar', 1), ('hooked', 1), (\"weather's\", 1), ('sliding', 1), ('invite', 3), ('every1', 1), ('ava', 1), ('goodtime', 1), ('oli', 1), ('melnite', 1), ('ifink', 1), ('sorted', 2), ('explain', 4), ('everythin', 1), ('l8rs', 1), ('idea', 2), ('converted', 1), ('walkabout', 1), ('building', 2), ('coat', 2), ('proof', 3), ('rupaul', 1), ('tool', 2), ('animal', 1), ('reminding', 1), ('adoring', 2), ('panic', 2), ('destination', 1), ('mumhas', 1), ('beendropping', 1), ('theplace', 1), ('adress', 1), ('unintentionally', 1), ('warning', 1), ('webpage', 1), ('base', 1), ('z', 1), ('gifts', 1), ('cliff', 1), ('å£1450', 2), ('09053750005', 1), ('310303', 1), ('08718725756', 1), ('140ppm', 1), ('unnecessarily', 1), ('affectionate', 1), ('excited', 1), ('partnership', 2), ('0871277810810', 1), (\"rct'\", 1), ('thnq', 1), ('adrian', 1), ('vatian', 1), ('brolly', 1), ('franxx', 1), ('k718', 1), ('09065069120', 1), ('ger', 1), ('toking', 1), ('syd', 1), ('ing', 1), ('arent', 2), ('cakes', 1), (\"that'd\", 1), ('scenario', 1), ('outsider', 1), ('rip', 1), ('uterus', 1), ('barbie', 1), (\"ken's\", 1), ('arngd', 1), ('walkin', 1), ('unfortuntly', 1), ('snake', 3), ('bites', 1), ('frnt', 1), ('sayin', 1), ('bite', 3), ('audiitions', 1), ('relocate', 1), ('ore', 1), ('owo', 1), ('wa', 1), ('fro', 1), ('slightly', 2), ('gurl', 1), ('appropriate', 1), ('placed', 1), ('rubber', 1), ('wud', 2), (\"week's\", 3), ('triple', 1), ('echo', 1), ('gentleman', 2), ('dignity', 2), ('squatting', 1), ('thread', 2), ('69698', 2), ('relaxing', 1), ('7am', 1), ('5ish', 1), ('map', 2), ('semi', 1), ('gmw', 1), ('connected', 1), ('studies', 1), ('anyones', 1), ('zoom', 1), ('half8th', 1), ('continued', 1), ('president', 1), ('8lb', 1), ('7oz', 1), ('brilliantly', 1), ('karnan', 1), ('thinl', 1), ('sachin', 2), ('lyrics', 1), (\"textin'\", 1), ('babyjontet', 1), ('aunty', 1), ('prominent', 1), ('cheek', 1), ('raglan', 1), ('edward', 1), ('cricket', 1), ('closeby', 1), ('costumes', 1), ('yowifes', 1), ('dealing', 2), ('denying', 1), ('you\\x89û÷ll', 1), ('andros', 2), ('steal', 1), ('shoes', 2), ('behave', 2), ('07008009200', 1), ('2morrow', 1), ('frying', 3), (\"x'mas\", 1), ('relatives', 2), ('risks', 1), ('anywhere', 2), ('hunting', 1), ('vomitin', 1), (\"world's\", 1), ('happiest', 1), ('characters', 1), ('differences', 1), ('some1', 3), ('luvs', 1), ('praying', 2), ('allday', 1), ('ploughing', 1), ('pile', 1), ('ironing', 1), ('chinky', 1), ('lord', 1), ('rings', 1), ('soundtrack', 1), ('stdtxtrate', 1), ('starve', 1), ('eighth', 2), ('l', 2), ('alternative', 1), (\"term's\", 1), ('3650', 1), ('09066382422', 1), ('300603', 1), ('bcm4284', 1), ('oz', 2), ('scrumptious', 1), ('genius', 2), ('15', 2), ('gokila', 1), ('600', 1), ('400', 1), ('deltomorrow', 1), ('100p', 1), ('hustle', 1), ('forth', 1), ('harlem', 1), ('continent', 1), ('indyarocks', 1), ('phonebook', 1), ('ps', 2), ('anal', 1), ('bang', 2), ('drunkard', 1), ('sarcastic', 2), ('645', 1), ('medicine', 3), ('meaningless', 1), ('wishin', 1), ('paragon', 1), ('responding', 1), ('lim', 1), ('equally', 1), ('uneventful', 1), ('pesky', 1), ('cyclists', 1), ('brison', 1), ('language', 2), ('members', 2), ('trips', 1), ('forwarding', 1), ('hearin', 1), ('didnåõt', 1), ('intend', 1), ('iwas', 1), ('marine', 1), ('itried2tell', 1), ('urmom', 1), ('careabout', 1), ('vivek', 1), ('kotees', 1), ('noooooooo', 1), ('trek', 1), ('endowed', 1), ('tscs', 2), ('idew', 1), ('skillgame', 2), ('1winaweek', 2), ('150ppermesssubscription', 2), ('lul', 1), ('juicy', 2), ('nurses', 1), ('shes', 1), ('obese', 1), ('oyea', 1), ('enufcredeit', 1), ('tocall', 1), ('ileave', 1), ('beside', 1), ('shoul', 1), ('ffffffffff', 1), ('outbid', 1), ('simonwatson5120', 1), ('shinco', 1), ('plyr', 1), ('smsrewards', 1), ('notifications', 1), ('bathroom', 1), ('papers', 2), ('w8in', 1), ('4utxt', 1), ('82242', 1), ('hlp', 1), ('08712317606', 1), ('msg150p', 1), ('2rcv', 1), ('byatch', 1), ('whassup', 1), ('convinced', 2), ('conversations', 1), ('senses', 1), ('overemphasise', 1), ('gotten', 2), ('pai', 1), ('seh', 1), ('09066358361', 1), ('y87', 1), ('tues', 2), ('digi', 1), ('fab', 1), ('coupla', 1), ('wks', 2), ('management', 3), ('62220cncl', 1), ('stopcs', 1), ('08717890890å£1', 1), ('complain', 1), ('bettr', 1), ('bsnl', 1), ('offc', 1), ('hont', 1), (\"dad's\", 1), ('sh', 1), ('kanji', 1), ('mentionned', 1), ('tiwary', 1), ('rcb', 1), ('battle', 1), ('kochi', 1), ('jez', 1), ('iscoming', 1), ('todo', 1), ('workand', 1), ('whilltake', 1), ('bottom', 2), ('gei', 1), ('tron', 1), ('dl', 1), ('3d', 3), ('09', 3), ('872', 2), ('9755', 1), ('compass', 1), ('soul', 1), ('gnun', 1), ('way2sms', 1), ('sunoco', 1), ('eaten', 2), ('staring', 1), ('consent', 1), ('forms', 1), ('lay', 1), ('bimbo', 1), (\"ugo's\", 1), ('fredericksburg', 1), ('meat', 1), ('lovers', 2), ('supreme', 1), ('complementary', 1), ('wa14', 1), ('2px', 1), ('sender', 2), ('iåõm', 4), ('inspection', 1), ('nursery', 1), ('sn', 2), ('didntgive', 1), ('bellearlier', 1), ('answerin', 1), ('reasonable', 1), ('matric', 1), ('mountain', 1), ('deer', 1), ('tb', 3), ('chgs', 1), ('unclaimed', 1), ('09066368327', 1), ('closingdate04', 1), ('claimcode', 1), ('m39m51', 1), ('50pmmorefrommobile2bremoved', 1), ('mobypobox734ls27yf', 1), ('muhommad', 1), ('penny', 1), ('laready', 1), ('attached', 2), ('valid12hrs', 2), ('fwiw', 1), ('afford', 1), ('reassuring', 1), ('computers', 1), ('appointments', 1), ('shoving', 1), ('dolls', 1), ('patrick', 1), ('swayze', 1), ('ryan', 1), ('allow', 1), ('sux', 1), ('raiden', 1), ('nitros', 2), ('0825', 1), ('vague', 1), ('accounting', 1), ('delayed', 1), ('discuss', 3), ('housing', 1), ('agency', 1), ('renting', 1), ('haircut', 1), ('breezy', 1), ('alle', 1), ('mone', 1), ('eppolum', 1), ('allalo', 1), ('sophas', 1), ('secondary', 1), ('schools', 2), ('applying', 1), ('ogunrinde', 1), ('kaila', 1), ('flow', 1), ('developed', 1), ('ovarian', 1), ('cysts', 1), ('shrink', 1), ('spiffing', 1), ('workage', 1), ('afternon', 1), ('interviews', 1), ('thnx', 1), (\"'hex'\", 1), ('aids', 1), ('patent', 1), ('african', 1), ('soil', 1), ('bids', 2), ('reliant', 1), ('breathing', 1), ('neck', 2), ('bud', 3), ('include', 2), ('japanese', 1), ('proverb', 1), ('strike', 1), ('09058094454', 1), ('accordin', 1), ('discussed', 2), ('parkin', 1), ('falling', 1), ('smeone', 1), ('velly', 1), ('heads', 1), ('sections', 1), ('clearer', 1), ('becz', 1), ('undrstndng', 1), ('avoids', 1), ('suffer', 1), ('ujhhhhhhh', 1), ('shipped', 1), ('sandiago', 1), ('parantella', 1), ('poop', 2), ('escape', 3), ('bridge', 1), ('lager', 1), ('fps', 1), ('affair', 2), ('weigh', 1), ('goldviking', 2), ('762', 2), ('workout', 1), ('fats', 1), ('tunde', 1), ('orh', 1), (\"how're\", 1), ('throwing', 1), ('deciding', 1), ('chik', 1), (\"100's\", 1), ('filth', 1), ('saristar', 1), ('e14', 1), ('9yt', 1), ('08701752560', 1), ('450p', 1), ('stop2', 1), ('villa', 1), ('82324', 1), ('darlings', 2), (\"ta's\", 1), (\"ìï'll\", 1), ('panren', 1), ('paru', 1), ('cozy', 1), ('rajini', 1), ('tiring', 1), ('modules', 2), ('concentrating', 1), ('earliest', 1), ('although', 1), ('baig', 1), ('watches', 1), ('touched', 2), ('noisy', 1), ('easiest', 1), ('barcelona', 1), ('prolly', 3), ('sq825', 1), ('arrival', 1), ('lux', 2), ('eh74rr', 1), ('typical', 1), ('heat', 1), ('applyed', 1), ('oil', 2), ('teacher', 3), ('nordstrom', 1), ('tape', 2), ('cross', 2), ('ntwk', 2), ('08001950382', 1), ('674', 1), ('randomlly', 1), ('mys', 1), ('fundamentals', 1), ('despite', 2), ('rushing', 1), ('forgive', 1), ('nok', 1), ('87021', 1), ('txtin', 2), ('4info', 2), ('excused', 1), ('prix', 1), ('hassling', 1), ('andres', 1), ('haughaighgtujhyguj', 1), ('bold2', 1), ('payment', 1), ('portal', 1), ('truly', 2), ('memorable', 1), ('boyf', 1), ('interviw', 1), ('batsman', 1), ('multis', 1), ('deus', 2), ('raji', 1), (\"that'll\", 2), ('nic', 1), ('checkin', 1), ('reunion', 1), ('creep', 1), ('mila', 1), ('age23', 1), ('blonde', 1), ('mtalk', 1), ('69866', 1), ('30pp', 1), ('5free', 1), ('increments', 1), ('help08718728876', 1), ('whr', 1), ('169', 1), ('6031', 1), ('stayin', 1), ('heåõs', 1), ('2getha', 1), ('flatter', 1), ('pints', 1), ('carlin', 1), ('topped', 1), ('bubbletext', 1), ('tgxxrz', 1), ('rgent', 1), ('å£1250', 1), ('09071512433', 1), ('050703', 1), ('csbcm4235wc1n3xx', 2), ('callcost', 1), ('mobilesvary', 1), ('maxå£7', 2), ('somerset', 1), ('matthew', 1), ('09063440451', 1), ('ppm150', 1), ('box334', 1), ('eightish', 1), ('carpark', 1), ('loxahatchee', 1), ('burning', 1), ('pleassssssseeeeee', 1), ('sportsx', 1), ('helens', 1), ('princes', 1), ('chad', 1), ('gymnastics', 1), ('site', 2), ('christians', 1), ('responsibilities', 1), ('intention', 1), ('visitors', 1), ('smsservices', 1), ('yourinclusive', 1), ('exorcism', 1), ('emily', 1), ('hugs', 2), ('snogs', 2), (\"'rencontre'\", 1), ('mountains', 1), ('symptoms', 1), ('beloved', 2), ('tooth', 1), ('or2optout', 1), ('hv9d', 1), ('2stoptx', 1), ('wasnåõt', 1), ('spouse', 1), ('pmt', 1), ('4give', 1), ('shldxxxx', 1), ('gsex', 1), ('2667', 1), ('wc1n', 1), ('3xx', 1), ('shrek', 1), ('secured', 1), ('unsecured', 1), ('195', 1), ('6669', 1), ('voicemail', 2), ('08719181513', 1), ('txtstar', 1), ('brisk', 1), ('walks', 1), ('89105', 1), ('obey', 1), ('bunch', 1), ('lotto', 1), ('dresser', 2), ('concerned', 1), (\"parents'\", 1), ('snowboarding', 1), ('befor', 1), ('pocy', 1), ('lambda', 1), ('wld', 2), ('nosh', 1), ('gong', 1), ('kaypoh', 1), ('name1', 1), ('name2', 1), ('mobno', 1), ('adam', 1), ('07123456789', 1), ('txtno', 1), ('ads', 1), ('dearer', 1), ('dem', 1), ('permission', 1), ('perform', 1), ('safely', 1), ('ubi', 3), ('67441233', 1), ('irene', 1), ('ere', 1), ('bus8', 1), ('22', 1), ('65', 1), ('61', 1), ('66', 1), ('382', 1), ('cres', 1), ('6ph', 1), ('5wkg', 1), ('ì¬n', 1), ('phone750', 1), ('everybody', 3), ('hypertension', 1), ('surrender', 1), ('como', 1), ('listened2the', 1), ('plaid', 1), ('air1', 1), ('hilarious', 1), ('boughtåóbraindanceåóa', 1), ('ofstuff', 1), ('aphexåõs', 1), ('abel', 1), ('coulda', 1), ('mesages', 1), ('apeshit', 1), ('meanwhile', 2), ('simulate', 1), ('readiness', 1), ('0906346330', 1), ('47', 1), ('po19', 1), ('2ez', 1), ('compensation', 1), ('predicting', 1), ('inch', 2), ('accumulation', 1), ('shola', 1), ('academic', 2), ('transfer', 3), ('sagamu', 1), ('lautech', 1), ('vital', 1), ('completes', 1), ('education', 1), ('zealand', 1), ('resend', 1), ('stalking', 1), ('becausethey', 1), ('09058098002', 1), ('pobox1', 1), ('w14rg', 1), ('packing', 1), ('ridden', 1), ('jd', 1), ('accounts', 1), ('executive', 2), ('footy', 1), ('stadium', 1), ('large', 1), ('coca', 1), ('cola', 1), ('respectful', 1), (\"partner's\", 1), ('method', 1), ('calculation', 2), ('chez', 1), ('jules', 1), ('rr', 1), ('dick', 3), ('hourish', 1), ('finalise', 1), ('several', 1), ('forgiveness', 1), ('r836', 1), ('09065069154', 1), ('thet', 1), ('skinny', 1), ('casting', 1), ('headset', 1), ('adp', 1), ('optimistic', 1), ('improve', 1), ('330', 1), ('1120', 1), ('1205', 1), ('various', 1), ('yeovil', 1), ('motor', 1), ('max', 1), ('cutie', 1), ('hills', 1), ('killed', 2), ('ystrday', 1), ('brownie', 1), ('rows', 1), ('sday', 1), ('everyso', 1), ('often', 3), ('panicks', 1), ('bein', 2), ('character', 1), ('covers', 1), ('ganesh', 1), ('abroad', 1), ('lonely', 2), ('xxsp', 1), ('stopcost', 1), ('08712400603', 1), ('math', 2), ('mcfly', 1), ('ab', 1), ('sara', 1), ('jorge', 1), ('instructions', 1), ('germany', 2), ('0844', 1), ('861', 1), ('85', 2), ('prepayment', 1), ('telediscount', 1), ('velachery', 1), ('smartcall', 1), ('68866', 1), ('subscriptn3gbp', 1), ('08448714184', 1), ('landlineonly', 1), ('09064019788', 1), ('box42wr29c', 1), ('mallika', 1), ('sherawat', 1), ('nange', 1), ('bakra', 1), ('kalstiya', 1), ('possibility', 1), ('2years', 1), ('strain', 1), ('dime', 2), ('warwick', 1), ('tmw', 1), ('canceled', 1), (\"havn't\", 1), ('jog', 1), ('consensus', 1), ('predict', 1), ('sweater', 1), ('mango', 1), ('elaborating', 1), ('safety', 1), ('aspects', 1), ('wetherspoons', 1), ('420', 1), ('virgin', 1), ('09061104283', 1), ('50pm', 1), ('approx', 1), ('pattern', 1), ('emerging', 1), ('fiend', 1), ('impede', 1), ('hesitant', 1), ('slower', 1), ('maniac', 1), ('sue', 2), ('lapdancer', 1), ('g2', 1), ('1da', 1), ('150ppmsg', 1), ('09058094583', 1), ('garden', 1), ('bulbs', 1), ('seeds', 1), ('å£33', 1), ('scotsman', 1), ('go2', 1), ('notxt', 1), ('teresa', 1), ('dec', 1), ('thot', 2), (\"you'ld\", 1), ('bam', 1), ('aid', 1), ('usmle', 1), ('hallaq', 1), ('owned', 1), ('possessive', 1), ('pract', 1), ('flung', 1), ('ambitious', 1), ('4mths', 2), ('mobilesdirect', 2), ('08000938767', 2), ('or2stoptxt', 2), ('rightio', 1), ('48', 1), ('wtlp', 1), ('housewives', 1), ('0871750', 1), ('77', 1), ('landlines', 1), ('stink', 1), ('kavalan', 1), ('guides', 1), ('snatch', 1), ('purse', 1), ('monkey', 1), ('asshole', 1), ('3lions', 1), ('suggest', 2), ('ors', 1), ('stool', 1), ('prasad', 1), ('98321561', 1), ('familiar', 1), ('electricity', 2), ('prasanth', 1), ('ettans', 1), ('passed', 2), ('youphone', 1), ('athome', 1), ('youwanna', 1), ('prof', 2), ('sem', 2), ('enna', 1), ('kalaachutaarama', 1), ('corvettes', 1), ('lov', 2), ('nevr', 1), ('unrecognized', 1), ('somone', 1), ('valuing', 1), ('definitly', 1), ('undrstnd', 1), ('transfered', 2), ('gained', 1), ('kg', 1), ('pressure', 1), ('limits', 1), ('onwords', 1), ('mtnl', 1), ('mumbai', 1), ('shoppin', 2), ('comprehensive', 1), ('relieved', 1), ('westonzoyland', 1), ('ffffuuuuuuu', 1), ('famous', 1), ('ability', 2), (\"'anything'\", 1), ('unconditionally', 1), ('temper', 1), (\"'married'\", 1), ('zac', 1), ('forced', 1), ('slice', 2), ('lolnice', 1), ('holy', 2), ('christ', 1), ('repent', 1), ('praveesh', 1), ('delicious', 1), ('dvg', 1), ('vinobanagar', 1), ('condition', 2), ('åòharry', 1), ('potter', 1), ('phoenix', 1), ('harry', 1), ('readers', 1), ('get4an18th', 1), ('nachos', 1), ('08715203652', 1), ('42810', 1), ('0', 2), ('minimum', 1), ('3miles', 1), ('cthen', 1), ('conclusion', 1), ('references', 1), ('cover', 4), ('wikipedia', 1), ('syria', 1), ('acted', 1), ('upon', 1), ('sooooo', 1), ('taka', 1), ('salesman', 1), ('puzzeles', 1), ('stalk', 1), ('profiles', 1), ('goodmate', 1), ('asusual', 1), ('cheered', 1), ('franyxxxxx', 1), ('pocay', 1), ('wocay', 1), ('2morrowxxxx', 1), ('45pm', 1), ('basketball', 1), ('outdoors', 1), ('sorta', 1), ('blown', 1), ('ajith', 1), ('116', 1), ('atten', 1), ('worlds', 1), ('discreet', 1), ('83110', 1), ('neglect', 1), ('hardly', 1), ('dartboard', 1), ('doubles', 1), ('trebles', 1), ('motherfucker', 1), ('stu', 1), ('truble', 1), ('evone', 1), ('hates', 1), ('dan', 2), ('strict', 1), ('teaches', 2), ('conducts', 2), ('asjesus', 1), ('wrote', 1), ('dippeditinadew', 1), ('lovingly', 1), ('itwhichturnedinto', 1), ('gifted', 1), ('tomeandsaid', 1), ('grave', 1), ('wtc', 1), ('weiyi', 1), ('revealing', 1), ('gauti', 1), ('sehwag', 1), ('odi', 1), ('okmail', 1), ('mathews', 1), ('tait', 1), ('edwards', 1), ('anderson', 1), ('twins', 1), ('amigos', 1), ('burn', 1), ('ne', 2), ('interesting', 2), ('wrking', 1), ('stage', 1), ('macha', 1), ('upset', 4), ('mindset', 1), ('significance', 1), ('follows', 1), ('subsequent', 1), ('09050001808', 1), ('m95', 1), (\"'its\", 1), ('dial', 1), ('browser', 1), ('surf', 1), ('missunderstding', 1), (\"one's\", 1), (\"it'll\", 1), ('smarter', 1), ('shattered', 1), ('coco', 1), ('hor', 2), ('cock', 1), (\"hubby's\", 1), ('89938', 1), ('strings', 1), ('50ea', 1), ('otbox', 1), ('731', 1), ('la1', 1), ('7ws', 1), ('accenture', 1), ('definite', 2), ('greece', 1), ('donate', 2), (\"unicef's\", 1), ('asian', 1), ('tsunami', 1), ('disaster', 1), ('fund', 1), ('864233', 1), ('frog', 1), ('mad1', 1), ('mad2', 1), (\"taylor's\", 1), ('denis', 2), ('mina', 1), (\"nobody's\", 1), ('8077', 1), ('machines', 1), ('wildlife', 1), ('want2come', 1), ('that2worzels', 1), ('wizzle', 1), ('baaaaabe', 1), ('misss', 1), ('youuuuu', 1), ('we\\x89û÷ll', 1), ('wishlist', 1), ('section', 1), ('forums', 2), ('nitro', 1), ('korean', 1), (\"leona's\", 1), ('hasnt', 1), ('dose', 1), ('tablet', 1), ('08719181259', 1), ('26', 2), ('can\\x89û÷t', 1), ('7634', 1), ('7684', 1), ('parties', 1), ('lookatme', 2), ('clip', 1), ('35p', 1), ('mmsto', 1), ('32323', 1), ('plate', 1), ('leftovers', 1), ('tke', 1), ('sacked', 1), ('celebrate', 1), ('fondly', 1), ('ceiling', 1), ('showers', 1), ('possessiveness', 1), ('poured', 1), ('golden', 1), ('ignorant', 1), ('freaky', 1), ('granite', 1), ('explosive', 1), ('nasdaq', 1), ('symbol', 2), ('cdgt', 1), ('08712400200', 1), ('withdraw', 1), ('anyhow', 1), ('dreading', 1), ('thou', 1), ('upto', 2), ('netflix', 1), ('1hr', 1), ('delay', 2), ('sooo', 1), ('involve', 1), ('imposed', 1), ('30th', 1), ('areyouunique', 1), ('jam', 1), ('hannaford', 1), ('wheat', 1), ('chex', 1), ('bognor', 1), ('splendid', 1), ('deduct', 1), ('wrc', 2), ('rally', 2), ('lucozade', 2), ('le', 1), ('61200', 1), ('packs', 1), ('itcould', 1), ('tix', 1), ('solihull', 1), ('skateboarding', 1), ('thrown', 1), ('winds', 1), ('bandages', 1), ('situations', 1), ('loosing', 1), ('randomly', 2), ('loyal', 1), ('customers', 1), ('09066380611', 1), ('xafter', 1), ('cst', 1), ('chg', 1), ('steak', 1), ('hero', 1), ('apt', 1), ('9061100010', 1), ('wire3', 1), ('1st4terms', 1), ('mobcudb', 1), (\"weren't\", 1), ('disastrous', 1), ('fav', 2), ('flippin', 1), ('elama', 1), ('mudyadhu', 1), (\"sms'd\", 1), ('surgical', 1), ('emergency', 1), ('unfolds', 1), ('patty', 1), ('haul', 1), ('sonetimes', 1), ('rough', 1), ('brdget', 1), ('jones', 1), ('shb', 1), ('huge', 2), ('marking', 1), ('evaporated', 1), ('stealing', 1), (\"employer's\", 1), ('supervisor', 2), ('factory', 1), ('install', 1), ('browse', 1), ('artists', 1), ('lastest', 1), ('stereophonics', 1), ('marley', 1), ('dizzee', 1), ('racal', 1), ('libertines', 1), ('strokes', 1), ('nookii', 1), ('bookmark', 1), ('lists', 1), ('detail', 1), ('signal', 1), ('neither', 1), ('unusual', 1), ('misplaced', 1), ('associate', 1), ('aluable', 1), ('ffectionate', 1), ('oveable', 1), ('ternal', 1), ('oble', 1), ('ruthful', 1), ('ntimate', 1), ('atural', 1), ('namous', 1), ('hon', 1), ('doinat', 1), ('increase', 1), ('annoying', 2), ('3000', 1), ('08712402050', 2), ('10ppm', 2), ('ag', 2), ('promo', 2), ('dao', 1), ('careful', 1), ('078498', 1), ('08719180219', 1), ('uncomfortable', 1), ('rdy', 1), ('08714712394', 1), ('30pm', 1), ('thout', 1), ('irritation', 1), ('50s', 1), ('alot', 1), ('49557', 1), ('receipts', 1), ('pendent', 1), ('intrepid', 1), ('duo', 1), ('submitting', 1), ('wining', 1), ('946', 1), ('0871277810710p', 1), ('srsly', 1), ('yi', 1), ('radiator', 1), ('tok', 1), ('recorded', 1), ('stereo', 1), ('mi', 1), ('unknown', 1), ('thasa', 1), ('messed', 1), ('doke', 1), ('dressed', 1), ('laying', 1), ('08718730555', 1), ('imp', 1), ('hittng', 1), ('reflex', 1), ('sports', 2), ('fans', 1), ('0870141701216', 1), ('120p', 1), ('ringing', 1), ('houseful', 1), ('brats', 1), ('pulling', 1), ('inpersonation', 1), ('flea', 1), ('reminded', 1), ('chick', 1), ('boobs', 1), ('1b6a5ecef91ff9', 1), ('37819', 1), ('true18', 1), ('0430', 1), ('jul', 1), ('ansr', 2), ('tyrone', 2), ('evenings', 1), ('brin', 1), ('sheet', 1), ('casualty', 1), ('stuff42moro', 1), ('includes', 1), ('sheets', 3), ('cheque', 1), ('ay', 1), ('cloud', 1), ('river', 1), ('083', 1), ('6089', 1), ('isaiah', 1), ('canåõt', 1), ('isnåõt', 1), ('shite', 1), ('kip', 1), ('smokin', 1), ('threats', 1), ('sales', 1), ('shifad', 1), ('raised', 1), ('complaint', 1), ('twenty', 1), ('durham', 1), ('reserved', 1), ('seat', 1), ('art', 1), ('borrow', 1), ('x29', 1), ('09065989180', 1), ('08719899230', 1), ('41685', 2), ('07', 2), ('dhanush', 1), ('rocks', 1), ('passport', 1), ('08718738034', 1), ('seing', 1), ('asssssholeeee', 1), (\"account's\", 1), ('gandhipuram', 1), ('grooved', 1), ('ccna', 1), ('julianaland', 1), ('oblivious', 1), ('09061701851', 1), ('k61', 1), ('12hours', 1), ('sd', 1), ('83021', 1), ('fellow', 1), ('grasp', 1), ('08719181503', 1), ('painful', 1), ('recognises', 1), ('nauseous', 1), ('dieting', 1), ('deny', 1), ('problematic', 1), ('nos', 1), ('alter', 1), ('drugdealer', 1), ('massages', 1), ('formally', 1), ('screen', 1), ('tomorro', 1), ('taught', 1), ('becaus', 1), ('verifying', 1), ('prabu', 1), ('chachi', 1), ('pl', 1), ('tiz', 1), ('kanagu', 1), ('loud', 1), ('spontaneously', 1), ('goodevening', 1), ('wisdom', 1), ('mention', 1), ('served', 1), ('unemployed', 2), ('32000', 1), ('legitimat', 1), ('efreefone', 1), ('cough', 1), ('pan', 2), ('silly', 1), ('isn\\x89û÷t', 1), ('cereals', 1), ('gari', 1), ('algarve', 1), ('clothes', 1), (\"zaher's\", 1), ('hiphop', 1), ('interfued', 1), ('seeking', 1), ('underdtand', 1), ('shadow', 1), ('spring', 1), ('07808', 1), ('xxxxxx', 1), ('08719899217', 1), ('2p', 2), ('08448350055', 1), ('planettalkinstant', 1), ('pocked', 1), ('naal', 1), ('eruku', 1), ('taj', 1), ('mahal', 1), ('lesser', 1), ('known', 1), ('facts', 1), ('mumtaz', 2), (\"shahjahan's\", 1), ('wifes', 1), ('shahjahan', 1), (\"mumtaz's\", 2), ('arises', 1), ('hari', 1), ('adi', 1), ('entey', 1), ('nattil', 1), ('kittum', 1), ('tall', 1), ('gonnamissu', 1), ('postcard', 2), ('buttheres', 1), ('aboutas', 1), ('merememberin', 1), ('asthere', 1), ('ofsi', 1), ('breakin', 1), ('yaxx', 1), ('finishd', 1), ('wlcome', 1), ('lion', 1), ('spys', 1), ('computational', 1), ('push', 1), ('honestly', 1), ('promptly', 1), ('burnt', 1), ('companion', 1), ('chef', 1), ('listener', 1), ('organizer', 1), ('sympathetic', 1), ('athletic', 1), ('courageous', 1), ('determined', 1), ('dependable', 1), ('psychologist', 1), ('pest', 1), ('exterminator', 1), ('psychiatrist', 1), ('healer', 1), ('stylist', 1), ('driver', 1), ('aaniye', 1), ('pudunga', 1), ('venaam', 1), ('leanne', 1), ('que', 1), ('pases', 1), ('buen', 1), ('tiempo', 1), ('rewarding', 1), ('08714712388', 1), ('hellogorgeous', 1), ('lst', 1), ('nitw', 1), ('texd', 1), ('hopeu', 1), ('4ward', 1), ('jaz', 1), ('bhaji', 1), ('cricketer', 1), ('sigh', 1), ('starving', 1), ('crammed', 1), ('deficient', 1), ('pei', 1), ('warned', 1), ('sprint', 1), ('axis', 1), ('greatness', 1), ('heavily', 1), ('gpu', 1), ('correctly', 1), ('arty', 1), ('collages', 1), ('tryin', 1), ('nick', 1), ('types', 1), ('08718730666', 1), ('punto', 1), ('woulda', 1), ('å£1million', 1), ('ppt150x3', 1), ('box403', 1), ('w1t1jy', 1), ('juswoke', 1), ('boatin', 1), ('docks', 1), ('spinout', 1), ('watchin', 1), ('chastity', 1), ('device', 1), ('beatings', 1), ('fires', 1), ('upgrdcentre', 1), ('9153', 1), ('girlie', 1), ('sarasota', 1), ('bull', 1), ('floating', 1), ('cumming', 1), ('adjustable', 1), ('cooperative', 1), ('allows', 1), ('units', 1), ('accent', 1), ('4years', 1), ('dental', 1), ('nmde', 1), ('tai', 1), ('feng', 1), ('reservations', 1), ('09050000928', 1), ('grumble', 1), ('å£1000call', 1), ('09071512432', 1), ('300603t', 1), ('callcost150ppmmobilesvary', 1), ('nìâte', 1), ('turned', 1), ('data', 1), ('analysis', 1), ('grateful', 1), ('happier', 1), ('highest', 1), ('å£54', 1), ('maximum', 1), ('å£71', 1), ('pt2', 1), ('saibaba', 1), ('colany', 1), ('depression', 1), ('beneath', 1), ('pale', 1), ('weighed', 1), ('woohoo', 1), ('4the', 1), ('payed', 1), ('suganya', 1), ('multimedia', 1), ('draws', 1), ('09061701939', 1), ('s89', 1), ('ecstasy', 1), ('msgrcvd', 1), ('customercare', 1), ('props', 1), ('maaaan', 1), ('07808726822', 1), ('9758', 1), ('hiding', 1), ('honeymoon', 1), ('outfit', 1), ('panasonic', 1), ('bluetoothhdset', 1), ('doublemins', 1), ('doubletxt', 1), ('lambu', 1), ('ji', 1), ('batchlor', 1), ('stitch', 1), ('trouser', 1), (\"anything's\", 1), ('soz', 1), ('imat', 1), ('mums', 1), ('ft', 1), ('combination', 1), ('priority', 1), ('bottle', 2), ('amused', 1), ('reffering', 1), ('getiing', 1), ('nighters', 1), ('persevered', 1), ('tahan', 1), ('anot', 1), ('lo', 1), ('guessin', 1), ('uawake', 1), ('feellikw', 1), ('justfound', 1), ('aletter', 1), ('thatmum', 1), ('gotmarried', 1), ('4thnov', 1), ('ourbacks', 1), ('fuckinnice', 1), ('dear1', 1), ('best1', 1), ('clos1', 1), ('lvblefrnd', 1), ('jstfrnd', 1), ('cutefrnd', 1), ('lifpartnr', 1), ('swtheart', 1), ('bstfrnd', 1), ('popping', 1), ('ibuprofens', 1), ('mag', 1), ('24th', 1), ('returning', 1), ('dramatic', 1), ('leg', 1), ('musta', 1), ('overdid', 1), ('jon', 1), ('spain', 1), ('sum', 1), ('dinero', 1), ('åôrents', 1), ('000pes', 1), ('å£48', 1), ('breakfast', 1), ('hamper', 1), ('61610', 1), ('08712400602450p', 1), ('provided', 1), ('tones2you', 1), ('db', 1), ('bhaskar', 1), ('09096102316', 1), ('07090298926', 1), ('9307622', 1), ('asus', 1), ('reformat', 1), ('tau', 1), ('piah', 1), ('hanks', 1), ('lotsly', 1), ('hui', 1), ('xin', 1), ('lib', 1), ('sorts', 1), ('fightng', 1), ('dificult', 1), ('sticky', 1), ('fucks', 1), ('sometme', 1), ('pobox202', 1), ('nr31', 1), ('7zs', 1), ('450pw', 1), ('faggot', 1), ('tarot', 1), ('85555', 1), (\"there'll\", 1), ('shindig', 1), ('assumed', 1), ('breadstick', 1), ('invaders', 1), ('orig', 1), ('arcade', 2), ('console', 1), ('scratches', 1), ('resubbing', 1), ('newquay', 1), ('1im', 1), ('talkin', 1), ('limited', 1), ('gail', 1), ('l8tr', 1), ('yaxxx', 1), ('bcaz', 1), ('lipo', 1), ('humanities', 1), ('grown', 1), ('nationwide', 1), ('newport', 1), ('07973788240', 1), ('08715203649', 1), ('mc', 1), ('avalarr', 1), ('hollalater', 1), ('parking', 1), ('bawling', 1), ('failure', 1), ('failing', 1), ('cashed', 1), ('announced', 1), ('blog', 1), ('soryda', 1), ('sory', 1), ('inner', 1), ('tigress', 1), ('ebay', 1), ('123', 1), ('09050002311', 1), ('b4280703', 1), ('08718727868', 1), ('documents', 1), ('submitted', 1), ('stapati', 1), ('ditto', 1), ('07808247860', 1), ('08719899229', 1), ('40411', 1), ('09061702893', 1), ('khelate', 1), ('kintu', 1), ('opponenter', 1), ('dhorte', 1), ('lage', 1), (\"tm'ing\", 1), ('laughs', 1), ('adding', 1), ('zeros', 1), ('savings', 1), ('cme', 2), ('hos', 1), ('heroes', 1), ('tips', 1), ('genes', 1), ('begun', 1), ('registration', 1), ('permanent', 1), ('residency', 1)])\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 4337\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 55.45326684567191\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.65745644331875\n",
      "메일의 최대 길이 : 189\n",
      "메일의 평균 길이 : 15.754534\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기(shape): (4135, 189)\n"
     ]
    }
   ],
   "source": [
    "# 문장 토큰화\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
    "print('메일의 토큰화 결과(5개):\\n', X_train_encoded[:5])\n",
    "print()\n",
    "word_to_index = tokenizer.word_index\n",
    "print('토큰에 부여된 정수:\\n', word_to_index)\n",
    "print()\n",
    "vocab_size = len(word_to_index) + 1\n",
    "print('단어 집합의 크기: {}'.format((vocab_size)))\n",
    "print()\n",
    "print('각 단어에 대한 등장 빈도수: ', tokenizer.word_counts.items())\n",
    "\n",
    "\n",
    "# 토큰화된 단어 분석\n",
    "threshold = 2\n",
    "total_cnt = len(word_to_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "print('메일의 최대 길이 : %d' % max(len(sample) for sample in X_train_encoded))\n",
    "print('메일의 평균 길이 : %f' % (sum(map(len, X_train_encoded))/len(X_train_encoded)))\n",
    "plt.hist([len(sample) for sample in X_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "# 가장 긴 메일의 길이는 189이며, 전체 데이터의 길이 분포는 대체적으로 약 50이하의 길이를 가집니다\n",
    "\n",
    "\n",
    "max_len = 189\n",
    "X_train_padded = pad_sequences(X_train_encoded, maxlen = max_len)\n",
    "print(\"훈련 데이터의 크기(shape):\", X_train_padded.shape)\n",
    "# 189보다 길이가 짧은 메일 샘플은 전부 숫자 0이 패딩되어 189의 길이를 가지도록 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t24aQmxFQZ8G"
   },
   "source": [
    "- **2.RNN으로 스팸 메일 분류하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "c9hiTkxtQcpi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - acc: 0.8597 - loss: 0.4157 - val_acc: 0.9432 - val_loss: 0.2258\n",
      "Epoch 2/4\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.9616 - loss: 0.1489 - val_acc: 0.9625 - val_loss: 0.1425\n",
      "Epoch 3/4\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - acc: 0.9797 - loss: 0.0710 - val_acc: 0.9734 - val_loss: 0.0883\n",
      "Epoch 4/4\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - acc: 0.9897 - loss: 0.0425 - val_acc: 0.9831 - val_loss: 0.0659\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9845 - loss: 0.0647\n",
      "\n",
      "테스트 정확도: 0.9845\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# 모델 구성\n",
    "embedding_dim = 32\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train_padded, y_train, epochs=4, batch_size=64, validation_split=0.2)\n",
    "\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_encoded, maxlen = max_len)\n",
    "print(\"\\n테스트 정확도: %.4f\" % (model.evaluate(X_test_padded, y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pOC_v37vW5vb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "=== 예측 결과 ===\n",
      "실제값: 4183    0\n",
      "108     0\n",
      "5237    1\n",
      "1858    0\n",
      "3603    0\n",
      "368     0\n",
      "2       1\n",
      "2444    0\n",
      "2365    0\n",
      "3791    0\n",
      "Name: v1, dtype: int64\n",
      "예측값: [0 0 1 0 0 0 1 0 0 0]\n",
      "예측 확률: [0.00599068 0.00981754 0.994959   0.01892568 0.00406642 0.00418436\n",
      " 0.99534667 0.00403488 0.01764824 0.00964417]\n",
      "\n",
      "정확도: 0.9845\n",
      "혼동 행렬:\n",
      "[[901   2]\n",
      " [ 14 117]]\n",
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       903\n",
      "           1       0.98      0.89      0.94       131\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.98      0.95      0.96      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== 핵심 예측 및 비교 코드 ==========\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1. 예측값 생성\n",
    "y_pred_proba = model.predict(X_test_padded)  # 확률값 (0~1)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()  # 이진 분류값 (0 or 1)\n",
    "\n",
    "# 2. 결과 비교\n",
    "print(\"\\n=== 예측 결과 ===\")\n",
    "print(f\"실제값: {y_test[:10]}\")\n",
    "print(f\"예측값: {y_pred[:10]}\")\n",
    "print(f\"예측 확률: {y_pred_proba[:10].flatten()}\")\n",
    "\n",
    "# 3. 성능 지표\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n정확도: {accuracy:.4f}\")\n",
    "print(f\"혼동 행렬:\\n{cm}\")\n",
    "print(\"\\n분류 리포트:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4Uhhkh1-j7kh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "새로운 메일 스팸 분류 테스트\n",
      "============================================================\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "📧 테스트 메일 1:\n",
      "내용: URGENT! You have won $1000000! Click here now to claim your prize! Limited time offer! Call now!\n",
      "예측 결과: 스팸 메일\n",
      "스팸 확률: 0.9938\n",
      "신뢰도: 0.9938 (99.4%)\n",
      "------------------------------------------------------------\n",
      "\n",
      "📧 테스트 메일 2:\n",
      "내용: Hi John, hope you're doing well. Let's meet for coffee tomorrow at 3pm. Looking forward to catching up!\n",
      "예측 결과: 정상 메일\n",
      "스팸 확률: 0.0094\n",
      "신뢰도: 0.9906 (99.1%)\n",
      "------------------------------------------------------------\n",
      "\n",
      "📧 테스트 메일 3:\n",
      "내용: Special discount on our premium products. Save 30% this week only. Visit our website for more details.\n",
      "예측 결과: 스팸 메일\n",
      "스팸 확률: 0.8590\n",
      "신뢰도: 0.8590 (85.9%)\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "토큰화 분석\n",
      "============================================================\n",
      "\n",
      "🔍 'URGENT! You have won $1000000! Click here now to c...' 분석\n",
      "원본 단어들: ['URGENT!', 'You', 'have', 'won', '$1000000!', 'Click', 'here', 'now', 'to', 'claim', 'your', 'prize!', 'Limited', 'time', 'offer!', 'Call', 'now!']\n",
      "토큰화 결과: [183, 3, 16, 214, 1295, 113, 22, 2, 136, 13, 148, 7765, 60, 419, 18, 22]\n",
      "토큰 -> 단어: ['urgent', 'you', 'have', 'won', 'click', 'here', 'now', 'to', 'claim', 'your', 'prize', 'limited', 'time', 'offer', 'call', 'now']\n",
      "----------------------------------------\n",
      "\n",
      "🔍 'Hi John, hope you're doing well. Let's meet for co...' 분석\n",
      "원본 단어들: ['Hi', 'John,', 'hope', \"you're\", 'doing', 'well.', \"Let's\", 'meet', 'for', 'coffee', 'tomorrow', 'at', '3pm.', 'Looking', 'forward', 'to', 'catching', 'up!']\n",
      "토큰화 결과: [97, 1028, 120, 240, 153, 127, 2273, 152, 12, 1277, 169, 30, 423, 1226, 2, 1976, 41]\n",
      "토큰 -> 단어: ['hi', 'john', 'hope', \"you're\", 'doing', 'well', \"let's\", 'meet', 'for', 'coffee', 'tomorrow', 'at', 'looking', 'forward', 'to', 'catching', 'up']\n",
      "----------------------------------------\n",
      "\n",
      "🔍 'Special discount on our premium products. Save 30%...' 분석\n",
      "원본 단어들: ['Special', 'discount', 'on', 'our', 'premium', 'products.', 'Save', '30%', 'this', 'week', 'only.', 'Visit', 'our', 'website', 'for', 'more', 'details.']\n",
      "토큰화 결과: [381, 1252, 17, 94, 2835, 3592, 1124, 753, 39, 121, 68, 851, 94, 1394, 12, 123, 534]\n",
      "토큰 -> 단어: ['special', 'discount', 'on', 'our', 'premium', 'products', 'save', '30', 'this', 'week', 'only', 'visit', 'our', 'website', 'for', 'more', 'details']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ========== 새로운 메일 테스트 코드 ==========\n",
    "def predict_spam(text_list, model, tokenizer, max_len=189):\n",
    "    \"\"\"\n",
    "    새로운 메일 텍스트들이 스팸인지 예측하는 함수\n",
    "\n",
    "    Parameters:\n",
    "    - text_list: 예측할 메일 텍스트들의 리스트\n",
    "    - model: 학습된 RNN 모델\n",
    "    - tokenizer: 학습에 사용된 토크나이저\n",
    "    - max_len: 패딩할 최대 길이\n",
    "\n",
    "    Returns:\n",
    "    - predictions: 각 텍스트에 대한 예측 결과\n",
    "    \"\"\"\n",
    "    # 텍스트를 시퀀스로 변환\n",
    "    sequences = tokenizer.texts_to_sequences(text_list)\n",
    "    # 패딩 적용\n",
    "    padded = pad_sequences(sequences, maxlen=max_len)\n",
    "    # 예측 수행\n",
    "    predictions = model.predict(padded)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# 테스트할 새로운 메일 예시 3개\n",
    "test_emails = [\n",
    "    # 예시 1: 명백한 스팸 메일\n",
    "    \"URGENT! You have won $1000000! Click here now to claim your prize! Limited time offer! Call now!\",\n",
    "\n",
    "    # 예시 2: 정상 메일\n",
    "    \"Hi John, hope you're doing well. Let's meet for coffee tomorrow at 3pm. Looking forward to catching up!\",\n",
    "\n",
    "    # 예시 3: 애매한 경계선 메일 (프로모션성이지만 스팸은 아닐 수 있음)\n",
    "    \"Special discount on our premium products. Save 30% this week only. Visit our website for more details.\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"새로운 메일 스팸 분류 테스트\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# 예측 수행\n",
    "predictions = predict_spam(test_emails, model, tokenizer, max_len)\n",
    "\n",
    "# 결과 출력\n",
    "for i, (email, pred) in enumerate(zip(test_emails, predictions)):\n",
    "    prob = pred[0]  # 확률값 추출\n",
    "    is_spam = \"스팸 메일\" if prob > 0.5 else \"정상 메일\"\n",
    "    confidence = prob if prob > 0.5 else 1 - prob\n",
    "\n",
    "    print(f\"\\n📧 테스트 메일 {i+1}:\")\n",
    "    print(f\"내용: {email}\")\n",
    "    print(f\"예측 결과: {is_spam}\")\n",
    "    print(f\"스팸 확률: {prob:.4f}\")\n",
    "    print(f\"신뢰도: {confidence:.4f} ({confidence*100:.1f}%)\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# ========== 대화형 테스트 함수 ==========\n",
    "def interactive_spam_test():\n",
    "    \"\"\"\n",
    "    사용자가 직접 메일 내용을 입력하여 테스트할 수 있는 함수\n",
    "    \"\"\"\n",
    "    print(\"\\n🔍 직접 메일 테스트해보기\")\n",
    "    print(\"메일 내용을 입력하세요 (종료하려면 'quit' 입력):\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\n메일 내용: \")\n",
    "\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"테스트를 종료합니다.\")\n",
    "            break\n",
    "\n",
    "        if user_input.strip() == '':\n",
    "            print(\"메일 내용을 입력해주세요.\")\n",
    "            continue\n",
    "\n",
    "        # 예측 수행\n",
    "        prediction = predict_spam([user_input], model, tokenizer, max_len)\n",
    "        prob = prediction[0][0]\n",
    "        is_spam = \"스팸 메일\" if prob > 0.5 else \"정상 메일\"\n",
    "        confidence = prob if prob > 0.5 else 1 - prob\n",
    "\n",
    "        print(f\"📊 분석 결과:\")\n",
    "        print(f\"   예측: {is_spam}\")\n",
    "        print(f\"   스팸 확률: {prob:.4f}\")\n",
    "        print(f\"   신뢰도: {confidence:.4f} ({confidence*100:.1f}%)\")\n",
    "\n",
    "# 대화형 테스트 실행 (주석 해제하여 사용)\n",
    "# interactive_spam_test()\n",
    "\n",
    "# ========== 추가 분석: 단어 중요도 확인 ==========\n",
    "def analyze_email_tokens(email_text, tokenizer, max_len=189):\n",
    "    \"\"\"\n",
    "    이메일의 토큰화 과정을 분석하는 함수\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 '{email_text[:50]}...' 분석\")\n",
    "\n",
    "    # 토큰화\n",
    "    sequence = tokenizer.texts_to_sequences([email_text])\n",
    "    padded = pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "    # 원본 단어들 확인\n",
    "    words = email_text.split()\n",
    "    print(f\"원본 단어들: {words}\")\n",
    "\n",
    "    # 토큰화된 결과\n",
    "    tokens = sequence[0]\n",
    "    print(f\"토큰화 결과: {tokens}\")\n",
    "\n",
    "    # 역토큰화 (숫자 -> 단어)\n",
    "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "    decoded_words = [reverse_word_map.get(token, '<UNK>') for token in tokens]\n",
    "    print(f\"토큰 -> 단어: {decoded_words}\")\n",
    "\n",
    "    return padded\n",
    "\n",
    "# 각 테스트 메일에 대해 토큰 분석\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"토큰화 분석\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, email in enumerate(test_emails):\n",
    "    analyze_email_tokens(email, tokenizer, max_len)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VWAwcAVlSjv"
   },
   "source": [
    "## **LSTM(Long Short-Term Memory)**\n",
    "\n",
    "- LSTM은 **장단기 메모리 네트워크**로, RNN(순환신경망)의 한 종류\n",
    "- 기존 RNN의 기울기 소실 문제, **장기 의존성 문제(the problem of Long-Term Dependencies)를 해결하기 위해 개발된 고급 신경망 구조**\n",
    "- LSTM은 은닉층의 메모리 셀에 입력 게이트, 망각 게이트, 출력 게이트를 추가하여 불필요한 기억을 지우고, 기억해야할 것들을 정함\n",
    "- - 아키텍쳐 (참고: https://wikidocs.net/22888)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kG2aAdlcp0Ap"
   },
   "source": [
    "![RNN](https://wikidocs.net/images/page/22888/vanilla_rnn_ver2.PNG \"RNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_MDGDGyp1Zl"
   },
   "source": [
    "![LSTM](https://wikidocs.net/images/page/22888/vaniila_rnn_and_different_lstm_ver2.PNG \"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8r9nH0VnhES"
   },
   "source": [
    "### 예제: **한글 스팸메일 분류기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7LUl3Od6lR34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "한글 스팸 메일 분류기 생성 중...\n",
      "============================================================\n",
      "총 데이터 수: 1000\n",
      "정상 메일 수: 500\n",
      "스팸 메일 수: 500\n",
      "정상 메일 비율: 50.0%\n",
      "스팸 메일 비율: 50.0%\n",
      "데이터 타입 - X: <U34, y: int64\n",
      "데이터 형태 - X: (1000,), y: (1000,)\n",
      "\n",
      "훈련 데이터: 800\n",
      "테스트 데이터: 200\n",
      "\n",
      "어휘 크기: 209\n",
      "시퀀스 최대 길이: 100\n",
      "\n",
      "모델 구조:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm (\u001b[38;5;33mBidirectional\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모델 훈련 시작...\n",
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7375 - loss: 0.6526 - val_accuracy: 1.0000 - val_loss: 0.5367 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9734 - loss: 0.3091 - val_accuracy: 1.0000 - val_loss: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9984 - loss: 0.0329 - val_accuracy: 1.0000 - val_loss: 7.3278e-04 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 5.6963e-05 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9969 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 4.4253e-05 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 3.0375e-05 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 2.1814e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 1.4846e-05 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9984 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 1.2470e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 1.0328e-05 - learning_rate: 2.5000e-04\n",
      "\n",
      "테스트 정확도: 1.0000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          정상       1.00      1.00      1.00       100\n",
      "          스팸       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "\n",
      "혼동 행렬:\n",
      "[[100   0]\n",
      " [  0 100]]\n",
      "\n",
      "============================================================\n",
      "한글 메일 스팸 분류 테스트\n",
      "============================================================\n",
      "\n",
      "📧 테스트 1:\n",
      "내용: 축하합니다! 복권에 당첨되셨습니다. 1억원을 받으시려면 지금 즉시 링크를 클릭하세요!\n",
      "예측: 스팸 메일\n",
      "스팸 확률: 1.0000\n",
      "신뢰도: 1.0000 (100.0%)\n",
      "--------------------------------------------------\n",
      "\n",
      "📧 테스트 2:\n",
      "내용: 내일 오후 3시 회의실에서 프로젝트 진행 상황을 논의하겠습니다. 참석 부탁드립니다.\n",
      "예측: 정상 메일\n",
      "스팸 확률: 0.0000\n",
      "신뢰도: 1.0000 (100.0%)\n",
      "--------------------------------------------------\n",
      "\n",
      "📧 테스트 3:\n",
      "내용: 무료 다이어트 약품 증정! 효과 100% 보장! 지금 신청하면 특별 할인!\n",
      "예측: 스팸 메일\n",
      "스팸 확률: 1.0000\n",
      "신뢰도: 1.0000 (100.0%)\n",
      "--------------------------------------------------\n",
      "\n",
      "📧 테스트 4:\n",
      "내용: 보고서 작성이 완료되었습니다. 첨부파일을 확인해주시기 바랍니다.\n",
      "예측: 정상 메일\n",
      "스팸 확률: 0.0001\n",
      "신뢰도: 0.9999 (100.0%)\n",
      "--------------------------------------------------\n",
      "\n",
      "📧 테스트 5:\n",
      "내용: 긴급! 대출 승인 완료! 무심사 당일 지급! 연락 바랍니다!\n",
      "예측: 스팸 메일\n",
      "스팸 확률: 1.0000\n",
      "신뢰도: 1.0000 (100.0%)\n",
      "--------------------------------------------------\n",
      "\n",
      "📧 테스트 6:\n",
      "내용: 교육 자료를 공유드립니다. 검토 후 의견 부탁드립니다.\n",
      "예측: 정상 메일\n",
      "스팸 확률: 0.0000\n",
      "신뢰도: 1.0000 (100.0%)\n",
      "--------------------------------------------------\n",
      "✅ 모델이 korean_spam_model.h5에 저장되었습니다.\n",
      "✅ 토크나이저가 korean_tokenizer.pickle에 저장되었습니다.\n",
      "\n",
      "============================================================\n",
      "한글 스팸 메일 분류기 완성!\n",
      "아래 함수를 실행하여 직접 테스트해보세요:\n",
      "interactive_korean_spam_test()\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 텍스트 전처리 함수\n",
    "def preprocess_korean_text(text):\n",
    "    \"\"\"\n",
    "    한글 텍스트 전처리 함수\n",
    "    - 특수문자 제거\n",
    "    - 불필요한 공백 제거\n",
    "    - 소문자 변환은 한글에서 불필요\n",
    "    \"\"\"\n",
    "    # 한글, 영문, 숫자, 공백만 남기기\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', ' ', text)\n",
    "    # 연속된 공백을 하나로 변경\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # 앞뒤 공백 제거\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# 한글 스팸/정상 메일 모의 데이터셋 생성\n",
    "def create_korean_email_dataset():\n",
    "    \"\"\"\n",
    "    한글 스팸/정상 메일 모의 데이터셋 생성\n",
    "    실제 프로젝트에서는 공개 데이터셋이나 수집된 데이터를 사용\n",
    "    \"\"\"\n",
    "\n",
    "    # 정상 메일 예시 (500개 생성을 위한 기본 패턴)\n",
    "    normal_patterns = [\n",
    "        \"안녕하세요 회의 일정을 알려드립니다\",\n",
    "        \"프로젝트 진행 상황 보고드립니다\",\n",
    "        \"첨부파일 확인 부탁드립니다\",\n",
    "        \"내일 오후 미팅 참석 가능하신가요\",\n",
    "        \"업무 관련 문의사항이 있습니다\",\n",
    "        \"보고서 작성 완료했습니다\",\n",
    "        \"점심시간에 잠깐 이야기할 수 있을까요\",\n",
    "        \"고객사 미팅 결과 공유드립니다\",\n",
    "        \"다음 주 일정 조율 부탁드립니다\",\n",
    "        \"교육 자료 전달드립니다\",\n",
    "        \"회의실 예약 확인 부탁드립니다\",\n",
    "        \"출장 계획서 검토 요청드립니다\",\n",
    "        \"월간 성과 보고서 제출합니다\",\n",
    "        \"팀 빌딩 행사 참석 의사 확인\",\n",
    "        \"새 프로젝트 제안서 검토 바랍니다\"\n",
    "    ]\n",
    "\n",
    "    # 스팸 메일 예시 (500개 생성을 위한 기본 패턴)\n",
    "    spam_patterns = [\n",
    "        \"축하합니다 1억원 당첨되셨습니다 지금 확인하세요\",\n",
    "        \"긴급 대출 가능 무심사 당일 승인\",\n",
    "        \"클릭만으로 월 300만원 수익 보장\",\n",
    "        \"무료 상품권 증정 지금 신청하세요\",\n",
    "        \"다이어트 보조제 특가 판매 효과 100퍼센트\",\n",
    "        \"투자 권유 고수익 보장 위험 부담 없음\",\n",
    "        \"성인용품 할인 판매 비밀 배송\",\n",
    "        \"카지노 게임 첫 가입 보너스 지급\",\n",
    "        \"주식 정보 제공 수익률 200퍼센트\",\n",
    "        \"아르바이트 모집 하루 10만원 보장\",\n",
    "        \"온라인 도박 사이트 가입 즉시 보너스\",\n",
    "        \"신용카드 현금 서비스 즉시 승인\",\n",
    "        \"불법 복제품 판매 정품 보장\",\n",
    "        \"피라미드 판매 조직 가입 권유\",\n",
    "        \"가상화폐 투자 사기 의혹 상품\"\n",
    "    ]\n",
    "\n",
    "    # 데이터셋 확장 생성\n",
    "    emails = []\n",
    "    labels = []\n",
    "\n",
    "    # 정상 메일 500개 생성\n",
    "    for i in range(500):\n",
    "        base_pattern = normal_patterns[i % len(normal_patterns)]\n",
    "        # 패턴에 변화를 주어 다양성 증가\n",
    "        variations = [\n",
    "            base_pattern,\n",
    "            base_pattern + f\" {i+1}번째 건입니다\",\n",
    "            base_pattern + \" 확인 후 회신 바랍니다\",\n",
    "            base_pattern + \" 관련하여 논의가 필요합니다\",\n",
    "            \"업무: \" + base_pattern\n",
    "        ]\n",
    "        emails.append(variations[i % len(variations)])\n",
    "        labels.append(0)  # 정상 메일\n",
    "\n",
    "    # 스팸 메일 500개 생성\n",
    "    for i in range(500):\n",
    "        base_pattern = spam_patterns[i % len(spam_patterns)]\n",
    "        # 스팸의 특징을 강화한 변화\n",
    "        variations = [\n",
    "            base_pattern,\n",
    "            \"🎉\" + base_pattern + \"🎉\",\n",
    "            base_pattern + \" 지금 즉시 클릭하세요!\",\n",
    "            \"★★★ \" + base_pattern + \" ★★★\",\n",
    "            base_pattern + \" 놓치면 후회합니다!\"\n",
    "        ]\n",
    "        emails.append(variations[i % len(variations)])\n",
    "        labels.append(1)  # 스팸 메일\n",
    "\n",
    "    return emails, labels\n",
    "\n",
    "# 데이터셋 생성 및 로드\n",
    "print(\"=\"*60)\n",
    "print(\"한글 스팸 메일 분류기 생성 중...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "emails, labels = create_korean_email_dataset()\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({\n",
    "    'email': emails,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# numpy 배열로 변환하여 안정성 향상\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "print(f\"총 데이터 수: {len(df)}\")\n",
    "print(f\"정상 메일 수: {np.sum(labels_array == 0)}\")\n",
    "print(f\"스팸 메일 수: {np.sum(labels_array == 1)}\")\n",
    "print(f\"정상 메일 비율: {np.sum(labels_array == 0)/len(labels_array)*100:.1f}%\")\n",
    "print(f\"스팸 메일 비율: {np.sum(labels_array == 1)/len(labels_array)*100:.1f}%\")\n",
    "\n",
    "# 데이터 전처리\n",
    "df['email_processed'] = df['email'].apply(preprocess_korean_text)\n",
    "\n",
    "# 데이터 분할\n",
    "X = df['email_processed'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# 데이터 타입 확인 및 변환\n",
    "X = np.array(X, dtype=str)\n",
    "y = np.array(y, dtype=int)\n",
    "\n",
    "print(f\"데이터 타입 - X: {X.dtype}, y: {y.dtype}\")\n",
    "print(f\"데이터 형태 - X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n훈련 데이터: {len(X_train)}\")\n",
    "print(f\"테스트 데이터: {len(X_test)}\")\n",
    "\n",
    "# 토크나이저 설정 (한글 특성 고려)\n",
    "MAX_FEATURES = 10000  # 어휘 크기\n",
    "MAX_LEN = 100  # 최대 시퀀스 길이\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=MAX_FEATURES,\n",
    "    oov_token='<OOV>',  # Out-of-vocabulary 토큰\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'  # 제거할 문자\n",
    ")\n",
    "\n",
    "# 훈련 데이터로 토크나이저 학습\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 텍스트를 시퀀스로 변환\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# 패딩 적용\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "print(f\"\\n어휘 크기: {len(tokenizer.word_index)}\")\n",
    "print(f\"시퀀스 최대 길이: {MAX_LEN}\")\n",
    "\n",
    "# 개선된 모델 구축 (Bidirectional LSTM 사용)\n",
    "def create_enhanced_model():\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=MAX_FEATURES,\n",
    "                 output_dim=128,\n",
    "                 input_length=MAX_LEN,\n",
    "                 name='embedding'),\n",
    "        Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3), name='bilstm'),\n",
    "        Dense(32, activation='relu', name='dense1'),\n",
    "        Dropout(0.5, name='dropout'),\n",
    "        Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 모델 생성 및 컴파일\n",
    "model = create_enhanced_model()\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n모델 구조:\")\n",
    "model.summary()\n",
    "\n",
    "# 콜백 설정\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=0.0001\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "print(\"\\n모델 훈련 시작...\")\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 테스트 성능 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(f\"\\n테스트 정확도: {test_accuracy:.4f}\")\n",
    "\n",
    "# 예측 및 상세 평가\n",
    "y_pred_proba = model.predict(X_test_pad)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\n분류 리포트:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['정상', '스팸']))\n",
    "\n",
    "print(\"\\n혼동 행렬:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# 스팸 분류 예측 함수\n",
    "def predict_spam_korean(text, model, tokenizer, max_len=MAX_LEN):\n",
    "    \"\"\"\n",
    "    한글 텍스트가 스팸인지 예측하는 함수\n",
    "    \"\"\"\n",
    "    # 전처리\n",
    "    processed_text = preprocess_korean_text(text)\n",
    "\n",
    "    # 토크나이징 및 패딩\n",
    "    sequence = tokenizer.texts_to_sequences([processed_text])\n",
    "    padded = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
    "\n",
    "    # 예측\n",
    "    prediction = model.predict(padded, verbose=0)[0][0]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# 테스트용 한글 메일 예시\n",
    "test_korean_emails = [\n",
    "    \"축하합니다! 복권에 당첨되셨습니다. 1억원을 받으시려면 지금 즉시 링크를 클릭하세요!\",\n",
    "    \"내일 오후 3시 회의실에서 프로젝트 진행 상황을 논의하겠습니다. 참석 부탁드립니다.\",\n",
    "    \"무료 다이어트 약품 증정! 효과 100% 보장! 지금 신청하면 특별 할인!\",\n",
    "    \"보고서 작성이 완료되었습니다. 첨부파일을 확인해주시기 바랍니다.\",\n",
    "    \"긴급! 대출 승인 완료! 무심사 당일 지급! 연락 바랍니다!\",\n",
    "    \"교육 자료를 공유드립니다. 검토 후 의견 부탁드립니다.\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"한글 메일 스팸 분류 테스트\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, email in enumerate(test_korean_emails, 1):\n",
    "    prob = predict_spam_korean(email, model, tokenizer)\n",
    "    is_spam = \"스팸 메일\" if prob > 0.5 else \"정상 메일\"\n",
    "    confidence = prob if prob > 0.5 else 1 - prob\n",
    "\n",
    "    print(f\"\\n📧 테스트 {i}:\")\n",
    "    print(f\"내용: {email}\")\n",
    "    print(f\"예측: {is_spam}\")\n",
    "    print(f\"스팸 확률: {prob:.4f}\")\n",
    "    print(f\"신뢰도: {confidence:.4f} ({confidence*100:.1f}%)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 대화형 테스트 함수\n",
    "def interactive_korean_spam_test():\n",
    "    \"\"\"\n",
    "    사용자가 직접 한글 메일을 입력하여 테스트하는 함수\n",
    "    \"\"\"\n",
    "    print(\"\\n🔍 한글 메일 스팸 분류 테스트\")\n",
    "    print(\"메일 내용을 입력하세요 (종료: 'quit'):\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\n✉️ 메일 내용: \")\n",
    "\n",
    "        if user_input.lower() in ['quit', '종료', 'q']:\n",
    "            print(\"테스트를 종료합니다.\")\n",
    "            break\n",
    "\n",
    "        if user_input.strip() == '':\n",
    "            print(\"메일 내용을 입력해주세요.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            prob = predict_spam_korean(user_input, model, tokenizer)\n",
    "            is_spam = \"스팸 메일\" if prob > 0.5 else \"정상 메일\"\n",
    "            confidence = prob if prob > 0.5 else 1 - prob\n",
    "\n",
    "            print(f\"\\n📊 분석 결과:\")\n",
    "            print(f\"   🏷️  분류: {is_spam}\")\n",
    "            print(f\"   📈 스팸 확률: {prob:.4f}\")\n",
    "            print(f\"   ✅ 신뢰도: {confidence:.4f} ({confidence*100:.1f}%)\")\n",
    "\n",
    "            # 스팸일 가능성이 높은 경우 경고 표시\n",
    "            if prob > 0.8:\n",
    "                print(f\"   ⚠️  주의: 스팸일 가능성이 매우 높습니다!\")\n",
    "            elif prob < 0.2:\n",
    "                print(f\"   ✅ 안전: 정상 메일일 가능성이 매우 높습니다.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"오류가 발생했습니다: {e}\")\n",
    "\n",
    "# 모델과 토크나이저 저장 함수\n",
    "def save_model_and_tokenizer(model, tokenizer, model_path='korean_spam_model.h5', tokenizer_path='korean_tokenizer.pickle'):\n",
    "    \"\"\"\n",
    "    학습된 모델과 토크나이저를 저장하는 함수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 모델 저장\n",
    "        model.save(model_path)\n",
    "        print(f\"✅ 모델이 {model_path}에 저장되었습니다.\")\n",
    "\n",
    "        # 토크나이저 저장\n",
    "        with open(tokenizer_path, 'wb') as handle:\n",
    "            pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"✅ 토크나이저가 {tokenizer_path}에 저장되었습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 저장 중 오류 발생: {e}\")\n",
    "        print(\"현재 세션에서만 모델을 사용하세요.\")\n",
    "\n",
    "# 모델 및 토크나이저 저장 (선택사항)\n",
    "try:\n",
    "    save_model_and_tokenizer(model, tokenizer)\n",
    "except:\n",
    "    print(\"⚠️ 파일 저장을 건너뜁니다. 현재 세션에서만 사용 가능합니다.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"한글 스팸 메일 분류기 완성!\")\n",
    "print(\"아래 함수를 실행하여 직접 테스트해보세요:\")\n",
    "print(\"interactive_korean_spam_test()\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 대화형 테스트 실행 (주석 해제하여 사용)\n",
    "# interactive_korean_spam_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5Zmt7yLme8g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 한글 메일 스팸 분류 테스트\n",
      "메일 내용을 입력하세요 (종료: 'quit'):\n",
      "\n",
      "📊 분석 결과:\n",
      "   🏷️  분류: 정상 메일\n",
      "   📈 스팸 확률: 0.4973\n",
      "   ✅ 신뢰도: 0.5027 (50.3%)\n",
      "\n",
      "📊 분석 결과:\n",
      "   🏷️  분류: 스팸 메일\n",
      "   📈 스팸 확률: 1.0000\n",
      "   ✅ 신뢰도: 1.0000 (100.0%)\n",
      "   ⚠️  주의: 스팸일 가능성이 매우 높습니다!\n",
      "메일 내용을 입력해주세요.\n",
      "메일 내용을 입력해주세요.\n"
     ]
    }
   ],
   "source": [
    "# 대화형 테스트 실행 (주석 해제하여 사용)\n",
    "interactive_korean_spam_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvxSncXMywPP"
   },
   "source": [
    "## Seq2Seq (시퀀스-투-시퀀스(Sequence-to-Sequence, seq2seq)\n",
    "\n",
    "- **입력 시퀀스를 받아서 다른 시퀀스로 변환하는 모델**\n",
    "- 마치 번역기처럼 한 언어의 문장을 다른 언어로 바꾸는 것과 같음\n",
    "- 역사적 배경\n",
    "    - 2014년: Google이 기계번역용으로 제안\n",
    "    - 배경: 기존 방법들은 고정 길이 입력만 처리 가능했음\n",
    "    - 혁신: 가변 길이 입력을 가변 길이 출력으로 변환 가능\n",
    "- 기본 구조\n",
    "\n",
    "|구성 요소|역할|비유|\n",
    "|---|---|---|\n",
    "|Encoder|입력 시퀀스를 이해하고 압축|책을 읽고 요약하는 사람|\n",
    "|Decoder|압축된 정보로 출력 시퀀스 생성|요약본을 보고 다른 언어로 쓰는 사람|\n",
    "|Context Vector|인코더와 디코더를 연결하는 정보|두 사람 사이의 메모|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asTdfE8bzp2q"
   },
   "source": [
    "- 작동 과정\n",
    "    - 입력: \"I love you\"\n",
    "    -        ↓ (Encoder)\n",
    "    - Context Vector (압축된 의미)\n",
    "    -        ↓ (Decoder)  \n",
    "    - 출력: \"나는 너를 사랑해\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Q3Wp85W0PDG"
   },
   "source": [
    "- 아키텍처 (참고 https://wikidocs.net/24996)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuCGQ9vt8ol_"
   },
   "source": [
    "![Seq2seq](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FLUwms%2FbtszM0Eg9wB%2FAAAAAAAAAAAAAAAAAAAAAHUSsygDhXBD9OsONcPC84p1qhBQHqdlxVNImS4aFdRi%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3DhFLLizlqkuD3zD3pRxfQeu4%252Be7g%253D \"Seq2seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5J3KSgJ2CRp"
   },
   "source": [
    "### 예제1 : 기본 Seq2Seq 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nwb6s0XU2E2q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq 모델 생성 완료!\n",
      "Encoder: Encoder(\n",
      "  (embedding): Embedding(1000, 256)\n",
      "  (lstm): LSTM(256, 512, batch_first=True)\n",
      ")\n",
      "Decoder: Decoder(\n",
      "  (embedding): Embedding(1000, 256)\n",
      "  (lstm): LSTM(256, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell  # 마지막 상태만 반환\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        # 인코딩: 입력 시퀀스를 context vector로 압축\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # 디코딩: context vector로부터 출력 시퀀스 생성\n",
    "        outputs = []\n",
    "        input_token = target[:, 0:1]  # 시작 토큰\n",
    "\n",
    "        for i in range(1, target.size(1)):\n",
    "            output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs.append(output)\n",
    "            input_token = target[:, i:i+1]  # 다음 입력\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "# 모델 생성\n",
    "vocab_size = 1000\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "\n",
    "encoder = Encoder(vocab_size, embed_size, hidden_size)\n",
    "decoder = Decoder(vocab_size, embed_size, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "print(\"Seq2Seq 모델 생성 완료!\")\n",
    "print(f\"Encoder: {encoder}\")\n",
    "print(f\"Decoder: {decoder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a6-GJV4Ykeq"
   },
   "source": [
    "- **\"I love llamas\"를 \"Ik hou van lama's\"로 번역하는 예제**\n",
    "    - (실행을 위해 앞 코드에서 추가한 사항)\n",
    "    - **어휘 사전** : Vocabulary 클래스 → 단어-인덱스 매핑 자동화\n",
    "    - **특수 토큰** : `<SOS>`, `<EOS>`, `<PAD>`, `<UNK>` →문장 경계 및 패딩 처리\n",
    "    - **Teacher Forcing** : 확률적 적용 →훈련 안정성 향상\n",
    "    - **드롭아웃** : 0.2 비율 적용 → 과적합 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QcXuZ49lYdq8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "영어-네덜란드어 Seq2Seq 번역 모델\n",
      "==================================================\n",
      "영어 어휘 수: 25\n",
      "네덜란드어 어휘 수: 26\n",
      "\n",
      "모델 구조:\n",
      "Encoder: 어휘 크기 25, 임베딩 128, 은닉 256\n",
      "Decoder: 어휘 크기 26, 임베딩 128, 은닉 256\n",
      "\n",
      "모델 훈련 시작...\n",
      "Epoch [20/200], Loss: 0.8748\n",
      "Epoch [40/200], Loss: 0.7678\n",
      "Epoch [60/200], Loss: 0.7386\n",
      "Epoch [80/200], Loss: 0.7360\n",
      "Epoch [100/200], Loss: 0.7349\n",
      "Epoch [120/200], Loss: 0.7343\n",
      "Epoch [140/200], Loss: 0.7340\n",
      "Epoch [160/200], Loss: 0.7338\n",
      "Epoch [180/200], Loss: 0.7337\n",
      "Epoch [200/200], Loss: 0.7336\n",
      "\n",
      "번역 테스트:\n",
      "------------------------------\n",
      "영어: I love llamas\n",
      "네덜란드어: hou van lama's lama's lama's lama's\n",
      "\n",
      "영어: I like cats\n",
      "네덜란드어: hou van katten katten katten\n",
      "\n",
      "영어: I eat apples\n",
      "네덜란드어: eet appels appels appels\n",
      "\n",
      "영어: I drink water\n",
      "네덜란드어: drink water water\n",
      "\n",
      "==============================\n",
      "목표 번역:\n",
      "영어: I love llamas\n",
      "네덜란드어 번역: hou van lama's lama's lama's lama's\n",
      "정답: Ik hou van lama's\n",
      "\n",
      "========================================\n",
      "모델 성능 분석\n",
      "========================================\n",
      "1. Seq2Seq 모델의 특징:\n",
      "   - 인코더: 입력 문장을 고정 크기 벡터로 압축\n",
      "   - 디코더: 압축된 벡터로부터 출력 문장 생성\n",
      "   - Teacher Forcing: 훈련 시 정답을 다음 입력으로 사용\n",
      "\n",
      "2. 한계점:\n",
      "   - 긴 문장에서 정보 손실 발생 가능\n",
      "   - 입력 문장의 모든 정보를 하나의 벡터에 압축\n",
      "   - 단어 순서가 다른 언어쌍에서 성능 제한\n",
      "\n",
      "3. 개선 방안:\n",
      "   - Attention 메커니즘 추가\n",
      "   - 더 많은 훈련 데이터 사용\n",
      "   - Transformer 모델 도입\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
    "        self.idx2word = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
    "        self.word_count = 4\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.word_count\n",
    "            self.idx2word[self.word_count] = word\n",
    "            self.word_count += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.word_count\n",
    "\n",
    "def create_datasets():\n",
    "    \"\"\"영어-네덜란드어 번역 데이터셋 생성\"\"\"\n",
    "    # 간단한 훈련 데이터 (실제로는 더 많은 데이터가 필요)\n",
    "    english_sentences = [\n",
    "        \"I love llamas\",\n",
    "        \"I like cats\",\n",
    "        \"I eat apples\",\n",
    "        \"I drink water\",\n",
    "        \"I read books\",\n",
    "        \"I watch movies\",\n",
    "        \"I play games\",\n",
    "        \"I write code\",\n",
    "        \"I love programming\",\n",
    "        \"I study machine learning\"\n",
    "    ]\n",
    "\n",
    "    dutch_sentences = [\n",
    "        \"Ik hou van lama's\",\n",
    "        \"Ik hou van katten\",\n",
    "        \"Ik eet appels\",\n",
    "        \"Ik drink water\",\n",
    "        \"Ik lees boeken\",\n",
    "        \"Ik kijk naar films\",\n",
    "        \"Ik speel spelletjes\",\n",
    "        \"Ik schrijf code\",\n",
    "        \"Ik hou van programmeren\",\n",
    "        \"Ik studeer machine learning\"\n",
    "    ]\n",
    "\n",
    "    return english_sentences, dutch_sentences\n",
    "\n",
    "def preprocess_data(english_sentences, dutch_sentences):\n",
    "    \"\"\"데이터 전처리 및 어휘 사전 생성\"\"\"\n",
    "    en_vocab = Vocabulary()\n",
    "    nl_vocab = Vocabulary()\n",
    "\n",
    "    # 어휘 사전 구축\n",
    "    for sentence in english_sentences:\n",
    "        for word in sentence.lower().split():\n",
    "            en_vocab.add_word(word)\n",
    "\n",
    "    for sentence in dutch_sentences:\n",
    "        for word in sentence.lower().split():\n",
    "            nl_vocab.add_word(word)\n",
    "\n",
    "    return en_vocab, nl_vocab\n",
    "\n",
    "def sentence_to_indices(sentence, vocab, max_len=10):\n",
    "    \"\"\"문장을 인덱스 시퀀스로 변환\"\"\"\n",
    "    words = sentence.lower().split()\n",
    "    indices = [vocab.word2idx.get(word, vocab.word2idx['<UNK>']) for word in words]\n",
    "\n",
    "    # 최대 길이 제한 (EOS 토큰 공간 확보)\n",
    "    if len(indices) >= max_len:\n",
    "        indices = indices[:max_len-1]\n",
    "\n",
    "    # 패딩 추가\n",
    "    while len(indices) < max_len:\n",
    "        indices.append(vocab.word2idx['<PAD>'])\n",
    "\n",
    "    return indices\n",
    "\n",
    "# 2. 모델 정의 (기존 코드 개선)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = source.size(0)\n",
    "        target_len = target.size(1)\n",
    "        target_vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        # 인코딩\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # 디코딩 결과 저장\n",
    "        outputs = torch.zeros(batch_size, target_len, target_vocab_size)\n",
    "\n",
    "        # 첫 번째 입력은 <SOS> 토큰\n",
    "        input_token = target[:, 0:1]\n",
    "\n",
    "        for i in range(1, target_len):\n",
    "            output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, i:i+1] = output\n",
    "\n",
    "            # Teacher forcing 적용\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(-1)\n",
    "            input_token = target[:, i:i+1] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# 3. 훈련 함수\n",
    "def train_model(model, train_data, en_vocab, nl_vocab, num_epochs=100):\n",
    "    \"\"\"모델 훈련\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # 패딩 무시\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    max_len = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for en_sentence, nl_sentence in train_data:\n",
    "            # 데이터 준비 - 길이 통일\n",
    "            en_indices = sentence_to_indices(en_sentence, en_vocab, max_len)\n",
    "            nl_words = sentence_to_indices(nl_sentence, nl_vocab, max_len-1)  # SOS/EOS 공간 확보\n",
    "\n",
    "            # 디코더 입력: <SOS> + 문장 (마지막 제외)\n",
    "            nl_input = [nl_vocab.word2idx['<SOS>']] + nl_words[:-1]\n",
    "            # 타겟: 문장 + <EOS>\n",
    "            nl_target = nl_words + [nl_vocab.word2idx['<EOS>']]\n",
    "\n",
    "            # 길이 맞추기\n",
    "            nl_input = nl_input[:max_len]\n",
    "            nl_target = nl_target[:max_len]\n",
    "\n",
    "            # 패딩으로 길이 통일\n",
    "            while len(nl_input) < max_len:\n",
    "                nl_input.append(nl_vocab.word2idx['<PAD>'])\n",
    "            while len(nl_target) < max_len:\n",
    "                nl_target.append(nl_vocab.word2idx['<PAD>'])\n",
    "\n",
    "            en_tensor = torch.LongTensor([en_indices])\n",
    "            nl_tensor = torch.LongTensor([nl_input])\n",
    "            target_tensor = torch.LongTensor([nl_target])\n",
    "\n",
    "            # 순전파\n",
    "            optimizer.zero_grad()\n",
    "            output = model(en_tensor, nl_tensor)\n",
    "\n",
    "            # 손실 계산 - 차원 맞추기\n",
    "            output = output.reshape(-1, output.shape[-1])  # [batch*seq, vocab]\n",
    "            target_tensor = target_tensor.reshape(-1)       # [batch*seq]\n",
    "            loss = criterion(output, target_tensor)\n",
    "\n",
    "            # 역전파\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            avg_loss = total_loss / len(train_data)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# 4. 번역 함수\n",
    "def translate(model, sentence, en_vocab, nl_vocab, max_len=10):\n",
    "    \"\"\"문장 번역\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 입력 문장 전처리\n",
    "        en_indices = sentence_to_indices(sentence, en_vocab)\n",
    "        en_tensor = torch.LongTensor([en_indices])\n",
    "\n",
    "        # 인코딩\n",
    "        hidden, cell = model.encoder(en_tensor)\n",
    "\n",
    "        # 디코딩\n",
    "        result = []\n",
    "        input_token = torch.LongTensor([[nl_vocab.word2idx['<SOS>']]])\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            output, hidden, cell = model.decoder(input_token, hidden, cell)\n",
    "            predicted_id = output.argmax(-1).item()\n",
    "\n",
    "            if predicted_id == nl_vocab.word2idx['<EOS>']:\n",
    "                break\n",
    "\n",
    "            if predicted_id != nl_vocab.word2idx['<PAD>']:\n",
    "                word = nl_vocab.idx2word[predicted_id]\n",
    "                result.append(word)\n",
    "\n",
    "            input_token = torch.LongTensor([[predicted_id]])\n",
    "\n",
    "        return ' '.join(result)\n",
    "\n",
    "# 5. 메인 실행 코드\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"영어-네덜란드어 Seq2Seq 번역 모델\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # 데이터 준비\n",
    "    english_sentences, dutch_sentences = create_datasets()\n",
    "    en_vocab, nl_vocab = preprocess_data(english_sentences, dutch_sentences)\n",
    "\n",
    "    print(f\"영어 어휘 수: {len(en_vocab)}\")\n",
    "    print(f\"네덜란드어 어휘 수: {len(nl_vocab)}\")\n",
    "    print()\n",
    "\n",
    "    # 훈련 데이터\n",
    "    train_data = list(zip(english_sentences, dutch_sentences))\n",
    "\n",
    "    # 모델 생성\n",
    "    embed_size = 128\n",
    "    hidden_size = 256\n",
    "\n",
    "    encoder = Encoder(len(en_vocab), embed_size, hidden_size)\n",
    "    decoder = Decoder(len(nl_vocab), embed_size, hidden_size)\n",
    "    model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "    print(\"모델 구조:\")\n",
    "    print(f\"Encoder: 어휘 크기 {len(en_vocab)}, 임베딩 {embed_size}, 은닉 {hidden_size}\")\n",
    "    print(f\"Decoder: 어휘 크기 {len(nl_vocab)}, 임베딩 {embed_size}, 은닉 {hidden_size}\")\n",
    "    print()\n",
    "\n",
    "    # 모델 훈련\n",
    "    print(\"모델 훈련 시작...\")\n",
    "    train_model(model, train_data, en_vocab, nl_vocab, num_epochs=200)\n",
    "    print()\n",
    "\n",
    "    # 번역 테스트\n",
    "    print(\"번역 테스트:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    test_sentences = [\n",
    "        \"I love llamas\",\n",
    "        \"I like cats\",\n",
    "        \"I eat apples\",\n",
    "        \"I drink water\"\n",
    "    ]\n",
    "\n",
    "    for sentence in test_sentences:\n",
    "        translation = translate(model, sentence, en_vocab, nl_vocab)\n",
    "        print(f\"영어: {sentence}\")\n",
    "        print(f\"네덜란드어: {translation}\")\n",
    "        print()\n",
    "\n",
    "    # 새로운 문장 번역 (목표 문장)\n",
    "    print(\"=\" * 30)\n",
    "    print(\"목표 번역:\")\n",
    "    target_sentence = \"I love llamas\"\n",
    "    translation = translate(model, target_sentence, en_vocab, nl_vocab)\n",
    "    print(f\"영어: {target_sentence}\")\n",
    "    print(f\"네덜란드어 번역: {translation}\")\n",
    "    print(f\"정답: Ik hou van lama's\")\n",
    "\n",
    "# 6. 모델 성능 분석\n",
    "def analyze_model_performance():\n",
    "    \"\"\"모델 성능 분석\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"모델 성능 분석\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    print(\"1. Seq2Seq 모델의 특징:\")\n",
    "    print(\"   - 인코더: 입력 문장을 고정 크기 벡터로 압축\")\n",
    "    print(\"   - 디코더: 압축된 벡터로부터 출력 문장 생성\")\n",
    "    print(\"   - Teacher Forcing: 훈련 시 정답을 다음 입력으로 사용\")\n",
    "\n",
    "    print(\"\\n2. 한계점:\")\n",
    "    print(\"   - 긴 문장에서 정보 손실 발생 가능\")\n",
    "    print(\"   - 입력 문장의 모든 정보를 하나의 벡터에 압축\")\n",
    "    print(\"   - 단어 순서가 다른 언어쌍에서 성능 제한\")\n",
    "\n",
    "    print(\"\\n3. 개선 방안:\")\n",
    "    print(\"   - Attention 메커니즘 추가\")\n",
    "    print(\"   - 더 많은 훈련 데이터 사용\")\n",
    "    print(\"   - Transformer 모델 도입\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    analyze_model_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mNIgtqgEnQ8"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RRXAC1HeE0p"
   },
   "source": [
    "## **Attention 메커니즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EN82gyCeMKz"
   },
   "source": [
    "- **어떤 부분에 집중할지 결정하는 메커니즘**(어텐션은 관련성이 높은 정보에 집중하는 메커니즘)\n",
    "- 마치 책을 읽을 때 중요한 문장에 형광펜을 치는 것과 같다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3AybMBDttxF"
   },
   "source": [
    "- 구성요소\n",
    "\n",
    "|구성 요소|역할|비유|\n",
    "|---|---|---|\n",
    "|Query (Q)|질문, 찾고 있는 것|\"번역하려는 현재 단어\"|\n",
    "|Key (K)|참조할 정보들의 인덱스|\"사전의 찾기 목록\"|\n",
    "|Value (V)|실제 정보 내용|\"사전의 실제 뜻 설명\"|\n",
    "\n",
    "- Attention 종류\n",
    "\n",
    "|어텐션 타입|용도|Query|Key|Value|\n",
    "|---|---|---|---|---|\n",
    "|Self-Attention|문맥 이해|같은 문장|같은 문장|같은 문장|\n",
    "|Cross-Attention|번역, 요약|타겟 언어|소스 언어|소스 언어|\n",
    "|Visual Attention|이미지 캡션|생성할 단어|이미지 영역|이미지 특징|\n",
    "\n",
    "\n",
    "- 작동 원리\n",
    "    - Query로 어떤 정보를 찾을지 정의\n",
    "    - 모든 Key들과 유사도 계산 (점수 매기기)\n",
    "    - 점수가 높은 Value들에 더 집중\n",
    "    - 가중합으로 최종 결과 생성\n",
    "\n",
    "- 아키텍처 (참고 https://denev6.tistory.com/entry/Attention-Mechanism?category=1039051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNTEhsL2s8up"
   },
   "source": [
    "![Attention](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FcX4CSD%2FbtsGcN8fNML%2FAAAAAAAAAAAAAAAAAAAAAPaDbvrD7FwLowmxlMTPy2qzgCdlrNUXriNwMrY3_fn9%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3DeYx75sEAKFiOWcrO7ISyOMDj3VM%253D \"Attention\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BZsiD2MDNWK"
   },
   "source": [
    "- **Self-Attention**:\n",
    "    - \"한 시퀀스 내의 모든 위치가 서로 직접적으로 상호작용하여 각 위치가 다른 모든 위치들로부터 얼마나 정보를 가져올지 결정하는 메커니즘\"\n",
    "    - 기본 아이디어\n",
    "        - Query, Key, Value가 모두 같은 입력에서 나옴\n",
    "        - 문장의 각 단어가 같은 문장의 다른 모든 단어들과 관계를 계산\n",
    "    - 작동 과정\n",
    "        > 입력 문장: \"The cat sat on the mat\"\n",
    "\n",
    "        >각 단어가 질문: \"나와 관련있는 단어는?\"\n",
    "        >- \"cat\" → \"The\"(0.1), \"cat\"(0.8), \"sat\"(0.6), \"on\"(0.1), \"the\"(0.1), \"mat\"(0.3)\n",
    "        >- \"sat\" → \"The\"(0.1), \"cat\"(0.7), \"sat\"(0.9), \"on\"(0.4), \"the\"(0.1), \"mat\"(0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHuPulCM-gWD"
   },
   "source": [
    "- Scaled Dot-Product Attention\n",
    "    - Query와 Key의 유사도를 계산하고 √d_k로 스케일링한 후, 소프트맥스를 적용해 Value에 가중치를 부여하는 어텐션 메커니즘\n",
    "    - Attention(Q,K,V) = softmax(QK^T/√d_k)V\n",
    "        - QK^T: Query와 Key 간 유사도 계산\n",
    "        - √d_k: 차원 크기로 나눠서 기울기 안정화\n",
    "        - softmax: 확률 분포로 변환\n",
    "        - V: 실제 정보에 가중치 적용\n",
    "    - 비유 : 비유: \"시험 볼 때 중요한 부분에 형광펜 치는 것\" - 관련성 높은 정보에 더 집중!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYVCIKaLqk5_"
   },
   "source": [
    "### **예제1 : 가장 기본적인 Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dHH_pLP2qjyw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 기본 Attention 예제 ===\n",
      "점수 계산 결과: tensor([[1.1700, 0.8300, 0.5800]])\n",
      "어텐션 가중치: tensor([[0.4413, 0.3141, 0.2446]])\n",
      "최종 출력: tensor([[1.5494, 1.3630, 1.0240, 0.7065]])\n",
      "어느 단어에 집중했나: [0.44128728 0.31409517 0.2446176 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def basic_attention(query, key, value):\n",
    "    \"\"\"가장 기본적인 어텐션 메커니즘\"\"\"\n",
    "    # 1. 점수 계산 (Query와 Key의 유사도)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1))\n",
    "    print(f\"점수 계산 결과: {scores}\")\n",
    "\n",
    "    # 2. 소프트맥스로 가중치 변환\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "    print(f\"어텐션 가중치: {attention_weights}\")\n",
    "\n",
    "    # 3. Value에 가중치 적용\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "# 예제: 3개 단어, 4차원 임베딩\n",
    "query = torch.tensor([[1.0, 0.5, 0.2, 0.1]])  # 찾고자 하는 것\n",
    "key = torch.tensor([\n",
    "    [1.0, 0.3, 0.1, 0.0],  # 첫 번째 단어\n",
    "    [0.2, 1.0, 0.5, 0.3],  # 두 번째 단어\n",
    "    [0.1, 0.4, 1.0, 0.8]   # 세 번째 단어\n",
    "])\n",
    "value = torch.tensor([\n",
    "    [2.0, 1.0, 0.5, 0.2],  # 첫 번째 단어의 실제 정보\n",
    "    [1.5, 2.0, 1.0, 0.8],  # 두 번째 단어의 실제 정보\n",
    "    [0.8, 1.2, 2.0, 1.5]   # 세 번째 단어의 실제 정보\n",
    "])\n",
    "\n",
    "print(\"=== 기본 Attention 예제 ===\")\n",
    "output, weights = basic_attention(query, key, value)\n",
    "print(f\"최종 출력: {output}\")\n",
    "print(f\"어느 단어에 집중했나: {weights.squeeze().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf1jtCg2rQyr"
   },
   "source": [
    "### **예제2 : Scaled Dot-Product Attention** (실제 사용되는 방식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a4q2Jl7trUAV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scaled Dot-Product Attention 예제 ===\n",
      "입력 문장 임베딩:\n",
      "tensor([[1.0000, 0.2000, 0.3000, 0.1000],\n",
      "        [0.3000, 1.0000, 0.8000, 0.2000],\n",
      "        [0.1000, 0.5000, 1.0000, 0.9000]])\n",
      "\n",
      "어텐션 가중치 (단어별 집중도):\n",
      "[[0.3866182  0.31971744 0.29366443]\n",
      " [0.24319205 0.40296566 0.3538423 ]\n",
      " [0.21367475 0.33847663 0.44784853]]\n",
      "\n",
      "어텐션 적용 후 출력:\n",
      "[[0.5118999  0.5438733  0.66542387 0.36690328]\n",
      " [0.39946598 0.6285252  0.74917245 0.4233704 ]\n",
      " [0.36000258 0.60513586 0.78273225 0.49212646]]\n",
      "\n",
      "=== 해석 ===\n",
      "'I'가 집중한 단어들:\n",
      "  I: 0.387\n",
      "  love: 0.320\n",
      "  AI: 0.294\n",
      "\n",
      "'love'가 집중한 단어들:\n",
      "  I: 0.243\n",
      "  love: 0.403\n",
      "  AI: 0.354\n",
      "\n",
      "'AI'가 집중한 단어들:\n",
      "  I: 0.214\n",
      "  love: 0.338\n",
      "  AI: 0.448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"실제 Transformer에서 사용하는 어텐션\"\"\"\n",
    "    d_k = Q.size(-1)  # Key 차원\n",
    "\n",
    "    # 1. Q와 K의 점곱 후 스케일링\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    # 2. 마스킹 적용 (필요한 경우)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    # 3. 소프트맥스로 확률 변환\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "    # 4. Value에 가중치 적용\n",
    "    output = torch.matmul(attention_weights, V)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "# 예제: 문장 \"I love AI\" (3개 단어)\n",
    "print(\"\\n=== Scaled Dot-Product Attention 예제 ===\")\n",
    "\n",
    "# 각 단어의 임베딩 (간단한 예시)\n",
    "sentence_embeddings = torch.tensor([\n",
    "    [1.0, 0.2, 0.3, 0.1],  # \"I\"\n",
    "    [0.3, 1.0, 0.8, 0.2],  # \"love\"\n",
    "    [0.1, 0.5, 1.0, 0.9]   # \"AI\"\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Q, K, V가 모두 같은 경우 (Self-Attention)\n",
    "Q = K = V = sentence_embeddings\n",
    "\n",
    "output, attention_weights = scaled_dot_product_attention(Q, K, V)\n",
    "\n",
    "print(\"입력 문장 임베딩:\")\n",
    "print(sentence_embeddings)\n",
    "print(\"\\n어텐션 가중치 (단어별 집중도):\")\n",
    "print(attention_weights.numpy())\n",
    "print(\"\\n어텐션 적용 후 출력:\")\n",
    "print(output.numpy())\n",
    "\n",
    "# 각 단어가 어디에 집중했는지 해석\n",
    "words = [\"I\", \"love\", \"AI\"]\n",
    "print(\"\\n=== 해석 ===\")\n",
    "for i, word in enumerate(words):\n",
    "    weights = attention_weights[i].numpy()\n",
    "    print(f\"'{word}'가 집중한 단어들:\")\n",
    "    for j, w in enumerate(words):\n",
    "        print(f\"  {w}: {weights[j]:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu9V7WLLrUc0"
   },
   "source": [
    "### **예제3 : 실제 번역 예제로 이해하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nkUNNPH-rUrd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 번역 어텐션 예제 ===\n",
      "영어: ['I', 'love', 'you']\n",
      "한국어: ['나는', '너를', '사랑해']\n",
      "\n",
      "'나는' 번역시 영어 단어 집중도:\n",
      "  I: 0.420\n",
      "  love: 0.302\n",
      "  you: 0.277\n",
      "\n",
      "'너를' 번역시 영어 단어 집중도:\n",
      "  I: 0.262\n",
      "  love: 0.360\n",
      "  you: 0.379\n",
      "\n",
      "'사랑해' 번역시 영어 단어 집중도:\n",
      "  I: 0.268\n",
      "  love: 0.438\n",
      "  you: 0.294\n"
     ]
    }
   ],
   "source": [
    "def attention_translation_example():\n",
    "    \"\"\"번역에서 어텐션이 어떻게 작동하는지 보여주는 예제\"\"\"\n",
    "\n",
    "    # 영어 문장: \"I love you\"\n",
    "    english_words = [\"I\", \"love\", \"you\"]\n",
    "    # 한국어 번역: \"나는 너를 사랑해\"\n",
    "    korean_words = [\"나는\", \"너를\", \"사랑해\"]\n",
    "\n",
    "    # 간단한 임베딩 (실제로는 더 복잡)\n",
    "    english_embeddings = torch.tensor([\n",
    "        [1.0, 0.1, 0.2],  # I\n",
    "        [0.2, 1.0, 0.8],  # love\n",
    "        [0.1, 0.2, 1.0]   # you\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    korean_embeddings = torch.tensor([\n",
    "        [0.9, 0.1, 0.1],  # 나는\n",
    "        [0.1, 0.1, 0.9],  # 너를\n",
    "        [0.1, 0.9, 0.2]   # 사랑해\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    print(\"=== 번역 어텐션 예제 ===\")\n",
    "    print(\"영어:\", english_words)\n",
    "    print(\"한국어:\", korean_words)\n",
    "\n",
    "    # 각 한국어 단어가 영어 단어들에 얼마나 집중하는지\n",
    "    for i, korean_word in enumerate(korean_words):\n",
    "        query = korean_embeddings[i:i+1]  # 현재 한국어 단어\n",
    "        key = english_embeddings          # 모든 영어 단어들\n",
    "        value = english_embeddings\n",
    "\n",
    "        output, weights = scaled_dot_product_attention(query, key, value)\n",
    "\n",
    "        print(f\"\\n'{korean_word}' 번역시 영어 단어 집중도:\")\n",
    "        for j, eng_word in enumerate(english_words):\n",
    "            print(f\"  {eng_word}: {weights[0][j].item():.3f}\")\n",
    "\n",
    "attention_translation_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWzMtrxjr7S2"
   },
   "source": [
    "### **예제4 : 시각적 어텐션** (이미지에서 텍스트 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B99OetApr9uu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 시각적 어텐션 예제 ===\n",
      "이미지 영역들: ['하늘', '나무', '사람', '강아지', '잔디']\n",
      "\n",
      "'사람이' 생성시 이미지 영역별 집중도:\n",
      "  하늘  : 0.198 ███\n",
      "  나무  : 0.196 ███\n",
      "  사람  : 0.217 ████\n",
      "  강아지 : 0.201 ████\n",
      "  잔디  : 0.188 ███\n",
      "\n",
      "'강아지와' 생성시 이미지 영역별 집중도:\n",
      "  하늘  : 0.211 ████\n",
      "  나무  : 0.188 ███\n",
      "  사람  : 0.211 ████\n",
      "  강아지 : 0.209 ████\n",
      "  잔디  : 0.182 ███\n",
      "\n",
      "'함께' 생성시 이미지 영역별 집중도:\n",
      "  하늘  : 0.193 ███\n",
      "  나무  : 0.202 ████\n",
      "  사람  : 0.211 ████\n",
      "  강아지 : 0.197 ███\n",
      "  잔디  : 0.197 ███\n"
     ]
    }
   ],
   "source": [
    "def visual_attention_example():\n",
    "    \"\"\"이미지 캡션 생성에서의 어텐션 예제\"\"\"\n",
    "\n",
    "    # 이미지의 다른 영역들 (5개 영역)\n",
    "    image_regions = [\"하늘\", \"나무\", \"사람\", \"강아지\", \"잔디\"]\n",
    "\n",
    "    # 각 영역의 특징 벡터 (간단히 3차원)\n",
    "    region_features = torch.tensor([\n",
    "        [0.8, 0.2, 0.1],  # 하늘 (파란색 위주)\n",
    "        [0.2, 0.8, 0.3],  # 나무 (초록색 위주)\n",
    "        [0.6, 0.4, 0.5],  # 사람 (복합적)\n",
    "        [0.7, 0.3, 0.2],  # 강아지 (갈색 위주)\n",
    "        [0.1, 0.9, 0.2]   # 잔디 (초록색 위주)\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    # 생성하려는 단어들\n",
    "    words_to_generate = [\"사람이\", \"강아지와\", \"함께\"]\n",
    "    word_queries = torch.tensor([\n",
    "        [0.6, 0.4, 0.5],  # \"사람이\" - 사람 영역에 집중해야 함\n",
    "        [0.7, 0.3, 0.2],  # \"강아지와\" - 강아지 영역에 집중\n",
    "        [0.4, 0.4, 0.4]   # \"함께\" - 전체적으로 봐야 함\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    print(\"=== 시각적 어텐션 예제 ===\")\n",
    "    print(\"이미지 영역들:\", image_regions)\n",
    "\n",
    "    for i, word in enumerate(words_to_generate):\n",
    "        query = word_queries[i:i+1]\n",
    "        key = value = region_features\n",
    "\n",
    "        output, weights = scaled_dot_product_attention(query, key, value)\n",
    "\n",
    "        print(f\"\\n'{word}' 생성시 이미지 영역별 집중도:\")\n",
    "        for j, region in enumerate(image_regions):\n",
    "            attention_score = weights[0][j].item()\n",
    "            bar = \"█\" * int(attention_score * 20)  # 막대 그래프로 표시\n",
    "            print(f\"  {region:4s}: {attention_score:.3f} {bar}\")\n",
    "\n",
    "visual_attention_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6tNtp9PsRJv"
   },
   "source": [
    "### **예제5 : Self-Attention으로 문맥 이해하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2vAnOCXhsRiV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Self-Attention 문맥 이해 예제 ===\n",
      "문장: The bank can guarantee deposits\n",
      "\n",
      "'bank'가 각 단어에 집중하는 정도:\n",
      "  The      : 0.168\n",
      "  bank     : 0.198\n",
      "  can      : 0.186\n",
      "  guarantee: 0.213\n",
      "  deposits : 0.235\n",
      "\n",
      "해석: 'bank'가 'guarantee'(0.213)와 'deposits'(0.235)에\n",
      "높은 집중도를 보이므로, 금융기관의 의미로 이해됨!\n"
     ]
    }
   ],
   "source": [
    "def self_attention_context():\n",
    "    \"\"\"Self-Attention으로 문맥을 어떻게 이해하는지 보여주는 예제\"\"\"\n",
    "\n",
    "    # 문장: \"The bank can guarantee deposits will eventually cover future tuition costs\"\n",
    "    # \"bank\"가 금융기관인지 강둑인지 문맥으로 판단해야 함\n",
    "\n",
    "    sentence = [\"The\", \"bank\", \"can\", \"guarantee\", \"deposits\"]\n",
    "\n",
    "    # 단어별 간단한 임베딩 (실제로는 훨씬 복잡)\n",
    "    embeddings = torch.tensor([\n",
    "        [0.1, 0.2, 0.3, 0.1],  # The\n",
    "        [0.5, 0.3, 0.2, 0.4],  # bank (애매한 의미)\n",
    "        [0.2, 0.4, 0.8, 0.1],  # can\n",
    "        [0.3, 0.6, 0.4, 0.7],  # guarantee (보장하다 - 금융 관련)\n",
    "        [0.8, 0.2, 0.3, 0.9]   # deposits (예금 - 금융 관련)\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    print(\"=== Self-Attention 문맥 이해 예제 ===\")\n",
    "    print(\"문장:\", \" \".join(sentence))\n",
    "\n",
    "    # Self-attention 계산\n",
    "    output, attention_weights = scaled_dot_product_attention(embeddings, embeddings, embeddings)\n",
    "\n",
    "    # \"bank\" 단어(인덱스 1)가 다른 단어들에 얼마나 집중하는지 확인\n",
    "    bank_attention = attention_weights[1]\n",
    "\n",
    "    print(f\"\\n'bank'가 각 단어에 집중하는 정도:\")\n",
    "    for i, word in enumerate(sentence):\n",
    "        attention_score = bank_attention[i].item()\n",
    "        print(f\"  {word:9s}: {attention_score:.3f}\")\n",
    "\n",
    "    print(f\"\\n해석: 'bank'가 'guarantee'({bank_attention[3]:.3f})와 'deposits'({bank_attention[4]:.3f})에\")\n",
    "    print(\"높은 집중도를 보이므로, 금융기관의 의미로 이해됨!\")\n",
    "\n",
    "self_attention_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmAOXjcPtd9C"
   },
   "source": [
    "## **Transformer 메커니즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL-57hMvt5GV"
   },
   "source": [
    "- 2017년 \"Attention Is All You Need\" 논문 발표 (Google)\n",
    "- https://arxiv.org/abs/1706.03762\n",
    "- 배경: RNN의 순차 처리 한계 극복\n",
    "- 혁신: 병렬 처리 + Self-Attention으로 성능 대폭 향상\n",
    "-\n",
    "- 핵심 구조\n",
    "|구성 요소|기능|핵심 특징|\n",
    "|---|---|---|\n",
    "|Self-Attention|문장 내 단어들 간의 관계 파악|모든 위치를 동시에 참조|\n",
    "|Multi-Head Attention|여러 관점에서 동시에 집중|8개 헤드로 다양한 패턴 학습|\n",
    "|Positional Encoding|단어 순서 정보 제공|삼각함수로 위치 인코딩|\n",
    "|Feed Forward Network|비선형 변환|2층 완전연결층|\n",
    "|Layer Normalization|학습 안정화|각 층마다 정규화|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GK5EpOnv4mO"
   },
   "source": [
    "- 비유\n",
    "    - RNN: 책을 한 줄씩 읽기 (느리지만 순서 중요)\n",
    "    - Transformer: 책 전체를 한번에 스캔 후 중요 부분에 집중 (빠르고 정확)\n",
    "        - \"모든 단어가 모든 단어와 직접 대화할 수 있게 하자!\"\n",
    "- 아키텍처 (참고 https://wikidocs.net/31379)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVwA9W381S4t"
   },
   "source": [
    "<!-- ![Transformer](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FbaUw7E%2FbtsGwRgo7Gh%2FAAAAAAAAAAAAAAAAAAAAADsw8eQNDsJIV5siCEHkZ47STihuV8H4bDHsi0Pn9TWk%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3D2JkSSaqR3ITrU1zIsxbLgcxJomQ%253D \"Transformer\") -->\n",
    "\n",
    "\n",
    "![Transformer](https://wikidocs.net/images/page/236193/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8.png \"Transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYPn-39xukWq"
   },
   "source": [
    "### **예제 1: 간단한 Attention 계산**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kYj-Ex4ZusGl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 shape: torch.Size([1, 4, 6])\n",
      "출력 shape: torch.Size([1, 4, 6])\n",
      "어텐션 가중치 shape: torch.Size([1, 4, 4])\n",
      "\n",
      "어텐션 가중치 (어디에 집중했는지):\n",
      "[[0.04095288 0.01825249 0.00157932 0.9392153 ]\n",
      " [0.06694145 0.2349849  0.24481353 0.45326015]\n",
      " [0.04001846 0.43282014 0.0916252  0.43553618]\n",
      " [0.35671413 0.13407855 0.48082045 0.02838681]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def simple_attention(query, key, value):\n",
    "    \"\"\"간단한 어텐션 메커니즘\"\"\"\n",
    "    # 1. Query와 Key의 유사도 계산\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1))\n",
    "\n",
    "    # 2. 소프트맥스로 가중치 계산\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "    # 3. Value에 가중치 적용\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "# 예제 데이터 (문장 길이=4, 임베딩 차원=6)\n",
    "seq_len, d_model = 4, 6\n",
    "query = torch.randn(1, seq_len, d_model)\n",
    "key = torch.randn(1, seq_len, d_model)\n",
    "value = torch.randn(1, seq_len, d_model)\n",
    "\n",
    "# 어텐션 계산\n",
    "output, weights = simple_attention(query, key, value)\n",
    "\n",
    "print(\"입력 shape:\", query.shape)\n",
    "print(\"출력 shape:\", output.shape)\n",
    "print(\"어텐션 가중치 shape:\", weights.shape)\n",
    "print(\"\\n어텐션 가중치 (어디에 집중했는지):\")\n",
    "print(weights[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmBAvUQhustY"
   },
   "source": [
    "### **예제 2: Multi-Head Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aFus3Q5nus6R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 shape: torch.Size([2, 10, 512])\n",
      "출력 shape: torch.Size([2, 10, 512])\n",
      "Multi-Head Attention 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        # 선형 변환층들\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "\n",
    "        # 1. Q, K, V 생성\n",
    "        Q = self.W_q(x)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        # 2. 멀티헤드로 분할\n",
    "        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # 3. 어텐션 계산\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_output = torch.matmul(attention_weights, V)\n",
    "\n",
    "        # 4. 헤드들 합치기\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, seq_len, d_model)\n",
    "\n",
    "        # 5. 최종 선형 변환\n",
    "        output = self.W_o(attention_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# 사용 예시\n",
    "d_model, num_heads = 512, 8\n",
    "mha = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "# 입력: (배치=2, 시퀀스=10, 특성=512)\n",
    "x = torch.randn(2, 10, d_model)\n",
    "output = mha(x)\n",
    "\n",
    "print(f\"입력 shape: {x.shape}\")\n",
    "print(f\"출력 shape: {output.shape}\")\n",
    "print(\"Multi-Head Attention 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfTUKYQ7utF9"
   },
   "source": [
    "### **예제 3: 간단한 Transformer 블록**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ef6XeDwYutOD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer 블록 입력:  torch.Size([2, 10, 512])\n",
      "Transformer 블록 출력: torch.Size([2, 10, 512])\n",
      "Transformer 블록 처리 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# (가정) MultiHeadAttention은 아래와 같은 시그니처/동작을 가진다고 가정합니다.\n",
    "# - 입력: x (B, T, d_model)\n",
    "# - 출력: (B, T, d_model)  ← 각 헤드에서 산출된 어텐션 결과를 concat + 선형 변환 후 반환\n",
    "# - (확장) 실제 구현은 마스크, key_padding_mask 등을 받을 수 있음. 여기서는 단순화.\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model은 num_heads로 나누어 떨어져야 합니다.\"\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 자기어텐션(Self-Attention): Q=K=V=x\n",
    "        # MultiheadAttention은 (B, T, C) 입력을 지원(batch_first=True)하므로 그대로 사용 가능\n",
    "        out, _ = self.attn(x, x, x, need_weights=False)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        하나의 Transformer 인코더 블록(원 논문의 Post-LN 구성과 동일한 형태):\n",
    "        - 서브층 1: 멀티헤드 자기어텐션(Multi-Head Self-Attention)\n",
    "        - 서브층 2: 포지션-와이즈 피드포워드 네트워크(FFN)\n",
    "        - 각 서브층 뒤에 잔차연결(Residual) + LayerNorm\n",
    "        - 드롭아웃으로 과적합 방지\n",
    "\n",
    "        Args:\n",
    "            d_model (int): 임베딩 차원 (모든 서브층의 입출력 채널 수)\n",
    "            num_heads (int): 멀티헤드 개수 (d_model % num_heads == 0 권장/필수)\n",
    "            d_ff (int): FFN 내부 확장 차원 (일반적으로 4 * d_model)\n",
    "            dropout (float): 드롭아웃 비율 (학습 시만 적용, eval()에서는 비활성)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) Multi-Head Attention 서브층\n",
    "        #    입력과 동일 차원의 출력을 내는 자기어텐션(Self-Attention) 모듈\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        # 2) Position-wise Feed-Forward Network (FFN)\n",
    "        #    각 시점(토큰 위치)별로 동일한 두 개의 선형변환을 적용:\n",
    "        #      d_model → d_ff (확장) → 활성화(ReLU) → d_ff → d_model (축소)\n",
    "        #    ReLU 대신 GeLU를 쓰는 변형도 많음(BERT/Transformers).\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),  # 확장\n",
    "            nn.ReLU(),                 # 비선형성 (학습표현력 향상)\n",
    "            nn.Linear(d_ff, d_model)   # 원래 차원으로 축소\n",
    "        )\n",
    "\n",
    "        # 3) Layer Normalization (Post-LN)\n",
    "        #    각 서브층의 출력 + 잔차를 더한 뒤 정규화.\n",
    "        #    원 논문(2017)은 Post-LN, 최근엔 Pre-LN(서브층 앞에 LN)도 자주 사용됨.\n",
    "        self.norm1 = nn.LayerNorm(d_model)  # 어텐션 서브층 뒤\n",
    "        self.norm2 = nn.LayerNorm(d_model)  # FFN 서브층 뒤\n",
    "\n",
    "        # 4) Dropout\n",
    "        #    서브층 출력에 드롭아웃을 적용하여 과적합을 줄임.\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 입력 시퀀스 임베딩 텐서 (B, T, d_model)\n",
    "        Returns:\n",
    "            (B, T, d_model): 입력과 동일한 shape. (Residual로 “정보 보존 + 변환”)\n",
    "        \"\"\"\n",
    "        # --- 서브층 1: Self-Attention + Residual + LayerNorm ---\n",
    "        # attention_output: (B, T, d_model)\n",
    "        attention_output = self.attention(x)\n",
    "\n",
    "        # 드롭아웃 후, 입력 x에 Residual 연결로 더함 (정보 경로 보존 & 기울기 흐름 안정화)\n",
    "        # 그 다음 LayerNorm으로 분포를 정규화하여 학습을 안정화 (Post-LN 패턴)\n",
    "        x = self.norm1(x + self.dropout(attention_output))\n",
    "\n",
    "        # --- 서브층 2: Feed-Forward + Residual + LayerNorm ---\n",
    "        # ffn_output: (B, T, d_model)  ← position-wise로 독립적 적용 (T마다 같은 파라미터)\n",
    "        ffn_output = self.ffn(x)\n",
    "\n",
    "        # 다시 드롭아웃 → Residual → LayerNorm (Post-LN)\n",
    "        x = self.norm2(x + self.dropout(ffn_output))\n",
    "\n",
    "        # 출력 shape는 입력과 동일 (B, T, d_model)\n",
    "        return x\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Transformer 블록 테스트\n",
    "# =========================\n",
    "\n",
    "# 하이퍼파라미터 설정 예:\n",
    "# - d_model=512: 토큰 임베딩/채널 수\n",
    "# - num_heads=8: 512/8=64 → 각 헤드의 차원 d_k=64 (정수로 나눠떨어짐)\n",
    "# - d_ff=2048: FFN 내부 확장(=4 * d_model) → 원 논문 기본 권장 설정\n",
    "transformer_block = TransformerBlock(d_model=512, num_heads=8, d_ff=2048)\n",
    "\n",
    "# 더미 입력: 배치 크기 B=2, 시퀀스 길이 T=10, 채널 C=d_model=512\n",
    "x = torch.randn(2, 10, 512)  # (B, T, C)\n",
    "\n",
    "# 순전파: 출력도 (B, T, C) 형태를 유지 (Residual 덕분에 차원 보존)\n",
    "output = transformer_block(x)\n",
    "\n",
    "print(f\"Transformer 블록 입력:  {x.shape}\")     # torch.Size([2, 10, 512])\n",
    "print(f\"Transformer 블록 출력: {output.shape}\") # torch.Size([2, 10, 512])\n",
    "print(\"Transformer 블록 처리 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F__Q1Jh7Gaq7"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXLkoXSVGdOW"
   },
   "source": [
    "## **BERT**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PksYoKg3Gu9X"
   },
   "source": [
    "- **BERT(Bidirectional Encoder Representations from Transformers)**\n",
    "- 2018년 구글에서 발표한 혁신적인 자연어처리 모델\n",
    "- 기존의 일방향 언어모델과 달리 양방향으로 문맥을 이해할 수 있어 획기적인 성능 향상을 보임\n",
    "한국어 BERT 모델들은 이러한 BERT 아키텍처를 한국어에 맞게 적용한 것으로:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s9HGlq8Gw0o"
   },
   "source": [
    "### 한국어 BERT 모델\n",
    "- 2019년: SKT에서 KoBERT 공개\n",
    "- 2020년: Beomi님이 KcBERT 공개\n",
    "- 2020년: KETI에서 KR-BERT 공개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j3T10z4H8t6"
   },
   "source": [
    "- 주의사항\n",
    "    - **메모리 관리**: 코랩에서는 GPU 메모리 제한이 있으므로 배치크기 조절 필요\n",
    "    - **모델 선택**: KoBERT, KcBERT, KR-BERT 중 태스크에 맞는 모델 선택\n",
    "    - **데이터 전처리**: 한국어 특성을 고려한 전처리 (띄어쓰기, 특수문자 등)\n",
    "    - **평가 지표**: 정확도 외에 F1-score, Precision, Recall 등 다양한 지표 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXn9w4rGHDbn"
   },
   "source": [
    "### **예제1: 기본 설치 및 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7EE82MMmHH2I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# !pip install transformers torch datasets sentencepiece\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU 사용 확인\n",
    "device = (\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"사용 디바이스: {device}\")\n",
    "\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2\n",
    ")\n",
    "classification_model.to(device)\n",
    "classification_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUtoeVayHH9o"
   },
   "source": [
    "### **예제2: KoBERT 기본 사용법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kQwlgaAFHIEF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 결과:\n",
      "'오늘 날씨가 정말 좋네요!' -> ['▁', 'ᄋ', 'ᅩ늘', '▁', '날ᄊ', 'ᅵ', 'ᄀ', 'ᅡ', '▁', '정말', '▁', '좋네', 'ᄋ', 'ᅭ', '!']\n",
      "'이 영화는 너무 재미없어요.' -> ['▁', 'ᄋ', 'ᅵ', '▁', 'ᄋ', 'ᅧᆼ', 'ᄒ', 'ᅪ는', '▁', '너무', '▁', '재ᄆ', 'ᅵ', 'ᄋ', 'ᅥᆹ', 'ᄋ', 'ᅥ', 'ᄋ', 'ᅭ', '.']\n",
      "'파이썬 프로그래밍을 배우고 싶습니다.' -> ['▁', '파', 'ᄋ', 'ᅵ', '썬', '▁', '프로', 'ᄀ', 'ᅳ래ᄆ', 'ᅵ', 'ᆼ', 'ᄋ', 'ᅳᆯ', '▁', '배', 'ᄋ', 'ᅮ', 'ᄀ', 'ᅩ', '▁', 'ᄉ', 'ᅵ', 'ᇁ습ᄂ', 'ᅵ', '다', '.']\n",
      "\n",
      "임베딩 차원: torch.Size([3, 28, 768])\n"
     ]
    }
   ],
   "source": [
    "# KoBERT 모델 및 토크나이저 로드\n",
    "model_name = \"skt/kobert-base-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# 텍스트 인코딩 예제\n",
    "texts = [\n",
    "    \"오늘 날씨가 정말 좋네요!\",\n",
    "    \"이 영화는 너무 재미없어요.\",\n",
    "    \"파이썬 프로그래밍을 배우고 싶습니다.\"\n",
    "]\n",
    "\n",
    "# 토큰화 및 인코딩\n",
    "encoded = tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors='pt', return_token_type_ids=False)\n",
    "print(\"토큰화 결과:\")\n",
    "for i, text in enumerate(texts):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    print(f\"'{text}' -> {tokens}\")\n",
    "\n",
    "# 모델 추론\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print(f\"\\n임베딩 차원: {last_hidden_states.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gg5MnWjHIJ2"
   },
   "source": [
    "### **예제3: 감정분석 실습 (파인튜닝)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "irqRcnc-HIQo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'이 강의는 정말 유익하고 재미있어요!' -> 긍정 (확신도: 0.51)\n",
      "'설명이 너무 어려워서 이해하기 힘들어요.' -> 긍정 (확신도: 0.50)\n",
      "'적당한 수준인 것 같습니다.' -> 긍정 (확신도: 0.51)\n"
     ]
    }
   ],
   "source": [
    "# 샘플 데이터셋 생성 (실제로는 더 큰 데이터셋 사용)\n",
    "data = {\n",
    "    'text': [\n",
    "        \"이 제품 정말 좋아요! 강추합니다.\",\n",
    "        \"배송이 너무 늦어서 짜증나네요.\",\n",
    "        \"가격 대비 괜찮은 것 같아요.\",\n",
    "        \"품질이 생각보다 좋지 않네요.\",\n",
    "        \"서비스가 친절하고 만족스러워요.\",\n",
    "        \"다시는 이용하고 싶지 않습니다.\",\n",
    "        \"보통 수준인 것 같아요.\",\n",
    "        \"정말 실망스러운 경험이었습니다.\"\n",
    "    ],\n",
    "    'label': [1, 0, 1, 0, 1, 0, 1, 0]  # 1: 긍정, 0: 부정\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = SentimentDataset(\n",
    "    train_df['text'], train_df['label'], tokenizer\n",
    ")\n",
    "val_dataset = SentimentDataset(\n",
    "    val_df['text'], val_df['label'], tokenizer\n",
    ")\n",
    "\n",
    "# 분류 모델 로드\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2\n",
    ")\n",
    "\n",
    "# 훈련 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# 평가 함수\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': accuracy_score(labels, predictions)}\n",
    "\n",
    "# 트레이너 설정 및 훈련\n",
    "trainer = Trainer(\n",
    "    model=classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 모델 훈련 (주석 처리 - 실제 사용시 활성화)\n",
    "# trainer.train()\n",
    "\n",
    "# 예측 함수\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = classification_model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "        confidence = predictions[0][predicted_class].item()\n",
    "\n",
    "    sentiment = \"긍정\" if predicted_class == 1 else \"부정\"\n",
    "    return sentiment, confidence\n",
    "\n",
    "# 테스트\n",
    "test_texts = [\n",
    "    \"이 강의는 정말 유익하고 재미있어요!\",\n",
    "    \"설명이 너무 어려워서 이해하기 힘들어요.\",\n",
    "    \"적당한 수준인 것 같습니다.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    sentiment, confidence = predict_sentiment(text)\n",
    "    print(f\"'{text}' -> {sentiment} (확신도: {confidence:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4J4_MmyFHbS0"
   },
   "source": [
    "### **예제4: 한국어 단어 유사도 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GGsOXOMpHmXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 유사도 매트릭스:\n",
      "\t 사랑\t좋아\t행복\t슬픔\t화남\t기쁨\n",
      "사랑\t1.000\t0.897\t0.845\t1.000\t0.845\t0.880\n",
      "좋아\t0.897\t1.000\t0.869\t0.897\t0.869\t0.920\n",
      "행복\t0.845\t0.869\t1.000\t0.845\t1.000\t0.913\n",
      "슬픔\t1.000\t0.897\t0.845\t1.000\t0.845\t0.880\n",
      "화남\t0.845\t0.869\t1.000\t0.845\t1.000\t0.913\n",
      "기쁨\t0.880\t0.920\t0.913\t0.880\t0.913\t1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_word_embedding(word):\n",
    "    \"\"\"단어의 임베딩 벡터를 구하는 함수\"\"\"\n",
    "    inputs = tokenizer(word, return_tensors='pt', add_special_tokens=True,   # [CLS], [SEP] 포함\n",
    "            truncation=True,\n",
    "            max_length = 512,\n",
    "            return_token_type_ids=False)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # [CLS] 토큰의 임베딩 사용\n",
    "        embedding = outputs.last_hidden_state[0, 0, :].numpy()\n",
    "    return embedding\n",
    "\n",
    "# 단어들의 유사도 측정\n",
    "words = [\"사랑\", \"좋아\", \"행복\", \"슬픔\", \"화남\", \"기쁨\"]\n",
    "embeddings = []\n",
    "\n",
    "for word in words:\n",
    "    embedding = get_word_embedding(word)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# 유사도 행렬 계산\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"단어 유사도 매트릭스:\")\n",
    "print(\"\\t\", \"\\t\".join(words))\n",
    "for i, word in enumerate(words):\n",
    "    similarities = [f\"{sim:.3f}\" for sim in similarity_matrix[i]]\n",
    "    print(f\"{word}\\t\" + \"\\t\".join(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KN6l87K2HqId"
   },
   "source": [
    "### **예제5: 문장 완성 게임**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Lp1WF74PHqRi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문: 오늘 [MASK]가 정말 좋네요.\n",
      "예측 결과:\n",
      "1. ᄋ 날 ᄀ  ᄋ. (확률: 0.013)\n",
      "2. ᄋ날 ᄀ  ᄋ. (확률: 0.010)\n",
      "3. ᄋ진짜 ᄀ  ᄋ. (확률: 0.009)\n",
      "4. ᄋ 스트레스 ᄀ  ᄋ. (확률: 0.008)\n",
      "5. ᄋ 정말 ᄀ  ᄋ. (확률: 0.007)\n",
      "--------------------------------------------------\n",
      "원문: 파이썬은 [MASK] 프로그래밍 언어입니다.\n",
      "예측 결과:\n",
      "1. 이ᄋ 괴 기 ᄋᄋ이ᅵ. (확률: 0.015)\n",
      "2. 이ᄋ 현역 기 ᄋᄋ이ᅵ. (확률: 0.012)\n",
      "3. 이ᄋ센트 기 ᄋᄋ이ᅵ. (확률: 0.010)\n",
      "4. 이ᄋ진짜 기 ᄋᄋ이ᅵ. (확률: 0.009)\n",
      "5. 이ᄋ 인터 기 ᄋᄋ이ᅵ. (확률: 0.008)\n",
      "--------------------------------------------------\n",
      "원문: AI는 미래의 [MASK]를 바꿀 것입니다.\n",
      "예측 결과:\n",
      "1. AI ᅵᄋlo   ᄀ이ᅵ. (확률: 0.029)\n",
      "2. AI ᅵᄋ뜸   ᄀ이ᅵ. (확률: 0.020)\n",
      "3. AI ᅵᄋ짜   ᄀ이ᅵ. (확률: 0.016)\n",
      "4. AI ᅵᄋ갱   ᄀ이ᅵ. (확률: 0.012)\n",
      "5. AI ᅵᄋ날   ᄀ이ᅵ. (확률: 0.012)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 마스크 언어 모델 파이프라인 생성\n",
    "fill_mask = pipeline(\"fill-mask\", model=model_name, tokenizer=tokenizer)\n",
    "\n",
    "def sentence_completion_game(sentence_with_mask):\n",
    "    \"\"\"마스크된 단어를 예측하는 게임\"\"\"\n",
    "    results = fill_mask(sentence_with_mask)\n",
    "\n",
    "    print(f\"원문: {sentence_with_mask}\")\n",
    "    print(\"예측 결과:\")\n",
    "    for i, result in enumerate(results[:5], 1):\n",
    "        filled_sentence = result['sequence']\n",
    "        score = result['score']\n",
    "        print(f\"{i}. {filled_sentence} (확률: {score:.3f})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 게임 예제들\n",
    "game_sentences = [\n",
    "    \"오늘 [MASK]가 정말 좋네요.\",\n",
    "    \"파이썬은 [MASK] 프로그래밍 언어입니다.\",\n",
    "    \"AI는 미래의 [MASK]를 바꿀 것입니다.\"\n",
    "]\n",
    "\n",
    "for sentence in game_sentences:\n",
    "    sentence_completion_game(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jWxlIrnHqZO"
   },
   "source": [
    "### **예제6: 텍스트 분류 놀이**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9V72EK28Hqhx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 주제 분류 결과:\n",
      "'파이썬으로 AI 프로그래밍을 배우고 있어요.' -> 주제: 기술, 점수: {'기술': 2, '음식': 0, '영화': 1}\n",
      "'어제 먹은 파스타가 정말 맛있었어요.' -> 주제: 음식, 점수: {'기술': 0, '음식': 1, '영화': 0}\n",
      "'이번 주말에 개봉한 영화를 보러 갈 예정입니다.' -> 주제: 영화, 점수: {'기술': 0, '음식': 0, '영화': 1}\n"
     ]
    }
   ],
   "source": [
    "def classify_text_topic(text):\n",
    "    \"\"\"텍스트의 주제를 분류하는 간단한 예제\"\"\"\n",
    "    # 키워드 기반 간단 분류 (실제로는 더 정교한 모델 필요)\n",
    "    tech_keywords = [\"프로그래밍\", \"코딩\", \"AI\", \"컴퓨터\", \"소프트웨어\"]\n",
    "    food_keywords = [\"음식\", \"맛있\", \"요리\", \"식당\", \"메뉴\"]\n",
    "    movie_keywords = [\"영화\", \"배우\", \"감독\", \"스토리\", \"상영\"]\n",
    "\n",
    "    tech_score = sum(1 for keyword in tech_keywords if keyword in text)\n",
    "    food_score = sum(1 for keyword in food_keywords if keyword in text)\n",
    "    movie_score = sum(1 for keyword in movie_keywords if keyword in text)\n",
    "\n",
    "    scores = {\"기술\": tech_score, \"음식\": food_score, \"영화\": movie_score}\n",
    "    predicted_topic = max(scores, key=scores.get)\n",
    "\n",
    "    return predicted_topic, scores\n",
    "\n",
    "# 테스트 문장들\n",
    "test_sentences = [\n",
    "    \"파이썬으로 AI 프로그래밍을 배우고 있어요.\",\n",
    "    \"어제 먹은 파스타가 정말 맛있었어요.\",\n",
    "    \"이번 주말에 개봉한 영화를 보러 갈 예정입니다.\"\n",
    "]\n",
    "\n",
    "print(\"텍스트 주제 분류 결과:\")\n",
    "for text in test_sentences:\n",
    "    topic, scores = classify_text_topic(text)\n",
    "    print(f\"'{text}' -> 주제: {topic}, 점수: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTH8dVxiIXxl"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FataFDpgIZMS"
   },
   "source": [
    "## **GPT(Generative Pre-trained Transformer)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnGYW3wlCyfr"
   },
   "source": [
    "- **디코더-온리 (Decoder-only) 아키텍처**\n",
    "- 오직 '디코더' 부분만을 사용하여 입력 텍스트를 이해하고 그에 이어지는 텍스트를 생성하는 작업을 모두 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68MyZi2e4a8p"
   },
   "source": [
    "- **G\tGenerative (생성)**: 두 모델 모두 다음에 올 단어(토큰)를 순차적으로 예측하는 자기회귀(Autoregressive) 방식을 통해 새로운 텍스트를 생성\n",
    "- **P\tPre-trained (사전 학습)** :\t방대한 양의 인터넷 텍스트, 책, 코드 등의 데이터셋을 통해 언어의 일반적인 패턴과 지식을 미리 학습한 상태\n",
    "- **T\tTransformer (트랜스포머)** : 딥러닝 모델의 근간이 되는 트랜스포머 아키텍처 기반"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiKQ2rMKDejP"
   },
   "source": [
    "### **예제: GPT-2로 영어 텍스트 생성하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Q1BT9XNBDhdT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 모델을 로딩합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79691bf0f9024396aff3d64fa9552d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172f841890744816b4ccd89c34687b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a608307114474edfa8d823af9c99a4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877e4a41dc9a4bd7bc53d0e359301892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9bce3de2e14180b8d84fc2421353fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d635628d381b4fb0b9ba9d4bfc0f2e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de13da50fe9340bd9c97aadc2814a323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로딩 완료!\n",
      "\n",
      "--- 텍스트 생성 결과 ---\n",
      "시작 문장(Prompt): 'The future of AI is'\n",
      "\n",
      "[결과 1]\n",
      "The future of AI is still in its infancy, but with a lot of work going into it, we're starting to see an exponential growth in the way we interact with AI.\n",
      "\n",
      "\"We now have a huge amount of information in our minds that we can use to create new ways of thinking and thinking.\"\n",
      "\n",
      "For example, with machine learning, the ability to predict, predict, predict is one of the most important aspects of AI.\n",
      "\n",
      "\"This data can act as a model for future outcomes. We can use it to make predictions about certain environments, or things like climate change and so on.\n",
      "\n",
      "\"The more information we have in our minds, the more predictive we can be about where a future is going to come from.\"\n",
      "\n",
      "At the same time, AI is becoming a much more powerful tool for helping us understand and predict natural phenomena such as weather, weather forecasts and so on.\n",
      "\n",
      "\"The idea of machine learning, AI is the future of natural sciences, and we are trying to be innovative in what we do.\n",
      "\n",
      "\"AI can be used to help people or people are trying to predict the future, and we are really trying to use it to help us understand what's happening in the world.\"\n",
      "\n",
      "Explore further: AI can help us\n",
      "--------------------\n",
      "[결과 2]\n",
      "The future of AI is far from clear. The question is whether an AI may or may not be able to understand language, or to even understand human language. The problem is that AI has been for over 30 years, and there are no \"intelligent\" people to replace humans. It's hard to know what to expect from AI. It's hard to know what to expect from human intelligence.\n",
      "\n",
      "The problem with AI is that the human mind doesn't respond to certain mental representations. If you're good at recognizing complex patterns, then your mind will automatically respond to those patterns in a way that your brain can respond to. In other words, your brain is not going to respond to an AI's \"intelligence\" when faced with a big picture problem like a computer.\n",
      "\n",
      "It's time for me to take a moment to talk about this. I am a professor at the University of California, Berkeley. I have been studying neurotechnology for over a decade now. I have a PhD in neuroscience at the University of California, Berkeley. In that time I have investigated neural networks, the neural networks that are designed to understand and train human brain networks.\n",
      "\n",
      "I have spent many years studying neural networks. I have spent many years studying neural networks. And in the past year or so I\n",
      "--------------------\n",
      "[결과 3]\n",
      "The future of AI is going to be very different than it has been in the past.\"\n",
      "\n",
      "Some of the company's latest developments include a new hardware chip that will allow it to take advantage of its deep learning capabilities, and a new software system to improve the accuracy of its machine learning algorithms.\n",
      "\n",
      "It would seem that the company's ambitions for AI have been dashed in recent months. In February, AI chief executive Richard Branson said it was \"not really a big deal\" that AI could be used for any kind of \"problem solving task\" such as computer hacking.\n",
      "\n",
      "Despite this, the company has already been criticised for using Siri in its latest and most recent commercial product announcement, which uses Siri to tell users about upcoming events.\n",
      "\n",
      "Facebook confirmed to TIME that it had been working on a new product called \"Real Time\" that could give users a more accurate picture of the world around them.\n",
      "\n",
      "Facebook's AI partner, DeepMind, has been working on a machine learning system for more than a decade that can accurately predict the future.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. transformers 라이브러리 설치\n",
    "# !pip install transformers\n",
    "\n",
    "# 2. 필요한 도구 불러오기\n",
    "from transformers import pipeline\n",
    "\n",
    "# 3. 'text-generation' 파이프라인 로드\n",
    "# 모델로 'gpt2'를 지정합니다. 이 모델은 OpenAI가 공개한 GPT 모델의 표준 버전입니다.\n",
    "print(\"GPT-2 모델을 로딩합니다...\")\n",
    "text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "print(\"모델 로딩 완료!\")\n",
    "\n",
    "# 4. 텍스트 생성을 위한 시작 문장(프롬프트) 정의\n",
    "prompt = \"The future of AI is\"\n",
    "\n",
    "# 5. 텍스트 생성 실행\n",
    "# - max_length: 프롬프트를 포함한 전체 텍스트의 최대 길이\n",
    "# - num_return_sequences: 몇 개의 다른 문장을 생성할지 지정\n",
    "generated_texts = text_generator(\n",
    "    prompt,\n",
    "    max_length=50,\n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "# 6. 생성된 텍스트 결과 출력\n",
    "print(\"\\n--- 텍스트 생성 결과 ---\")\n",
    "print(f\"시작 문장(Prompt): '{prompt}'\\n\")\n",
    "\n",
    "for i, text in enumerate(generated_texts):\n",
    "    print(f\"[결과 {i+1}]\")\n",
    "    print(text['generated_text'])\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMDX6vcnDhur"
   },
   "source": [
    "### **[참고] 한글 GTP 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21JLG7SXENZD"
   },
   "source": [
    "|모델 이름|\t개발사|\t주요 특징|\n",
    "|---|---|--|\n",
    "|KoGPT|\tSKT|\t(한국의 GPT-2/3) OpenAI의 GPT 모델을 한국어에 맞게 개발한 선구적인 모델 KoGPT2, KoGPT-Trinity 등 버전이 있음.|\n",
    "|HyperCLOVA X\t|Naver Cloud|\t(한국의 GPT-4) 국내 최대 규모의 초거대 AI 모델. 강력한 성능을 자랑하며, API 형태로 제공되는 상용 모델.|\n",
    "|Polyglot-Ko|\tEleutherAI|\t(강력한 오픈소스) 다국어 모델이지만 한국어 데이터 비중이 매우 높아 한국어 성능이 뛰어난 것으로 유명한 오픈소스 모델.|\n",
    "|SOLAR|\tUpstage\t|(고성능 소형 모델) 작은 크기에도 불구하고 세계적인 LLM 성능 순위에서 1위를 차지했던 강력한 오픈소스 모델.|\n",
    "|KoAlpaca|\tBeomi (개인)|\t(오픈소스 생태계의 힘) Polyglot-Ko 모델을 기반으로 한국어 지시(Instruction) 데이터로 미세 조정한 대표적인 커뮤니티 모델.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cszDWEtVEUba"
   },
   "source": [
    "### **예제 : KoGPT-2로 한글 텍스트 생성하기**\n",
    "- KoGPT-2는 한국어 자연어 처리의 기초를 다진 상징적인 모델로, 학생들이 GPT의 발전 과정을 이해하는 출발점으로 삼기에 매우 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ng4l0IUeEUn0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKT의 KoGPT-2 모델을 로딩하고 있습니다...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340f69f65f094387ba47560c39fdc2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159f529f702541339dd7bcc431e3bf00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3496918b866744b18a33591e4db41692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea598f4397864e75a897fb7f467d4a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로딩이 완료되었습니다!\n",
      "\n",
      "==================================================\n",
      "시작 문장(Prompt): '인공지능이 인간에게 미치는 영향은'\n",
      "==================================================\n",
      "\n",
      "--- [생성 결과 1] ---\n",
      "인공지능이 인간에게 미치는 영향은 매우 작을 것으로 예측된다.\n",
      "미래에 발생할지 모르는 각종 재난이나 재해나 자연재해에 대한 대응을 위해 인공지능은 인간 삶에 필수적인 요소라고 할 수 있다.\n",
      "미래에는 인공지능이 인간 삶에 중요한 역할을 할 것이라는 예측이다.\n",
      "인공지능은 인간의 삶에 필요한 인지적 기능을 제공하고, 인간의 삶에 필요한 지식을 생성하고 학습해 이를 통해 인간에게 필요한 지식을 생성하도록 돕는다.\n",
      "이러한 인공지능은 인간을 인간답게 만드는 중요한 요소 중 하나로 알려져 있다.\n",
      "예를 들어 인공지능은 인간의 학습능력을 향상시키기 위해 필요한 정보를 수집하고 학습할 수 있도록 도와준다.\n",
      "이러한 인공지능은 인간의 삶에 필수적인 정보를 지속적으로 학습하고 학습할 수 있도록 돕는다.\n",
      "인공지능은 자연지능의 학습자뿐 아니라 인간뿐만 아니라 인간에게도 학습자 수준의 학습능력을 제공한다.\n",
      "인공지능은 인간이 학습하는 모든 정보를 분석하고 학습할 수 있도록 돕는다.\n",
      "인공지능이 인간의 학습능력 향상에서 중요한 역할을 할 수 있다는 것이다.\n",
      "이러한 인공지능은 인간의 삶에 필요한 정보뿐 아니라 인간의 학습능력에 영향을 미치는 요소도 함께 학습한다.\n",
      "인공지능은 학습자의 다양한 학습경험을 바탕으로 학습자의 학습능력을 향상시켜 학습자의 학습부담을 줄여준다.\n",
      "인공지능은 학습자의 학습내용을 예측하고, 학습자 스스로 학습방법을\n",
      "\n",
      "\n",
      "--- [생성 결과 2] ---\n",
      "인공지능이 인간에게 미치는 영향은 매우 광범위하다.\n",
      "특히, 인지능과 관련된 지능의 증가는 인간의 지적 능력을 향상시켜 주므로 인간의 잠재적 능력을 높여 줄 뿐 아니라 인간의 지능은 더 향상될 수 있다.\n",
      "따라서 인간이 인간에게 미치는 영향을 최소화하는 것이 인간의 잠재적 능력을 증진시켜 주는 길이라고 할 수 있다.\n",
      "1. 지능과 관련된 지능\n",
      "인간은 현재 살고 있는 환경에서 주어진 일을 처리함에 있어 많은 어려움을 겪고 있다.\n",
      "이러한 어려움을 해결하기 위해서는 인간의 잠재적 능력들이 인간 환경에 어떻게 영향을 주는지 알아야 한다.\n",
      "이러한 문제를 해결하기 위해서는 우선 인간의 잠재적 능력을 향상시키기 위한 방법을 알아야 한다.\n",
      "인간은 잠재적 능력을 향상시키기 위해 다양한 노력을 기울이고 있다.\n",
      "즉, 인간 환경에 대한 예측과 예측을 통해 자신의 잠재적 능력을 향상시키는 것이 중요하다.\n",
      "인간은 잠재적 능력을 향상시키기 위해 다양한 노력을 하고 있다.\n",
      "예를 들어, 인간의 잠재적 능력은 인간 환경에 대한 예측과 예측 능력을 향상시키는 데 중요한 역할을 하고 있다.\n",
      "인간 환경에 대한 예측을 통해 인간 환경에 대한 예측 능력을 향상시키고 미래의 잠재적인 능력을 향상시키는 것이 바로 인간과의 상호작용이다.\n",
      "이러한 연구들은 인간의 잠재적 능력이 향상되는 데 있어서 중요한 역할을 하고 있다.\n",
      "인간은 잠재적 능력을 향상시키기 위해 여러 가지 실험을 통해 노력한다.\n",
      "예를 들어, 인간의 잠재적 능력은 지능이 높은 것으로 측정됐다.\n",
      "예를 들어, 인간은 자신의 잠재적 능력을 향상시키기 위해 여러 가지\n",
      "\n",
      "\n",
      "--- [생성 결과 3] ---\n",
      "인공지능이 인간에게 미치는 영향은 매우 크다.\n",
      "그러나 이 같은 인공지능의 위험성은 ‘사람이 사람보다 지능이 낮다’는 연구결과와 더불어 이미 오래전부터 제기된 사실이다.\n",
      "이미 몇 년 전부터 인공지능의 위험성에 대한 연구가 활발히 진행됐는데, 그 첫 번째 연구는 왓슨(Watson)이 개발한 ‘딥러닝’(Deep Learning) 기반의 인공지능 알고리즘이다.\n",
      "연구팀은 왓슨 기반 인공지능 알고리즘을 통해 인간의 뇌 속 정보를 수집하고, 이를 통해 특정 정보를 분석한다.\n",
      "연구팀은 사람의 뇌 속 정보에 대한 정보를 수집, 분석하기 위해 왓슨 기반 인공지능 알고리즘을 개발했다.\n",
      "딥러닝 기술을 통해 수집된 정보는 기존 인공지능 알고리즘에 기반한 인공지능의 시각과 유사한 형태로 뇌 속 정보를 분석하는 것이다.\n",
      "‘딥러닝’은 인간의 뇌 속 정보가 가진 이미지, 뇌 속 정보를 활용해 뇌 속 정보를 탐지한다.\n",
      "이를 통해 인간의 뇌 속 정보를 수집하고, 이를 바탕으로 다양한 인공지능이 출현할 수 있음을 보여준다.\n",
      "특히 왓슨 기반 인공지능 알고리즘은 인간의 뇌 속 정보를 수집 데이터와 연계하여 인공지능의 시각과 유사한 형태로 분석하는 것이 특징이다.\n",
      "이 같은 인공지능의 시각과 유사한 결과를 얻을 수 있을 것으로 기대된다.\n",
      "왓슨은 인공지능의 시각과 유사한 결과를 도출할 수 있는 인공\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Hugging Face의 transformers 라이브러리를 설치합니다.\n",
    "# !pip install transformers\n",
    "\n",
    "# 2. 텍스트 생성을 위한 'pipeline' 도구를 불러옵니다.\n",
    "from transformers import pipeline\n",
    "\n",
    "# 3. 'text-generation' 파이프라인을 생성하고, 사용할 모델을 지정합니다.\n",
    "# 'skt/kogpt2-base-v2'는 SKT에서 공개한 한국어 GPT-2 모델입니다.\n",
    "print(\"SKT의 KoGPT-2 모델을 로딩하고 있습니다...\")\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"skt/kogpt2-base-v2\"\n",
    ")\n",
    "print(\"모델 로딩이 완료되었습니다!\")\n",
    "\n",
    "# 4. 텍스트 생성을 시작할 문장(프롬프트)을 정의합니다.\n",
    "prompt = \"인공지능이 인간에게 미치는 영향은\"\n",
    "\n",
    "# 5. 모델을 사용해 텍스트를 생성합니다.\n",
    "# - max_length: 생성될 전체 텍스트의 최대 길이를 정합니다. (프롬프트 포함)\n",
    "# - num_return_sequences: 몇 개의 다른 문장을 생성할지 정합니다.\n",
    "generated_texts = text_generator(\n",
    "    prompt,\n",
    "    max_length=80,\n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "# 6. 생성된 결과를 예쁘게 출력합니다.\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"시작 문장(Prompt): '{prompt}'\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "for i, text in enumerate(generated_texts):\n",
    "    print(f\"--- [생성 결과 {i+1}] ---\")\n",
    "    print(text['generated_text'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDCIZEAVETzy"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6KVnDnU4bJJ"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers sentencepiece accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6KqqBIXF4fA4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 다국어 인스트럭트 모델(FLAN-T5-Large)을 사용해 다양한 지시를 수행합니다.\n",
      "\n",
      "--- [예제 1] ---\n",
      "📌 지시: Answer the following question: What is the capital of South Korea?\n",
      "💡 모델 응답: seoul\n",
      "\n",
      "--- [예제 2] ---\n",
      "📌 지시: Translate this sentence from English to German: I am a student.\n",
      "💡 모델 응답: Ich bin Student.\n",
      "\n",
      "--- [예제 3] ---\n",
      "📌 지시: Summarize this paragraph: The James Webb Space Telescope is the largest optical telescope in space...\n",
      "💡 모델 응답: The James Webb Space Telescope is the largest optical telescope in space.\n",
      "\n",
      "--- [예제 4] ---\n",
      "📌 지시: 라면을 맛있게 끓이는 방법에 대한 짧은 블로그 글을 작성해줘.\n",
      "💡 모델 응답:             .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# --- 1. 다국어 인스트럭트 모델 불러오기 ---\n",
    "# google/flan-t5-large 모델은 다국어 데이터로 훈련된 T5 계열 인스트럭트 모델입니다.\n",
    "# flan-ul2는 너무 크기 때문에 로컬 환경에서는 flan-t5-large 또는 flan-t5-xl이 적합합니다.\n",
    "# device 변수는 MPS(Mac), CUDA(GPU), CPU 환경에 맞게 자동 선택되도록 구성합니다.\n",
    "model_id = \"google/flan-t5-large\"\n",
    "device = \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model_id,\n",
    "    tokenizer=model_id,\n",
    "    device=0 if device in (\"cuda\",\"mps\") else -1,  # pipeline의 device 인덱스 규칙: GPU/MPS는 0, CPU는 -1\n",
    ")\n",
    "\n",
    "# --- 2. 다양한 종류의 '지시(Instruction)' 준비 ---\n",
    "instructions = [\n",
    "    # 예제 1: 간단한 질문 답변 (영어)\n",
    "    \"Answer the following question: What is the capital of South Korea?\",\n",
    "\n",
    "    # 예제 2: 번역 요청 (영어 -> 독일어)\n",
    "    \"Translate this sentence from English to German: I am a student.\",\n",
    "\n",
    "    # 예제 3: 텍스트 요약 (영어)\n",
    "    \"Summarize this paragraph: The James Webb Space Telescope is the largest optical telescope in space...\",\n",
    "\n",
    "    # 예제 4: 창의적인 텍스트 생성 (한국어 지시)\n",
    "    \"라면을 맛있게 끓이는 방법에 대한 짧은 블로그 글을 작성해줘.\"\n",
    "]\n",
    "\n",
    "print(\"✅ 다국어 인스트럭트 모델(FLAN-T5-Large)을 사용해 다양한 지시를 수행합니다.\\n\")\n",
    "\n",
    "# --- 3. 모델을 사용해 각 지시 수행 및 결과 출력 ---\n",
    "for i, inst in enumerate(instructions, 1):\n",
    "    print(f\"--- [예제 {i}] ---\")\n",
    "    print(f\"📌 지시: {inst}\")\n",
    "\n",
    "    # 파이프라인을 통해 지시를 수행하고 결과를 받습니다.\n",
    "    # max_new_tokens: 입력 길이를 제외하고 새로 생성할 최대 토큰 수를 지정합니다.\n",
    "    out = pipe(inst, max_new_tokens=128)[0][\"generated_text\"]\n",
    "\n",
    "    print(f\"💡 모델 응답: {out}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwfNpPib6wyi"
   },
   "source": [
    "### **예제: LLama 모델 사용하기 (별도의 로그인 필요)**\n",
    "- Hugging Face Access Token 발급 :\n",
    "    - https://huggingface.co/settings/tokens\n",
    "- Meta-Llama-3-8B-Instruct 모델 사용 권한 획득 :\n",
    "    - https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\n",
    "    - 접근 권한 상태 확인 : https://huggingface.co/settings/gated-repos\n",
    "    - Access가 되기까지 기다려야함\n",
    "\n",
    "- 참고: https://littlefoxdiary.tistory.com/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ynGW180M6xOD"
   },
   "outputs": [],
   "source": [
    "# transformers 최신 버전과 Llama 3 실행에 필요한 라이브러리 설치\n",
    "!pip install transformers accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1_PD49HLQEI"
   },
   "source": [
    "- **Hugging Face Access Token 사용방법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOTmjM01LLc0"
   },
   "outputs": [],
   "source": [
    "# 방법1: 토큰 직접 넣기\n",
    "import os\n",
    "os.environ['HF_TOKEN'] = \"Meta Llama3 token을 입력하세요.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5CVO7i1LXw_"
   },
   "outputs": [],
   "source": [
    "# 방법2 : 코랩 노트북 액세스에 HF_TOKEN 입력\n",
    "from huggingface_hub import login\n",
    "# 코랩의 Secrets 관리자에 저장된 'HF_TOKEN' 값을 가져옵니다.\n",
    "hf_token = userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnKZHqiRLy5f"
   },
   "source": [
    "- **질문에 맞는 텍스트 생성하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqQhRp0Y7oQv"
   },
   "outputs": [],
   "source": [
    "# 실행시간 오래 걸림\n",
    "import transformers\n",
    "import torch\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "\n",
    "# --- 1. 코랩 Secrets를 사용하여 Hugging Face에 로그인 ---\n",
    "# 코랩의 Secrets 관리자에 저장된 'HF_TOKEN' 값을 가져옵니다.\n",
    "hf_token = userdata.get('HF_TOKEN')\n",
    "\n",
    "# 가져온 토큰을 사용하여 Hugging Face Hub에 프로그래매틱하게 로그인합니다.\n",
    "login(token=hf_token)\n",
    "\n",
    "# --- 2. GPT 계열의 인스트럭트 모델 불러오기 ---\n",
    "# 모델 ID 지정: Meta의 Llama 3 8B Instruct 모델\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# 파이프라인 설정\n",
    "pipe = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# --- 3. 다양한 종류의 '지시(Instruction)' 준비 ---\n",
    "instructions = [\n",
    "    \"Answer the following question: What is the capital of South Korea?\",\n",
    "    \"Translate this sentence from English to German: I am a student.\",\n",
    "    \"Summarize this paragraph: The James Webb Space Telescope is the largest optical telescope in space. Its high resolution and sensitivity allow it to view objects too old, distant, or faint for the Hubble Space Telescope.\",\n",
    "    \"라면을 맛있게 끓이는 방법에 대한 짧은 블로그 글을 작성해줘.\"\n",
    "]\n",
    "\n",
    "print(\"✅ Hugging Face 로그인 완료! Llama 3 모델을 사용해 다양한 지시를 수행합니다.\\n\")\n",
    "\n",
    "# --- 4. 모델을 사용해 각 지시 수행 및 결과 출력 ---\n",
    "for i, instruction in enumerate(instructions):\n",
    "    print(f\"--- [예제 {i+1}] ---\")\n",
    "    print(f\"📌 지시: {instruction}\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": instruction},\n",
    "    ]\n",
    "\n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    generated_text = outputs[0][\"generated_text\"][-1]['content']\n",
    "    print(f\"💡 모델 응답: {generated_text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "whisper-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
